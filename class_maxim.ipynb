{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d76cb747-4315-403c-8c60-bc837c7299fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.metrics import topk_acc, real_acc, AverageMeter\n",
    "from utils.parsers import get_training_parser\n",
    "from utils.optimizer import get_optimizer, get_scheduler, OPTIMIZERS_DICT, SCHEDULERS\n",
    "\n",
    "from models.networks import get_model\n",
    "from data_utils.data_stats import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27b57bbd-317a-4877-99bc-4c4790505d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'cifar10'                 # One of cifar10, cifar100, stl10, imagenet or imagenet21\n",
    "architecture = 'B_12-Wi_1024'\n",
    "data_resolution = 32                # Resolution of data as it is stored\n",
    "crop_resolution = 64                # Resolution of fine-tuned model (64 for all models we provide)\n",
    "num_classes = CLASS_DICT[dataset]\n",
    "#data_path = './beton/'\n",
    "eval_batch_size = 1024\n",
    "checkpoint = 'in21k_cifar10'        # This means you want the network pre-trained on ImageNet21k and finetuned on CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9e058c1-839e-4bf0-b11a-4fcecfd993d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights already downloaded\n",
      "Load_state output <All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "# TODO: Do not forget to choose GPU as runtime\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# TODO: Create a folder called 'checkpoints'. It is already included in the .gitignore file\n",
    "# Define the model and specify the pre-trained weights\n",
    "model = get_model(architecture=architecture, resolution=crop_resolution, num_classes=num_classes, checkpoint=checkpoint)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02ac606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e985883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "argparse.BooleanOptionalAction"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argparse.BooleanOptionalAction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad0a2dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4566f22-4459-45cd-9cf3-608a64b4580b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12288])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 64, 64)\n",
    "x = x.flatten()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset and initialize the DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eab64cc3-5d61-418a-9f94-1e19b81d6609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "mean = (0.4914, 0.4822, 0.4465)\n",
    "std = (0.2471, 0.2435, 0.2616)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((crop_resolution, crop_resolution)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "cifar10_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "loader = DataLoader(cifar10_dataset, batch_size=1000, shuffle=True)\n",
    "\n",
    "\n",
    "cifar10_classes = [\n",
    "    'airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "    'dog', 'frog', 'horse', 'ship', 'truck'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each class, calculate the mean image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ce7d993e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = 10\n",
    "cmeans = [[] for i in range(num_class)]\n",
    "r = 0\n",
    "for x,y in loader:\n",
    "    r+=1\n",
    "    for c in range(num_class):\n",
    "        cmeans[c].append(x[y==c])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2b6be9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clist = [torch.cat(cmeans[i]).mean(dim=0) for i in range(num_class)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cclist = [c.unsqueeze(0) for c in clist]\n",
    "centers = torch.cat(cclist)\n",
    "centers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3f0f577f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17c188760>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(clist[9].numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the ClassMaximization class and create an instance of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "70476580-15f0-4b53-bcf6-2b3693e8f928",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_c = nn.parameter.Parameter(torch.randn(3,64,64))\n",
    "\n",
    "\n",
    "class ClassMaxim(nn.Module):\n",
    "    def __init__(self,num_class, centers=None):\n",
    "        super(ClassMaxim, self).__init__()\n",
    "        self.x_c = nn.parameter.Parameter(torch.randn(num_class, 3, 64, 64))\n",
    "        if centers!=None:\n",
    "            self.x_c = nn.parameter.Parameter(centers.clone())    \n",
    "        self.clone = self.x_c.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8d654e5c-b26c-43e8-9b5c-f89b4bf0754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "clsmax = ClassMaxim(num_class=10, centers=centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "560a33aa-8c71-4672-9b71-c5894bc4a600",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]]],\n",
       "\n",
       "\n",
       "        [[[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]]],\n",
       "\n",
       "\n",
       "        [[[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]]],\n",
       "\n",
       "\n",
       "        [[[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]]],\n",
       "\n",
       "\n",
       "        [[[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]]]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clsmax.clone==clsmax.x_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6d5bcb65-f4d4-49ef-addf-24c8f1554071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([10, 3, 64, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 64])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in clsmax.parameters():\n",
    "    print(type(param.data), param.size())\n",
    "\n",
    "clsmax.x_c[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "efe0e3d5-73ce-4938-be80-89337d8b6763",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[[[0.5686, 0.5681, 0.5661,  ..., 0.5668, 0.5671, 0.5669],\n",
       "           [0.5690, 0.5684, 0.5664,  ..., 0.5667, 0.5671, 0.5670],\n",
       "           [0.5688, 0.5682, 0.5661,  ..., 0.5657, 0.5663, 0.5662],\n",
       "           ...,\n",
       "           [0.5153, 0.5144, 0.5117,  ..., 0.5086, 0.5098, 0.5100],\n",
       "           [0.5159, 0.5151, 0.5126,  ..., 0.5089, 0.5097, 0.5098],\n",
       "           [0.5159, 0.5151, 0.5127,  ..., 0.5086, 0.5093, 0.5092]],\n",
       " \n",
       "          [[0.6323, 0.6318, 0.6297,  ..., 0.6301, 0.6300, 0.6296],\n",
       "           [0.6327, 0.6321, 0.6301,  ..., 0.6301, 0.6301, 0.6298],\n",
       "           [0.6327, 0.6320, 0.6297,  ..., 0.6293, 0.6294, 0.6292],\n",
       "           ...,\n",
       "           [0.5399, 0.5390, 0.5360,  ..., 0.5337, 0.5348, 0.5349],\n",
       "           [0.5400, 0.5391, 0.5365,  ..., 0.5333, 0.5341, 0.5341],\n",
       "           [0.5396, 0.5388, 0.5363,  ..., 0.5326, 0.5333, 0.5333]],\n",
       " \n",
       "          [[0.6989, 0.6984, 0.6963,  ..., 0.6955, 0.6953, 0.6948],\n",
       "           [0.6992, 0.6986, 0.6965,  ..., 0.6956, 0.6955, 0.6951],\n",
       "           [0.6988, 0.6981, 0.6957,  ..., 0.6948, 0.6948, 0.6945],\n",
       "           ...,\n",
       "           [0.5470, 0.5459, 0.5427,  ..., 0.5406, 0.5421, 0.5424],\n",
       "           [0.5465, 0.5455, 0.5426,  ..., 0.5398, 0.5410, 0.5411],\n",
       "           [0.5459, 0.5449, 0.5421,  ..., 0.5389, 0.5399, 0.5400]]],\n",
       " \n",
       " \n",
       "         [[[0.5362, 0.5363, 0.5358,  ..., 0.5344, 0.5329, 0.5318],\n",
       "           [0.5355, 0.5357, 0.5351,  ..., 0.5332, 0.5317, 0.5305],\n",
       "           [0.5334, 0.5335, 0.5329,  ..., 0.5299, 0.5282, 0.5270],\n",
       "           ...,\n",
       "           [0.5260, 0.5240, 0.5188,  ..., 0.5197, 0.5223, 0.5232],\n",
       "           [0.5274, 0.5260, 0.5220,  ..., 0.5216, 0.5237, 0.5242],\n",
       "           [0.5276, 0.5265, 0.5232,  ..., 0.5220, 0.5238, 0.5243]],\n",
       " \n",
       "          [[0.5421, 0.5422, 0.5414,  ..., 0.5412, 0.5399, 0.5388],\n",
       "           [0.5412, 0.5413, 0.5405,  ..., 0.5399, 0.5385, 0.5374],\n",
       "           [0.5387, 0.5387, 0.5379,  ..., 0.5363, 0.5347, 0.5335],\n",
       "           ...,\n",
       "           [0.5180, 0.5159, 0.5105,  ..., 0.5110, 0.5138, 0.5147],\n",
       "           [0.5193, 0.5178, 0.5136,  ..., 0.5129, 0.5150, 0.5156],\n",
       "           [0.5195, 0.5182, 0.5147,  ..., 0.5133, 0.5151, 0.5156]],\n",
       " \n",
       "          [[0.5333, 0.5332, 0.5323,  ..., 0.5333, 0.5323, 0.5315],\n",
       "           [0.5320, 0.5320, 0.5311,  ..., 0.5315, 0.5305, 0.5295],\n",
       "           [0.5285, 0.5286, 0.5277,  ..., 0.5271, 0.5258, 0.5247],\n",
       "           ...,\n",
       "           [0.4962, 0.4941, 0.4888,  ..., 0.4914, 0.4945, 0.4956],\n",
       "           [0.4978, 0.4963, 0.4922,  ..., 0.4936, 0.4960, 0.4967],\n",
       "           [0.4982, 0.4969, 0.4934,  ..., 0.4942, 0.4962, 0.4968]]],\n",
       " \n",
       " \n",
       "         [[[0.4899, 0.4906, 0.4909,  ..., 0.4888, 0.4880, 0.4871],\n",
       "           [0.4903, 0.4910, 0.4912,  ..., 0.4891, 0.4882, 0.4872],\n",
       "           [0.4902, 0.4908, 0.4910,  ..., 0.4887, 0.4875, 0.4865],\n",
       "           ...,\n",
       "           [0.4903, 0.4903, 0.4891,  ..., 0.4921, 0.4915, 0.4907],\n",
       "           [0.4906, 0.4904, 0.4893,  ..., 0.4928, 0.4919, 0.4910],\n",
       "           [0.4902, 0.4901, 0.4889,  ..., 0.4927, 0.4916, 0.4907]],\n",
       " \n",
       "          [[0.5135, 0.5143, 0.5147,  ..., 0.5123, 0.5115, 0.5106],\n",
       "           [0.5139, 0.5146, 0.5150,  ..., 0.5126, 0.5117, 0.5107],\n",
       "           [0.5137, 0.5143, 0.5145,  ..., 0.5122, 0.5111, 0.5101],\n",
       "           ...,\n",
       "           [0.4939, 0.4937, 0.4922,  ..., 0.4952, 0.4950, 0.4945],\n",
       "           [0.4937, 0.4935, 0.4920,  ..., 0.4955, 0.4951, 0.4944],\n",
       "           [0.4931, 0.4929, 0.4915,  ..., 0.4951, 0.4946, 0.4939]],\n",
       " \n",
       "          [[0.4525, 0.4530, 0.4530,  ..., 0.4501, 0.4498, 0.4492],\n",
       "           [0.4525, 0.4530, 0.4529,  ..., 0.4500, 0.4496, 0.4489],\n",
       "           [0.4514, 0.4519, 0.4518,  ..., 0.4487, 0.4480, 0.4473],\n",
       "           ...,\n",
       "           [0.4176, 0.4173, 0.4157,  ..., 0.4185, 0.4188, 0.4185],\n",
       "           [0.4187, 0.4184, 0.4168,  ..., 0.4195, 0.4196, 0.4192],\n",
       "           [0.4189, 0.4185, 0.4169,  ..., 0.4195, 0.4195, 0.4190]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[0.5293, 0.5285, 0.5258,  ..., 0.5325, 0.5336, 0.5338],\n",
       "           [0.5277, 0.5268, 0.5241,  ..., 0.5301, 0.5314, 0.5316],\n",
       "           [0.5235, 0.5225, 0.5195,  ..., 0.5242, 0.5258, 0.5262],\n",
       "           ...,\n",
       "           [0.5529, 0.5513, 0.5471,  ..., 0.5437, 0.5457, 0.5462],\n",
       "           [0.5560, 0.5546, 0.5508,  ..., 0.5469, 0.5487, 0.5491],\n",
       "           [0.5570, 0.5557, 0.5521,  ..., 0.5481, 0.5497, 0.5500]],\n",
       " \n",
       "          [[0.5547, 0.5538, 0.5510,  ..., 0.5586, 0.5594, 0.5594],\n",
       "           [0.5527, 0.5518, 0.5489,  ..., 0.5560, 0.5569, 0.5570],\n",
       "           [0.5479, 0.5468, 0.5437,  ..., 0.5496, 0.5510, 0.5512],\n",
       "           ...,\n",
       "           [0.5316, 0.5297, 0.5249,  ..., 0.5216, 0.5244, 0.5254],\n",
       "           [0.5344, 0.5327, 0.5284,  ..., 0.5252, 0.5276, 0.5283],\n",
       "           [0.5354, 0.5338, 0.5297,  ..., 0.5265, 0.5287, 0.5293]],\n",
       " \n",
       "          [[0.5391, 0.5382, 0.5356,  ..., 0.5415, 0.5426, 0.5426],\n",
       "           [0.5364, 0.5355, 0.5328,  ..., 0.5384, 0.5395, 0.5397],\n",
       "           [0.5302, 0.5292, 0.5263,  ..., 0.5310, 0.5325, 0.5328],\n",
       "           ...,\n",
       "           [0.4259, 0.4239, 0.4188,  ..., 0.4163, 0.4197, 0.4209],\n",
       "           [0.4291, 0.4273, 0.4226,  ..., 0.4201, 0.4231, 0.4241],\n",
       "           [0.4302, 0.4285, 0.4240,  ..., 0.4215, 0.4243, 0.4253]]],\n",
       " \n",
       " \n",
       "         [[[0.5736, 0.5732, 0.5714,  ..., 0.5721, 0.5722, 0.5718],\n",
       "           [0.5730, 0.5726, 0.5707,  ..., 0.5711, 0.5711, 0.5707],\n",
       "           [0.5708, 0.5703, 0.5683,  ..., 0.5680, 0.5680, 0.5676],\n",
       "           ...,\n",
       "           [0.3875, 0.3861, 0.3822,  ..., 0.3753, 0.3774, 0.3780],\n",
       "           [0.3877, 0.3864, 0.3828,  ..., 0.3757, 0.3778, 0.3783],\n",
       "           [0.3874, 0.3861, 0.3826,  ..., 0.3754, 0.3775, 0.3780]],\n",
       " \n",
       "          [[0.6385, 0.6382, 0.6366,  ..., 0.6380, 0.6378, 0.6373],\n",
       "           [0.6380, 0.6376, 0.6360,  ..., 0.6372, 0.6370, 0.6364],\n",
       "           [0.6360, 0.6356, 0.6339,  ..., 0.6346, 0.6343, 0.6337],\n",
       "           ...,\n",
       "           [0.4411, 0.4395, 0.4351,  ..., 0.4285, 0.4309, 0.4317],\n",
       "           [0.4407, 0.4391, 0.4350,  ..., 0.4282, 0.4305, 0.4311],\n",
       "           [0.4400, 0.4385, 0.4345,  ..., 0.4275, 0.4297, 0.4304]],\n",
       " \n",
       "          [[0.7016, 0.7013, 0.6998,  ..., 0.6996, 0.6990, 0.6983],\n",
       "           [0.7009, 0.7007, 0.6991,  ..., 0.6987, 0.6980, 0.6973],\n",
       "           [0.6987, 0.6985, 0.6969,  ..., 0.6959, 0.6951, 0.6943],\n",
       "           ...,\n",
       "           [0.4746, 0.4726, 0.4676,  ..., 0.4607, 0.4637, 0.4647],\n",
       "           [0.4734, 0.4715, 0.4667,  ..., 0.4597, 0.4625, 0.4634],\n",
       "           [0.4723, 0.4704, 0.4658,  ..., 0.4587, 0.4615, 0.4623]]],\n",
       " \n",
       " \n",
       "         [[[0.6562, 0.6557, 0.6538,  ..., 0.6538, 0.6527, 0.6517],\n",
       "           [0.6551, 0.6546, 0.6527,  ..., 0.6520, 0.6508, 0.6499],\n",
       "           [0.6520, 0.6515, 0.6494,  ..., 0.6473, 0.6462, 0.6453],\n",
       "           ...,\n",
       "           [0.5488, 0.5453, 0.5375,  ..., 0.5341, 0.5380, 0.5396],\n",
       "           [0.5540, 0.5512, 0.5446,  ..., 0.5417, 0.5442, 0.5450],\n",
       "           [0.5562, 0.5537, 0.5476,  ..., 0.5450, 0.5468, 0.5472]],\n",
       " \n",
       "          [[0.6954, 0.6949, 0.6929,  ..., 0.6928, 0.6914, 0.6903],\n",
       "           [0.6940, 0.6934, 0.6915,  ..., 0.6908, 0.6894, 0.6883],\n",
       "           [0.6901, 0.6897, 0.6876,  ..., 0.6857, 0.6844, 0.6833],\n",
       "           ...,\n",
       "           [0.5333, 0.5298, 0.5218,  ..., 0.5191, 0.5233, 0.5249],\n",
       "           [0.5388, 0.5358, 0.5290,  ..., 0.5268, 0.5295, 0.5304],\n",
       "           [0.5411, 0.5384, 0.5321,  ..., 0.5301, 0.5321, 0.5327]],\n",
       " \n",
       "          [[0.7242, 0.7236, 0.7216,  ..., 0.7206, 0.7196, 0.7187],\n",
       "           [0.7220, 0.7214, 0.7196,  ..., 0.7182, 0.7171, 0.7162],\n",
       "           [0.7167, 0.7163, 0.7144,  ..., 0.7122, 0.7111, 0.7101],\n",
       "           ...,\n",
       "           [0.5044, 0.5009, 0.4927,  ..., 0.4895, 0.4939, 0.4957],\n",
       "           [0.5098, 0.5068, 0.4997,  ..., 0.4972, 0.5003, 0.5014],\n",
       "           [0.5121, 0.5093, 0.5027,  ..., 0.5007, 0.5030, 0.5038]]]],\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(clsmax.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "89ab20c3-5d92-4808-a8e4-56974327db07",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = get_training_parser()\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "epoch = 100\n",
    "num_class=10\n",
    "\n",
    "loss_fn = CrossEntropyLoss(label_smoothing=args.smooth)\n",
    "opt = get_optimizer(args.optimizer)(clsmax.parameters(), lr=0.003, weight_decay=args.weight_decay)#args.lr\n",
    "scheduler = get_scheduler(opt, args.scheduler, **args.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "90254740-4a66-464b-9bbe-7f2e6d4781c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5574, grad_fn=<SelectBackward0>)\n",
      "tensor(2.5286, grad_fn=<SelectBackward0>)\n",
      "tensor(2.7787, grad_fn=<SelectBackward0>)\n",
      "tensor(3.0540, grad_fn=<SelectBackward0>)\n",
      "tensor(3.2471, grad_fn=<SelectBackward0>)\n",
      "tensor(3.3144, grad_fn=<SelectBackward0>)\n",
      "tensor(3.2991, grad_fn=<SelectBackward0>)\n",
      "tensor(3.5806, grad_fn=<SelectBackward0>)\n",
      "tensor(3.7763, grad_fn=<SelectBackward0>)\n",
      "tensor(3.9521, grad_fn=<SelectBackward0>)\n",
      "tensor(4.0764, grad_fn=<SelectBackward0>)\n",
      "tensor(4.1131, grad_fn=<SelectBackward0>)\n",
      "tensor(4.3527, grad_fn=<SelectBackward0>)\n",
      "tensor(4.3751, grad_fn=<SelectBackward0>)\n",
      "tensor(4.6343, grad_fn=<SelectBackward0>)\n",
      "tensor(4.7068, grad_fn=<SelectBackward0>)\n",
      "tensor(4.8893, grad_fn=<SelectBackward0>)\n",
      "tensor(5.0124, grad_fn=<SelectBackward0>)\n",
      "tensor(5.1493, grad_fn=<SelectBackward0>)\n",
      "tensor(5.2786, grad_fn=<SelectBackward0>)\n",
      "tensor(5.3794, grad_fn=<SelectBackward0>)\n",
      "tensor(5.4742, grad_fn=<SelectBackward0>)\n",
      "tensor(5.6504, grad_fn=<SelectBackward0>)\n",
      "tensor(5.6988, grad_fn=<SelectBackward0>)\n",
      "tensor(5.8596, grad_fn=<SelectBackward0>)\n",
      "tensor(5.9044, grad_fn=<SelectBackward0>)\n",
      "tensor(6.0614, grad_fn=<SelectBackward0>)\n",
      "tensor(6.0868, grad_fn=<SelectBackward0>)\n",
      "tensor(6.2660, grad_fn=<SelectBackward0>)\n",
      "tensor(6.2791, grad_fn=<SelectBackward0>)\n",
      "tensor(6.4296, grad_fn=<SelectBackward0>)\n",
      "tensor(6.4579, grad_fn=<SelectBackward0>)\n",
      "tensor(6.5613, grad_fn=<SelectBackward0>)\n",
      "tensor(6.6481, grad_fn=<SelectBackward0>)\n",
      "tensor(6.7322, grad_fn=<SelectBackward0>)\n",
      "tensor(6.8248, grad_fn=<SelectBackward0>)\n",
      "tensor(6.8982, grad_fn=<SelectBackward0>)\n",
      "tensor(6.9822, grad_fn=<SelectBackward0>)\n",
      "tensor(7.0392, grad_fn=<SelectBackward0>)\n",
      "tensor(7.2077, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model.eval() # fixed model\n",
    "\n",
    "# total_acc, total_top5 = AverageMeter(), AverageMeter()\n",
    "total_loss = AverageMeter()\n",
    "\n",
    "for step in range(40):\n",
    "    for c in range(1):\n",
    "        xx = clsmax.x_c[c].flatten()#.cuda()\n",
    "        preds = model(xx)\n",
    "        targs = torch.tensor(c)#.cuda()\n",
    "\n",
    "\n",
    "        (-preds[c]).backward()\n",
    "        # loss = loss_fn(preds, targs)\n",
    "        \n",
    "        # loss = loss / args.accum_steps\n",
    "        # loss.backward()\n",
    "\n",
    "        print(preds[c])\n",
    "        \n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    \n",
    "        #total_loss.update(loss.item() * args.accum_steps, 1)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6e8c54b2-e6f8-4af7-a8f9-e9d52392dc6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(62.5754, grad_fn=<LinalgVectorNormBackward0>)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(clsmax.x_c[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e3dc65a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(62.3464)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(centers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "71585bcc-c739-4f98-ae46-841870b877b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17c24a8c0>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(clsmax.x_c[0].detach().numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a9490de9-bd80-4e23-9236-aeacdd9c1a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17c2e9f60>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(clsmax.clone[0].detach().numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "848cac2e-3e82-4efa-98e9-5a9aab4b41da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False,  True,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False,  True,  True],\n",
       "         [False, False, False,  ..., False,  True, False],\n",
       "         ...,\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False,  True,  ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         ...,\n",
       "         [False,  True, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clsmax.clone[0]==clsmax.x_c[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same thing for CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE CNN that is pretrained on cifar10\n",
    "from cifar10_models.resnet import *\n",
    "model = resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925c7071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2b4b9488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "mean = (0.4914, 0.4822, 0.4465)\n",
    "std = (0.2471, 0.2435, 0.2616)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    # transforms.Resize((crop_resolution, crop_resolution)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "cifar10_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "loader = DataLoader(cifar10_dataset, batch_size=1000, shuffle=True)\n",
    "\n",
    "\n",
    "cifar10_classes = [\n",
    "    'airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "    'dog', 'frog', 'horse', 'ship', 'truck'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b2a9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = 10\n",
    "cmeans = [[] for i in range(num_class)]\n",
    "r = 0\n",
    "for x,y in loader:\n",
    "    r+=1\n",
    "    for c in range(num_class):\n",
    "        cmeans[c].append(x[y==c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "79136533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cmeans[c][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "90bfac62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 3, 32, 32])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(cmeans[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "890ad682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12280cf10>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((torch.cat(cmeans[0])[123]*std_tens + mean_tens).detach().numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206165d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "40e77ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(cmeans[0]).mean(dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "clist = [torch.cat(cmeans[i]).mean(dim=0) for i in range(num_class)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 32, 32])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cclist = [c.unsqueeze(0) for c in clist]\n",
    "centers = torch.cat(cclist)\n",
    "centers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3912819c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 3.1257e-01,  2.9659e-01,  3.0632e-01,  ...,  3.1016e-01,\n",
       "            3.0275e-01,  3.0560e-01],\n",
       "          [ 3.1089e-01,  2.9386e-01,  3.0242e-01,  ...,  2.9926e-01,\n",
       "            2.9296e-01,  2.9936e-01],\n",
       "          [ 3.0559e-01,  2.8566e-01,  2.9294e-01,  ...,  2.8804e-01,\n",
       "            2.8376e-01,  2.9428e-01],\n",
       "          ...,\n",
       "          [ 9.3153e-02,  6.9687e-02,  7.3089e-02,  ...,  5.6257e-02,\n",
       "            5.7070e-02,  7.1982e-02],\n",
       "          [ 9.3518e-02,  7.0541e-02,  7.8216e-02,  ...,  6.2682e-02,\n",
       "            6.2986e-02,  7.3677e-02],\n",
       "          [ 9.8999e-02,  7.9466e-02,  9.0233e-02,  ...,  7.1360e-02,\n",
       "            6.6033e-02,  7.2226e-02]],\n",
       "\n",
       "         [[ 6.1643e-01,  5.9989e-01,  6.0990e-01,  ...,  6.1356e-01,\n",
       "            6.0559e-01,  6.0542e-01],\n",
       "          [ 6.1597e-01,  5.9648e-01,  6.0453e-01,  ...,  6.0465e-01,\n",
       "            5.9807e-01,  6.0048e-01],\n",
       "          [ 6.0948e-01,  5.8600e-01,  5.9128e-01,  ...,  5.9047e-01,\n",
       "            5.8621e-01,  5.9379e-01],\n",
       "          ...,\n",
       "          [ 2.3860e-01,  2.1413e-01,  2.1710e-01,  ...,  2.0014e-01,\n",
       "            2.0283e-01,  2.1795e-01],\n",
       "          [ 2.3478e-01,  2.1032e-01,  2.1866e-01,  ...,  2.0453e-01,\n",
       "            2.0602e-01,  2.1634e-01],\n",
       "          [ 2.3582e-01,  2.1492e-01,  2.2555e-01,  ...,  2.0861e-01,\n",
       "            2.0362e-01,  2.0987e-01]],\n",
       "\n",
       "         [[ 9.6491e-01,  9.4914e-01,  9.5862e-01,  ...,  9.5636e-01,\n",
       "            9.5045e-01,  9.4917e-01],\n",
       "          [ 9.6220e-01,  9.4271e-01,  9.4983e-01,  ...,  9.4796e-01,\n",
       "            9.4414e-01,  9.4535e-01],\n",
       "          [ 9.5056e-01,  9.2553e-01,  9.2880e-01,  ...,  9.2996e-01,\n",
       "            9.2916e-01,  9.3452e-01],\n",
       "          ...,\n",
       "          [ 3.9004e-01,  3.6460e-01,  3.6492e-01,  ...,  3.5049e-01,\n",
       "            3.5470e-01,  3.7153e-01],\n",
       "          [ 3.8337e-01,  3.5796e-01,  3.6321e-01,  ...,  3.5233e-01,\n",
       "            3.5479e-01,  3.6761e-01],\n",
       "          [ 3.7979e-01,  3.5831e-01,  3.6743e-01,  ...,  3.5348e-01,\n",
       "            3.4961e-01,  3.5760e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.8127e-01,  1.7655e-01,  1.9443e-01,  ...,  1.9083e-01,\n",
       "            1.7508e-01,  1.6354e-01],\n",
       "          [ 1.6360e-01,  1.5864e-01,  1.7524e-01,  ...,  1.6389e-01,\n",
       "            1.4876e-01,  1.3500e-01],\n",
       "          [ 1.3487e-01,  1.2952e-01,  1.4341e-01,  ...,  1.3523e-01,\n",
       "            1.2558e-01,  1.1110e-01],\n",
       "          ...,\n",
       "          [ 1.1935e-01,  5.6962e-02, -9.2461e-03,  ...,  2.5583e-02,\n",
       "            7.6517e-02,  1.1157e-01],\n",
       "          [ 1.3543e-01,  8.9426e-02,  4.7970e-02,  ...,  7.5391e-02,\n",
       "            1.0115e-01,  1.2463e-01],\n",
       "          [ 1.4662e-01,  1.2010e-01,  1.0393e-01,  ...,  1.0727e-01,\n",
       "            1.1861e-01,  1.3298e-01]],\n",
       "\n",
       "         [[ 2.4602e-01,  2.3954e-01,  2.5649e-01,  ...,  2.5591e-01,\n",
       "            2.4313e-01,  2.3258e-01],\n",
       "          [ 2.2483e-01,  2.1811e-01,  2.3305e-01,  ...,  2.2682e-01,\n",
       "            2.1475e-01,  2.0093e-01],\n",
       "          [ 1.9021e-01,  1.8202e-01,  1.9380e-01,  ...,  1.9454e-01,\n",
       "            1.8693e-01,  1.7204e-01],\n",
       "          ...,\n",
       "          [ 1.2764e-01,  5.9444e-02, -1.0056e-02,  ...,  2.3565e-02,\n",
       "            7.8470e-02,  1.1715e-01],\n",
       "          [ 1.4287e-01,  9.3963e-02,  5.1214e-02,  ...,  7.5884e-02,\n",
       "            1.0390e-01,  1.2980e-01],\n",
       "          [ 1.5307e-01,  1.2475e-01,  1.0792e-01,  ...,  1.1116e-01,\n",
       "            1.2233e-01,  1.3723e-01]],\n",
       "\n",
       "         [[ 3.3193e-01,  3.2412e-01,  3.3906e-01,  ...,  3.4202e-01,\n",
       "            3.3177e-01,  3.2477e-01],\n",
       "          [ 3.0540e-01,  2.9919e-01,  3.1252e-01,  ...,  3.0935e-01,\n",
       "            2.9890e-01,  2.8820e-01],\n",
       "          [ 2.6641e-01,  2.5948e-01,  2.6880e-01,  ...,  2.7046e-01,\n",
       "            2.6422e-01,  2.5315e-01],\n",
       "          ...,\n",
       "          [ 1.7059e-01,  1.0809e-01,  4.2566e-02,  ...,  7.9725e-02,\n",
       "            1.3133e-01,  1.7064e-01],\n",
       "          [ 1.8533e-01,  1.4059e-01,  1.0047e-01,  ...,  1.2916e-01,\n",
       "            1.5730e-01,  1.8372e-01],\n",
       "          [ 1.9747e-01,  1.7114e-01,  1.5555e-01,  ...,  1.6398e-01,\n",
       "            1.7662e-01,  1.9246e-01]]],\n",
       "\n",
       "\n",
       "        [[[-5.9609e-03, -3.3772e-03,  1.3503e-02,  ..., -1.6537e-03,\n",
       "           -1.0770e-02, -1.7489e-02],\n",
       "          [-7.3035e-03, -5.5927e-03,  1.1005e-02,  ..., -2.6662e-03,\n",
       "           -1.2880e-02, -2.3063e-02],\n",
       "          [ 2.4980e-03, -2.9677e-03,  6.2117e-03,  ...,  9.1098e-04,\n",
       "           -3.6438e-03, -1.3737e-02],\n",
       "          ...,\n",
       "          [-1.3902e-03, -9.3381e-03, -3.5803e-03,  ..., -6.8369e-03,\n",
       "            2.2124e-03,  3.9994e-03],\n",
       "          [-6.7354e-03, -1.5435e-02, -9.5032e-03,  ..., -2.2028e-03,\n",
       "           -1.5743e-03, -5.2340e-03],\n",
       "          [-4.9071e-03, -1.4617e-02, -6.2085e-03,  ...,  1.1449e-02,\n",
       "            5.1833e-03, -2.9550e-03]],\n",
       "\n",
       "         [[ 1.2875e-01,  1.3234e-01,  1.4993e-01,  ...,  1.3373e-01,\n",
       "            1.2355e-01,  1.1660e-01],\n",
       "          [ 1.2696e-01,  1.2858e-01,  1.4545e-01,  ...,  1.3126e-01,\n",
       "            1.2096e-01,  1.1150e-01],\n",
       "          [ 1.3499e-01,  1.2821e-01,  1.3760e-01,  ...,  1.3237e-01,\n",
       "            1.2713e-01,  1.1777e-01],\n",
       "          ...,\n",
       "          [ 5.4725e-02,  4.2707e-02,  4.4456e-02,  ...,  4.5297e-02,\n",
       "            5.5617e-02,  5.9988e-02],\n",
       "          [ 4.6408e-02,  3.4346e-02,  3.7422e-02,  ...,  4.6550e-02,\n",
       "            4.8892e-02,  4.8734e-02],\n",
       "          [ 4.4840e-02,  3.3334e-02,  4.0053e-02,  ...,  5.6571e-02,\n",
       "            5.2245e-02,  4.7909e-02]],\n",
       "\n",
       "         [[ 2.2991e-02,  2.3072e-02,  3.8522e-02,  ...,  2.0875e-02,\n",
       "            1.2804e-02,  1.0453e-02],\n",
       "          [ 1.4821e-02,  1.4246e-02,  3.0319e-02,  ...,  1.3322e-02,\n",
       "            3.6802e-03, -1.9233e-03],\n",
       "          [ 1.6671e-02,  8.6781e-03,  1.7936e-02,  ...,  1.1529e-02,\n",
       "            7.1431e-03,  8.8897e-04],\n",
       "          ...,\n",
       "          [-1.1212e-01, -1.2441e-01, -1.2099e-01,  ..., -1.1977e-01,\n",
       "           -1.1020e-01, -1.0253e-01],\n",
       "          [-1.1450e-01, -1.2671e-01, -1.2306e-01,  ..., -1.1381e-01,\n",
       "           -1.1297e-01, -1.1006e-01],\n",
       "          [-1.0560e-01, -1.1817e-01, -1.1425e-01,  ..., -9.9639e-02,\n",
       "           -1.0481e-01, -1.0518e-01]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 1.5353e-01,  1.3213e-01,  1.4275e-01,  ...,  1.6740e-01,\n",
       "            1.6240e-01,  1.7145e-01],\n",
       "          [ 1.1952e-01,  9.4381e-02,  9.9723e-02,  ...,  1.1603e-01,\n",
       "            1.1304e-01,  1.2831e-01],\n",
       "          [ 1.0573e-01,  7.4502e-02,  7.4248e-02,  ...,  7.8298e-02,\n",
       "            8.2018e-02,  1.0048e-01],\n",
       "          ...,\n",
       "          [ 2.3273e-01,  1.9436e-01,  1.7881e-01,  ...,  1.6496e-01,\n",
       "            1.7985e-01,  2.0276e-01],\n",
       "          [ 2.4089e-01,  2.0525e-01,  2.0179e-01,  ...,  1.8696e-01,\n",
       "            1.9669e-01,  2.1398e-01],\n",
       "          [ 2.6562e-01,  2.3634e-01,  2.3827e-01,  ...,  2.1930e-01,\n",
       "            2.2420e-01,  2.3725e-01]],\n",
       "\n",
       "         [[ 2.9777e-01,  2.7488e-01,  2.8434e-01,  ...,  3.1523e-01,\n",
       "            3.1046e-01,  3.1709e-01],\n",
       "          [ 2.5779e-01,  2.3132e-01,  2.3353e-01,  ...,  2.5835e-01,\n",
       "            2.5685e-01,  2.6976e-01],\n",
       "          [ 2.3434e-01,  2.0107e-01,  1.9488e-01,  ...,  2.0644e-01,\n",
       "            2.1605e-01,  2.3307e-01],\n",
       "          ...,\n",
       "          [ 1.8992e-01,  1.4482e-01,  1.2169e-01,  ...,  1.0558e-01,\n",
       "            1.2807e-01,  1.5910e-01],\n",
       "          [ 1.9510e-01,  1.5379e-01,  1.4365e-01,  ...,  1.2920e-01,\n",
       "            1.4438e-01,  1.6938e-01],\n",
       "          [ 2.1828e-01,  1.8454e-01,  1.8140e-01,  ...,  1.6701e-01,\n",
       "            1.7517e-01,  1.9325e-01]],\n",
       "\n",
       "         [[ 3.5399e-01,  3.3382e-01,  3.4088e-01,  ...,  3.6192e-01,\n",
       "            3.5973e-01,  3.6751e-01],\n",
       "          [ 3.0616e-01,  2.8352e-01,  2.8477e-01,  ...,  3.0172e-01,\n",
       "            3.0230e-01,  3.1485e-01],\n",
       "          [ 2.7102e-01,  2.4146e-01,  2.3408e-01,  ...,  2.4054e-01,\n",
       "            2.5137e-01,  2.6782e-01],\n",
       "          ...,\n",
       "          [-8.9040e-02, -1.3298e-01, -1.5061e-01,  ..., -1.6369e-01,\n",
       "           -1.4599e-01, -1.1436e-01],\n",
       "          [-8.6780e-02, -1.2713e-01, -1.3500e-01,  ..., -1.4659e-01,\n",
       "           -1.3283e-01, -1.0589e-01],\n",
       "          [-6.2237e-02, -9.6281e-02, -9.8610e-02,  ..., -1.1107e-01,\n",
       "           -1.0278e-01, -8.1182e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 3.3274e-01,  3.1830e-01,  3.3320e-01,  ...,  3.3367e-01,\n",
       "            3.2446e-01,  3.2546e-01],\n",
       "          [ 3.1463e-01,  2.9842e-01,  3.1469e-01,  ...,  3.1177e-01,\n",
       "            3.0012e-01,  3.0001e-01],\n",
       "          [ 2.9364e-01,  2.7346e-01,  2.9066e-01,  ...,  2.9062e-01,\n",
       "            2.7857e-01,  2.7919e-01],\n",
       "          ...,\n",
       "          [-4.1584e-01, -4.4835e-01, -4.5667e-01,  ..., -4.7902e-01,\n",
       "           -4.7665e-01, -4.5739e-01],\n",
       "          [-4.2316e-01, -4.5447e-01, -4.5871e-01,  ..., -4.8548e-01,\n",
       "           -4.7902e-01, -4.6146e-01],\n",
       "          [-4.2089e-01, -4.4947e-01, -4.5068e-01,  ..., -4.8049e-01,\n",
       "           -4.7536e-01, -4.5881e-01]],\n",
       "\n",
       "         [[ 6.4189e-01,  6.2875e-01,  6.4467e-01,  ...,  6.4755e-01,\n",
       "            6.3836e-01,  6.3703e-01],\n",
       "          [ 6.2553e-01,  6.1102e-01,  6.2870e-01,  ...,  6.2850e-01,\n",
       "            6.1741e-01,  6.1486e-01],\n",
       "          [ 6.0230e-01,  5.8321e-01,  6.0162e-01,  ...,  6.0467e-01,\n",
       "            5.9327e-01,  5.9117e-01],\n",
       "          ...,\n",
       "          [-1.6096e-01, -1.9932e-01, -2.1778e-01,  ..., -2.4271e-01,\n",
       "           -2.2768e-01, -2.0323e-01],\n",
       "          [-1.6991e-01, -2.0642e-01, -2.1816e-01,  ..., -2.4484e-01,\n",
       "           -2.2876e-01, -2.0825e-01],\n",
       "          [-1.7327e-01, -2.0621e-01, -2.1294e-01,  ..., -2.4238e-01,\n",
       "           -2.3099e-01, -2.1282e-01]],\n",
       "\n",
       "         [[ 9.7513e-01,  9.6342e-01,  9.7873e-01,  ...,  9.7539e-01,\n",
       "            9.6682e-01,  9.6260e-01],\n",
       "          [ 9.5807e-01,  9.4638e-01,  9.6334e-01,  ...,  9.5601e-01,\n",
       "            9.4597e-01,  9.3999e-01],\n",
       "          [ 9.2982e-01,  9.1410e-01,  9.3179e-01,  ...,  9.2859e-01,\n",
       "            9.1822e-01,  9.1206e-01],\n",
       "          ...,\n",
       "          [ 1.1769e-01,  7.7057e-02,  5.1246e-02,  ...,  2.6097e-02,\n",
       "            4.9756e-02,  7.6967e-02],\n",
       "          [ 1.0786e-01,  6.8860e-02,  4.9843e-02,  ...,  2.3780e-02,\n",
       "            4.6710e-02,  6.9909e-02],\n",
       "          [ 9.8463e-02,  6.2939e-02,  5.0325e-02,  ...,  2.3384e-02,\n",
       "            3.9922e-02,  6.0492e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 6.6706e-01,  6.5104e-01,  6.6553e-01,  ...,  6.6285e-01,\n",
       "            6.5740e-01,  6.4889e-01],\n",
       "          [ 6.4187e-01,  6.2499e-01,  6.3488e-01,  ...,  6.2971e-01,\n",
       "            6.1998e-01,  6.1160e-01],\n",
       "          [ 6.1710e-01,  5.9176e-01,  6.0238e-01,  ...,  5.8698e-01,\n",
       "            5.7470e-01,  5.7783e-01],\n",
       "          ...,\n",
       "          [ 1.8562e-01,  9.3676e-02,  2.2952e-02,  ...,  3.6861e-02,\n",
       "            8.9537e-02,  1.4587e-01],\n",
       "          [ 2.1954e-01,  1.5182e-01,  1.0677e-01,  ...,  1.1453e-01,\n",
       "            1.4474e-01,  1.8193e-01],\n",
       "          [ 2.6244e-01,  2.1319e-01,  1.9173e-01,  ...,  1.9829e-01,\n",
       "            2.1164e-01,  2.2590e-01]],\n",
       "\n",
       "         [[ 8.7574e-01,  8.5931e-01,  8.7383e-01,  ...,  8.7074e-01,\n",
       "            8.6572e-01,  8.5462e-01],\n",
       "          [ 8.4437e-01,  8.2806e-01,  8.3771e-01,  ...,  8.3258e-01,\n",
       "            8.2477e-01,  8.1385e-01],\n",
       "          [ 8.0914e-01,  7.8431e-01,  7.9490e-01,  ...,  7.7917e-01,\n",
       "            7.7015e-01,  7.7131e-01],\n",
       "          ...,\n",
       "          [ 1.6262e-01,  6.7238e-02, -2.9858e-03,  ...,  9.6147e-03,\n",
       "            6.4478e-02,  1.2557e-01],\n",
       "          [ 1.9679e-01,  1.2660e-01,  8.0896e-02,  ...,  8.9821e-02,\n",
       "            1.2209e-01,  1.6212e-01],\n",
       "          [ 2.4168e-01,  1.9001e-01,  1.6824e-01,  ...,  1.7499e-01,\n",
       "            1.9096e-01,  2.0724e-01]],\n",
       "\n",
       "         [[ 1.0614e+00,  1.0458e+00,  1.0595e+00,  ...,  1.0498e+00,\n",
       "            1.0483e+00,  1.0404e+00],\n",
       "          [ 1.0212e+00,  1.0073e+00,  1.0157e+00,  ...,  1.0069e+00,\n",
       "            1.0029e+00,  9.9455e-01],\n",
       "          [ 9.7604e-01,  9.5447e-01,  9.6410e-01,  ...,  9.4482e-01,\n",
       "            9.3961e-01,  9.4278e-01],\n",
       "          ...,\n",
       "          [ 1.7721e-01,  8.9616e-02,  2.6142e-02,  ...,  3.4939e-02,\n",
       "            8.4414e-02,  1.4089e-01],\n",
       "          [ 2.0941e-01,  1.4309e-01,  1.0131e-01,  ...,  1.0584e-01,\n",
       "            1.3613e-01,  1.7511e-01],\n",
       "          [ 2.5065e-01,  2.0083e-01,  1.7999e-01,  ...,  1.8371e-01,\n",
       "            2.0060e-01,  2.1902e-01]]]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the ClassMaximization class and create an instance of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_c = nn.parameter.Parameter(torch.randn(3,64,64))\n",
    "\n",
    "class ClassMaxim(nn.Module):\n",
    "    def __init__(self,num_class, centers=None, reso=32):\n",
    "        super(ClassMaxim, self).__init__()\n",
    "        self.x_c = nn.parameter.Parameter(torch.randn(num_class, 3, reso, reso))\n",
    "        if centers!=None:\n",
    "            self.x_c = nn.parameter.Parameter(centers.clone())    \n",
    "        self.clone = self.x_c.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "43274b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 32, 32])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "clsmax = ClassMaxim(num_class=10, centers=centers, reso=32)\n",
    "# clsmax = ClassMaxim(num_class=10, reso=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(clsmax.clone!=clsmax.x_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = get_training_parser()\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "epoch = 100\n",
    "lr = 0.1\n",
    "num_class=10\n",
    "\n",
    "loss_fn = CrossEntropyLoss(label_smoothing=args.smooth)\n",
    "opt = get_optimizer(args.optimizer)(clsmax.parameters(), lr=lr, weight_decay=args.weight_decay)#args.lr\n",
    "scheduler = get_scheduler(opt, args.scheduler, **args.__dict__)\n",
    "\n",
    "lamb = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n",
      "tensor([ 1.6624,  0.5677,  0.2245, -0.8091, -0.0145, -0.4719, -0.1604,  0.2799,\n",
      "         0.1038,  0.8313], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.6637,  0.5697,  0.2258, -0.8089, -0.0155, -0.4721, -0.1606,  0.2815,\n",
      "         0.1057,  0.8314], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.6651,  0.5705,  0.2255, -0.8088, -0.0170, -0.4727, -0.1603,  0.2803,\n",
      "         0.1041,  0.8316], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.6657,  0.5711,  0.2254, -0.8111, -0.0152, -0.4708, -0.1610,  0.2809,\n",
      "         0.1056,  0.8323], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.6671,  0.5687,  0.2264, -0.8107, -0.0154, -0.4732, -0.1602,  0.2804,\n",
      "         0.1039,  0.8328], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.6683,  0.5712,  0.2259, -0.8109, -0.0163, -0.4729, -0.1608,  0.2820,\n",
      "         0.1044,  0.8335], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.6694,  0.5714,  0.2265, -0.8122, -0.0157, -0.4731, -0.1613,  0.2807,\n",
      "         0.1047,  0.8342], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.6705,  0.5719,  0.2260, -0.8123, -0.0156, -0.4741, -0.1615,  0.2826,\n",
      "         0.1042,  0.8350], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.6719,  0.5718,  0.2261, -0.8123, -0.0153, -0.4729, -0.1611,  0.2808,\n",
      "         0.1049,  0.8346], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.6725,  0.5726,  0.2259, -0.8134, -0.0156, -0.4756, -0.1624,  0.2837,\n",
      "         0.1061,  0.8355], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.6739,  0.5729,  0.2275, -0.8129, -0.0165, -0.4742, -0.1604,  0.2814,\n",
      "         0.1048,  0.8365], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.6749,  0.5736,  0.2265, -0.8152, -0.0149, -0.4741, -0.1626,  0.2831,\n",
      "         0.1047,  0.8374], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.6764,  0.5725,  0.2276, -0.8146, -0.0165, -0.4763, -0.1611,  0.2816,\n",
      "         0.1041,  0.8373], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.6772,  0.5749,  0.2267, -0.8156, -0.0151, -0.4753, -0.1617,  0.2836,\n",
      "         0.1058,  0.8383], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.6786,  0.5744,  0.2274, -0.8160, -0.0163, -0.4758, -0.1615,  0.2813,\n",
      "         0.1038,  0.8388], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.6794,  0.5744,  0.2274, -0.8162, -0.0157, -0.4768, -0.1615,  0.2838,\n",
      "         0.1067,  0.8377], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.6814,  0.5754,  0.2275, -0.8160, -0.0169, -0.4761, -0.1614,  0.2829,\n",
      "         0.1046,  0.8396], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.6816,  0.5760,  0.2273, -0.8175, -0.0140, -0.4780, -0.1630,  0.2844,\n",
      "         0.1050,  0.8393], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.6835,  0.5760,  0.2277, -0.8190, -0.0161, -0.4766, -0.1619,  0.2830,\n",
      "         0.1044,  0.8407], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.6842,  0.5768,  0.2277, -0.8179, -0.0150, -0.4788, -0.1634,  0.2845,\n",
      "         0.1060,  0.8413], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.6851,  0.5771,  0.2266, -0.8201, -0.0150, -0.4766, -0.1632,  0.2831,\n",
      "         0.1037,  0.8419], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.6869,  0.5766,  0.2290, -0.8180, -0.0156, -0.4789, -0.1623,  0.2844,\n",
      "         0.1063,  0.8424], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.6875,  0.5796,  0.2276, -0.8214, -0.0159, -0.4784, -0.1629,  0.2836,\n",
      "         0.1046,  0.8423], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.6891,  0.5776,  0.2292, -0.8213, -0.0151, -0.4798, -0.1620,  0.2851,\n",
      "         0.1066,  0.8431], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.6897,  0.5796,  0.2278, -0.8216, -0.0154, -0.4783, -0.1632,  0.2841,\n",
      "         0.1049,  0.8440], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.6914,  0.5779,  0.2290, -0.8210, -0.0149, -0.4790, -0.1627,  0.2847,\n",
      "         0.1065,  0.8448], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.6922,  0.5807,  0.2277, -0.8229, -0.0166, -0.4804, -0.1639,  0.2855,\n",
      "         0.1052,  0.8449], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.6932,  0.5792,  0.2294, -0.8213, -0.0155, -0.4798, -0.1631,  0.2853,\n",
      "         0.1066,  0.8451], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.6945,  0.5814,  0.2279, -0.8246, -0.0165, -0.4805, -0.1630,  0.2844,\n",
      "         0.1052,  0.8456], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.6957,  0.5791,  0.2300, -0.8226, -0.0141, -0.4817, -0.1650,  0.2858,\n",
      "         0.1045,  0.8475], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.6966,  0.5824,  0.2287, -0.8268, -0.0158, -0.4813, -0.1629,  0.2856,\n",
      "         0.1059,  0.8470], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.6984,  0.5814,  0.2303, -0.8243, -0.0157, -0.4822, -0.1643,  0.2853,\n",
      "         0.1058,  0.8479], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.6988,  0.5824,  0.2283, -0.8265, -0.0150, -0.4809, -0.1636,  0.2870,\n",
      "         0.1068,  0.8486], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7007,  0.5824,  0.2307, -0.8257, -0.0168, -0.4822, -0.1631,  0.2860,\n",
      "         0.1067,  0.8486], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7014,  0.5844,  0.2292, -0.8274, -0.0153, -0.4827, -0.1652,  0.2862,\n",
      "         0.1050,  0.8491], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7027,  0.5827,  0.2308, -0.8270, -0.0165, -0.4830, -0.1627,  0.2871,\n",
      "         0.1054,  0.8498], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7036,  0.5849,  0.2299, -0.8273, -0.0143, -0.4825, -0.1659,  0.2867,\n",
      "         0.1052,  0.8510], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7051,  0.5843,  0.2308, -0.8291, -0.0166, -0.4839, -0.1631,  0.2862,\n",
      "         0.1052,  0.8513], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7055,  0.5846,  0.2304, -0.8294, -0.0147, -0.4838, -0.1659,  0.2880,\n",
      "         0.1066,  0.8519], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7074,  0.5854,  0.2308, -0.8301, -0.0152, -0.4849, -0.1650,  0.2871,\n",
      "         0.1054,  0.8524], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7082,  0.5851,  0.2317, -0.8300, -0.0155, -0.4841, -0.1651,  0.2878,\n",
      "         0.1069,  0.8523], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7093,  0.5850,  0.2308, -0.8300, -0.0159, -0.4860, -0.1645,  0.2868,\n",
      "         0.1060,  0.8530], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7107,  0.5854,  0.2316, -0.8310, -0.0147, -0.4856, -0.1658,  0.2881,\n",
      "         0.1074,  0.8532], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7117,  0.5865,  0.2311, -0.8302, -0.0173, -0.4861, -0.1647,  0.2873,\n",
      "         0.1055,  0.8540], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7126,  0.5878,  0.2309, -0.8332, -0.0146, -0.4866, -0.1667,  0.2896,\n",
      "         0.1064,  0.8552], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7141,  0.5857,  0.2307, -0.8320, -0.0158, -0.4870, -0.1643,  0.2887,\n",
      "         0.1068,  0.8544], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7148,  0.5895,  0.2317, -0.8345, -0.0153, -0.4865, -0.1676,  0.2883,\n",
      "         0.1056,  0.8571], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7161,  0.5868,  0.2302, -0.8330, -0.0160, -0.4881, -0.1640,  0.2893,\n",
      "         0.1076,  0.8556], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7174,  0.5898,  0.2319, -0.8351, -0.0154, -0.4860, -0.1657,  0.2884,\n",
      "         0.1061,  0.8571], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7186,  0.5880,  0.2318, -0.8339, -0.0163, -0.4893, -0.1647,  0.2896,\n",
      "         0.1080,  0.8567], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7194,  0.5901,  0.2313, -0.8354, -0.0169, -0.4867, -0.1659,  0.2893,\n",
      "         0.1059,  0.8585], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7207,  0.5877,  0.2323, -0.8351, -0.0156, -0.4884, -0.1660,  0.2893,\n",
      "         0.1077,  0.8585], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7219,  0.5906,  0.2320, -0.8361, -0.0157, -0.4891, -0.1670,  0.2901,\n",
      "         0.1054,  0.8599], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7224,  0.5893,  0.2319, -0.8358, -0.0148, -0.4886, -0.1656,  0.2898,\n",
      "         0.1073,  0.8594], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7243,  0.5909,  0.2334, -0.8369, -0.0171, -0.4896, -0.1669,  0.2899,\n",
      "         0.1059,  0.8605], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7250,  0.5912,  0.2330, -0.8373, -0.0161, -0.4894, -0.1657,  0.2907,\n",
      "         0.1076,  0.8600], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7266,  0.5922,  0.2326, -0.8378, -0.0158, -0.4890, -0.1670,  0.2895,\n",
      "         0.1052,  0.8615], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7272,  0.5910,  0.2327, -0.8378, -0.0159, -0.4911, -0.1667,  0.2912,\n",
      "         0.1087,  0.8606], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7287,  0.5929,  0.2325, -0.8393, -0.0152, -0.4897, -0.1669,  0.2896,\n",
      "         0.1052,  0.8621], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7298,  0.5915,  0.2332, -0.8392, -0.0156, -0.4915, -0.1667,  0.2912,\n",
      "         0.1079,  0.8628], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7307,  0.5942,  0.2322, -0.8415, -0.0154, -0.4911, -0.1677,  0.2911,\n",
      "         0.1052,  0.8635], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7323,  0.5932,  0.2337, -0.8399, -0.0158, -0.4918, -0.1672,  0.2905,\n",
      "         0.1075,  0.8636], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7330,  0.5955,  0.2336, -0.8421, -0.0160, -0.4922, -0.1675,  0.2923,\n",
      "         0.1069,  0.8644], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7347,  0.5934,  0.2340, -0.8406, -0.0164, -0.4918, -0.1676,  0.2911,\n",
      "         0.1081,  0.8651], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7352,  0.5961,  0.2336, -0.8442, -0.0156, -0.4921, -0.1669,  0.2936,\n",
      "         0.1080,  0.8644], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7367,  0.5946,  0.2347, -0.8418, -0.0162, -0.4932, -0.1676,  0.2913,\n",
      "         0.1075,  0.8661], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7376,  0.5965,  0.2340, -0.8446, -0.0151, -0.4930, -0.1682,  0.2934,\n",
      "         0.1066,  0.8659], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7390,  0.5946,  0.2347, -0.8432, -0.0157, -0.4946, -0.1680,  0.2917,\n",
      "         0.1076,  0.8673], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7402,  0.5981,  0.2355, -0.8457, -0.0152, -0.4927, -0.1678,  0.2931,\n",
      "         0.1071,  0.8679], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7413,  0.5962,  0.2339, -0.8441, -0.0166, -0.4944, -0.1684,  0.2929,\n",
      "         0.1084,  0.8684], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7420,  0.5989,  0.2352, -0.8480, -0.0132, -0.4930, -0.1691,  0.2935,\n",
      "         0.1074,  0.8692], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7438,  0.5964,  0.2345, -0.8459, -0.0172, -0.4959, -0.1677,  0.2928,\n",
      "         0.1084,  0.8690], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7445,  0.6009,  0.2358, -0.8475, -0.0146, -0.4949, -0.1700,  0.2935,\n",
      "         0.1070,  0.8710], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7462,  0.5977,  0.2345, -0.8468, -0.0166, -0.4958, -0.1679,  0.2930,\n",
      "         0.1083,  0.8705], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7472,  0.6010,  0.2362, -0.8488, -0.0149, -0.4964, -0.1693,  0.2948,\n",
      "         0.1063,  0.8710], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7482,  0.5978,  0.2349, -0.8483, -0.0177, -0.4968, -0.1687,  0.2944,\n",
      "         0.1089,  0.8713], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7495,  0.6014,  0.2357, -0.8511, -0.0140, -0.4959, -0.1695,  0.2943,\n",
      "         0.1060,  0.8722], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7506,  0.5994,  0.2355, -0.8499, -0.0166, -0.4993, -0.1697,  0.2957,\n",
      "         0.1103,  0.8722], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7517,  0.6026,  0.2354, -0.8517, -0.0149, -0.4965, -0.1688,  0.2945,\n",
      "         0.1085,  0.8728], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7528,  0.6009,  0.2366, -0.8504, -0.0172, -0.4983, -0.1698,  0.2947,\n",
      "         0.1094,  0.8735], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7538,  0.6033,  0.2368, -0.8531, -0.0152, -0.4973, -0.1701,  0.2960,\n",
      "         0.1071,  0.8743], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7556,  0.6019,  0.2361, -0.8521, -0.0166, -0.4997, -0.1692,  0.2956,\n",
      "         0.1099,  0.8747], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7561,  0.6040,  0.2364, -0.8521, -0.0144, -0.4979, -0.1705,  0.2955,\n",
      "         0.1070,  0.8761], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7576,  0.6032,  0.2362, -0.8528, -0.0160, -0.5001, -0.1702,  0.2955,\n",
      "         0.1095,  0.8762], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7588,  0.6047,  0.2374, -0.8547, -0.0147, -0.4991, -0.1702,  0.2958,\n",
      "         0.1073,  0.8769], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7595,  0.6032,  0.2374, -0.8527, -0.0168, -0.4996, -0.1709,  0.2953,\n",
      "         0.1083,  0.8774], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7611,  0.6054,  0.2373, -0.8559, -0.0144, -0.5008, -0.1708,  0.2968,\n",
      "         0.1083,  0.8775], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7618,  0.6042,  0.2386, -0.8546, -0.0168, -0.5006, -0.1709,  0.2964,\n",
      "         0.1095,  0.8782], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7633,  0.6049,  0.2378, -0.8560, -0.0145, -0.5013, -0.1719,  0.2966,\n",
      "         0.1079,  0.8792], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7646,  0.6049,  0.2383, -0.8554, -0.0152, -0.5008, -0.1708,  0.2965,\n",
      "         0.1096,  0.8791], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7655,  0.6070,  0.2375, -0.8578, -0.0159, -0.5030, -0.1722,  0.2978,\n",
      "         0.1078,  0.8797], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7668,  0.6051,  0.2385, -0.8569, -0.0164, -0.5015, -0.1706,  0.2975,\n",
      "         0.1088,  0.8796], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7676,  0.6081,  0.2374, -0.8575, -0.0148, -0.5028, -0.1720,  0.2971,\n",
      "         0.1079,  0.8814], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7691,  0.6061,  0.2388, -0.8588, -0.0175, -0.5032, -0.1708,  0.2981,\n",
      "         0.1102,  0.8813], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7697,  0.6081,  0.2370, -0.8593, -0.0155, -0.5022, -0.1713,  0.2971,\n",
      "         0.1085,  0.8816], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7714,  0.6074,  0.2391, -0.8586, -0.0159, -0.5035, -0.1714,  0.2976,\n",
      "         0.1098,  0.8837], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7721,  0.6083,  0.2373, -0.8604, -0.0162, -0.5034, -0.1703,  0.2979,\n",
      "         0.1094,  0.8813], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7741,  0.6088,  0.2393, -0.8594, -0.0155, -0.5047, -0.1710,  0.2983,\n",
      "         0.1096,  0.8838], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7746,  0.6100,  0.2376, -0.8616, -0.0167, -0.5038, -0.1715,  0.2985,\n",
      "         0.1090,  0.8835], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7764,  0.6097,  0.2393, -0.8610, -0.0156, -0.5060, -0.1714,  0.2988,\n",
      "         0.1097,  0.8847], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7772,  0.6099,  0.2381, -0.8623, -0.0160, -0.5049, -0.1716,  0.2984,\n",
      "         0.1095,  0.8849], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7789,  0.6112,  0.2394, -0.8614, -0.0159, -0.5063, -0.1721,  0.2993,\n",
      "         0.1096,  0.8858], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7792,  0.6101,  0.2386, -0.8639, -0.0156, -0.5056, -0.1708,  0.3000,\n",
      "         0.1102,  0.8850], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7811,  0.6115,  0.2395, -0.8620, -0.0157, -0.5069, -0.1733,  0.2989,\n",
      "         0.1086,  0.8873], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7815,  0.6093,  0.2394, -0.8637, -0.0151, -0.5075, -0.1712,  0.2997,\n",
      "         0.1098,  0.8870], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7834,  0.6144,  0.2411, -0.8636, -0.0159, -0.5056, -0.1733,  0.2982,\n",
      "         0.1099,  0.8884], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7838,  0.6121,  0.2397, -0.8658, -0.0151, -0.5075, -0.1714,  0.3002,\n",
      "         0.1107,  0.8881], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7852,  0.6139,  0.2411, -0.8645, -0.0156, -0.5071, -0.1734,  0.2995,\n",
      "         0.1100,  0.8893], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7862,  0.6133,  0.2402, -0.8664, -0.0144, -0.5080, -0.1728,  0.3001,\n",
      "         0.1091,  0.8898], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7876,  0.6137,  0.2411, -0.8659, -0.0157, -0.5076, -0.1735,  0.2988,\n",
      "         0.1097,  0.8899], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7885,  0.6149,  0.2422, -0.8672, -0.0156, -0.5096, -0.1732,  0.3008,\n",
      "         0.1094,  0.8903], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7900,  0.6147,  0.2410, -0.8671, -0.0163, -0.5091, -0.1733,  0.3004,\n",
      "         0.1094,  0.8913], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7910,  0.6156,  0.2425, -0.8687, -0.0144, -0.5090, -0.1739,  0.3012,\n",
      "         0.1094,  0.8923], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7922,  0.6159,  0.2412, -0.8700, -0.0170, -0.5091, -0.1738,  0.3015,\n",
      "         0.1099,  0.8932], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7934,  0.6160,  0.2425, -0.8686, -0.0138, -0.5097, -0.1741,  0.3021,\n",
      "         0.1095,  0.8933], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7947,  0.6164,  0.2417, -0.8708, -0.0173, -0.5098, -0.1729,  0.3012,\n",
      "         0.1099,  0.8936], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7956,  0.6173,  0.2430, -0.8702, -0.0141, -0.5108, -0.1744,  0.3017,\n",
      "         0.1106,  0.8943], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7971,  0.6171,  0.2413, -0.8705, -0.0175, -0.5108, -0.1738,  0.3016,\n",
      "         0.1098,  0.8947], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7980,  0.6179,  0.2427, -0.8711, -0.0139, -0.5115, -0.1754,  0.3032,\n",
      "         0.1102,  0.8966], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.7993,  0.6175,  0.2417, -0.8719, -0.0172, -0.5112, -0.1747,  0.3020,\n",
      "         0.1101,  0.8958], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8002,  0.6190,  0.2424, -0.8727, -0.0144, -0.5118, -0.1745,  0.3032,\n",
      "         0.1111,  0.8966], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8021,  0.6195,  0.2422, -0.8735, -0.0175, -0.5124, -0.1748,  0.3030,\n",
      "         0.1098,  0.8973], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8020,  0.6200,  0.2429, -0.8748, -0.0140, -0.5108, -0.1743,  0.3025,\n",
      "         0.1097,  0.8984], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8045,  0.6209,  0.2421, -0.8744, -0.0168, -0.5132, -0.1748,  0.3036,\n",
      "         0.1111,  0.8976], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8048,  0.6200,  0.2438, -0.8745, -0.0152, -0.5134, -0.1754,  0.3020,\n",
      "         0.1104,  0.8984], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8065,  0.6228,  0.2424, -0.8758, -0.0174, -0.5144, -0.1757,  0.3041,\n",
      "         0.1108,  0.8992], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8074,  0.6206,  0.2445, -0.8753, -0.0149, -0.5137, -0.1747,  0.3037,\n",
      "         0.1103,  0.8998], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8087,  0.6229,  0.2429, -0.8770, -0.0179, -0.5156, -0.1749,  0.3046,\n",
      "         0.1097,  0.8997], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8096,  0.6212,  0.2440, -0.8759, -0.0137, -0.5148, -0.1759,  0.3043,\n",
      "         0.1114,  0.9008], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8109,  0.6233,  0.2437, -0.8793, -0.0169, -0.5149, -0.1739,  0.3037,\n",
      "         0.1101,  0.9006], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8122,  0.6219,  0.2444, -0.8762, -0.0152, -0.5161, -0.1763,  0.3049,\n",
      "         0.1114,  0.9017], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8126,  0.6243,  0.2435, -0.8809, -0.0151, -0.5146, -0.1757,  0.3041,\n",
      "         0.1087,  0.9025], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8146,  0.6227,  0.2442, -0.8792, -0.0155, -0.5176, -0.1752,  0.3053,\n",
      "         0.1123,  0.9024], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8155,  0.6248,  0.2448, -0.8789, -0.0153, -0.5161, -0.1760,  0.3042,\n",
      "         0.1095,  0.9034], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8165,  0.6245,  0.2445, -0.8799, -0.0160, -0.5182, -0.1758,  0.3058,\n",
      "         0.1117,  0.9042], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8178,  0.6256,  0.2447, -0.8811, -0.0156, -0.5169, -0.1769,  0.3049,\n",
      "         0.1097,  0.9045], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8189,  0.6248,  0.2450, -0.8800, -0.0162, -0.5188, -0.1757,  0.3049,\n",
      "         0.1109,  0.9057], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8198,  0.6276,  0.2459, -0.8833, -0.0166, -0.5174, -0.1763,  0.3052,\n",
      "         0.1097,  0.9060], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8213,  0.6246,  0.2453, -0.8817, -0.0151, -0.5190, -0.1758,  0.3063,\n",
      "         0.1124,  0.9059], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8223,  0.6278,  0.2456, -0.8828, -0.0153, -0.5190, -0.1780,  0.3048,\n",
      "         0.1083,  0.9076], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8236,  0.6255,  0.2461, -0.8821, -0.0157, -0.5200, -0.1762,  0.3068,\n",
      "         0.1124,  0.9074], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8247,  0.6291,  0.2454, -0.8832, -0.0169, -0.5175, -0.1762,  0.3049,\n",
      "         0.1101,  0.9078], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8259,  0.6274,  0.2469, -0.8834, -0.0150, -0.5215, -0.1773,  0.3059,\n",
      "         0.1117,  0.9089], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8270,  0.6296,  0.2456, -0.8853, -0.0161, -0.5183, -0.1764,  0.3068,\n",
      "         0.1102,  0.9092], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8285,  0.6278,  0.2468, -0.8837, -0.0144, -0.5207, -0.1773,  0.3067,\n",
      "         0.1114,  0.9105], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8293,  0.6309,  0.2457, -0.8868, -0.0166, -0.5203, -0.1768,  0.3069,\n",
      "         0.1109,  0.9099], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8307,  0.6294,  0.2472, -0.8846, -0.0153, -0.5234, -0.1769,  0.3076,\n",
      "         0.1109,  0.9112], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8317,  0.6311,  0.2458, -0.8877, -0.0157, -0.5205, -0.1770,  0.3074,\n",
      "         0.1107,  0.9104], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8333,  0.6301,  0.2473, -0.8865, -0.0152, -0.5228, -0.1782,  0.3076,\n",
      "         0.1116,  0.9131], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8341,  0.6309,  0.2464, -0.8883, -0.0148, -0.5220, -0.1779,  0.3088,\n",
      "         0.1108,  0.9115], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8354,  0.6320,  0.2481, -0.8881, -0.0150, -0.5238, -0.1784,  0.3079,\n",
      "         0.1125,  0.9144], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8368,  0.6322,  0.2458, -0.8883, -0.0159, -0.5223, -0.1778,  0.3086,\n",
      "         0.1106,  0.9133], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8376,  0.6325,  0.2485, -0.8898, -0.0148, -0.5233, -0.1785,  0.3095,\n",
      "         0.1122,  0.9145], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8388,  0.6323,  0.2454, -0.8896, -0.0173, -0.5243, -0.1770,  0.3090,\n",
      "         0.1119,  0.9137], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8401,  0.6340,  0.2476, -0.8896, -0.0143, -0.5244, -0.1794,  0.3096,\n",
      "         0.1118,  0.9161], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8411,  0.6336,  0.2461, -0.8910, -0.0172, -0.5244, -0.1773,  0.3079,\n",
      "         0.1114,  0.9155], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8423,  0.6359,  0.2481, -0.8909, -0.0137, -0.5254, -0.1797,  0.3101,\n",
      "         0.1118,  0.9175], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8435,  0.6349,  0.2460, -0.8930, -0.0167, -0.5248, -0.1773,  0.3092,\n",
      "         0.1119,  0.9164], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8445,  0.6355,  0.2483, -0.8922, -0.0134, -0.5268, -0.1802,  0.3108,\n",
      "         0.1111,  0.9188], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8458,  0.6354,  0.2471, -0.8935, -0.0162, -0.5243, -0.1770,  0.3091,\n",
      "         0.1117,  0.9181], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8469,  0.6362,  0.2486, -0.8941, -0.0139, -0.5273, -0.1801,  0.3102,\n",
      "         0.1110,  0.9197], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8482,  0.6364,  0.2483, -0.8950, -0.0167, -0.5258, -0.1778,  0.3096,\n",
      "         0.1118,  0.9199], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8490,  0.6369,  0.2493, -0.8956, -0.0139, -0.5283, -0.1792,  0.3108,\n",
      "         0.1112,  0.9202], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8504,  0.6367,  0.2491, -0.8940, -0.0164, -0.5266, -0.1798,  0.3089,\n",
      "         0.1120,  0.9208], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8517,  0.6385,  0.2492, -0.8971, -0.0143, -0.5284, -0.1802,  0.3112,\n",
      "         0.1112,  0.9212], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8528,  0.6371,  0.2485, -0.8948, -0.0169, -0.5278, -0.1798,  0.3101,\n",
      "         0.1128,  0.9217], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8539,  0.6399,  0.2493, -0.8981, -0.0141, -0.5278, -0.1802,  0.3109,\n",
      "         0.1109,  0.9224], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8552,  0.6383,  0.2491, -0.8980, -0.0160, -0.5284, -0.1794,  0.3112,\n",
      "         0.1134,  0.9233], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8560,  0.6417,  0.2489, -0.9004, -0.0149, -0.5281, -0.1808,  0.3118,\n",
      "         0.1108,  0.9232], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8577,  0.6384,  0.2487, -0.8980, -0.0159, -0.5299, -0.1805,  0.3115,\n",
      "         0.1127,  0.9245], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8584,  0.6427,  0.2499, -0.9015, -0.0153, -0.5292, -0.1801,  0.3125,\n",
      "         0.1122,  0.9248], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8604,  0.6399,  0.2500, -0.8991, -0.0163, -0.5316, -0.1807,  0.3124,\n",
      "         0.1124,  0.9247], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8611,  0.6429,  0.2494, -0.9029, -0.0159, -0.5294, -0.1798,  0.3123,\n",
      "         0.1126,  0.9253], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8625,  0.6405,  0.2499, -0.8997, -0.0144, -0.5305, -0.1809,  0.3121,\n",
      "         0.1121,  0.9271], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8635,  0.6429,  0.2506, -0.9030, -0.0158, -0.5319, -0.1807,  0.3137,\n",
      "         0.1125,  0.9270], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8647,  0.6418,  0.2513, -0.9012, -0.0150, -0.5315, -0.1803,  0.3122,\n",
      "         0.1145,  0.9278], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8658,  0.6434,  0.2508, -0.9032, -0.0158, -0.5325, -0.1811,  0.3134,\n",
      "         0.1124,  0.9274], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8671,  0.6419,  0.2511, -0.9026, -0.0154, -0.5321, -0.1808,  0.3140,\n",
      "         0.1137,  0.9283], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8681,  0.6448,  0.2510, -0.9046, -0.0159, -0.5336, -0.1823,  0.3133,\n",
      "         0.1111,  0.9287], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8695,  0.6433,  0.2514, -0.9038, -0.0155, -0.5320, -0.1814,  0.3139,\n",
      "         0.1134,  0.9294], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8705,  0.6454,  0.2520, -0.9049, -0.0159, -0.5345, -0.1825,  0.3142,\n",
      "         0.1125,  0.9292], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8718,  0.6437,  0.2521, -0.9038, -0.0159, -0.5325, -0.1810,  0.3128,\n",
      "         0.1127,  0.9309], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8725,  0.6462,  0.2522, -0.9069, -0.0153, -0.5335, -0.1825,  0.3150,\n",
      "         0.1125,  0.9314], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8741,  0.6457,  0.2524, -0.9046, -0.0164, -0.5338, -0.1809,  0.3131,\n",
      "         0.1121,  0.9314], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8754,  0.6473,  0.2521, -0.9067, -0.0155, -0.5356, -0.1830,  0.3150,\n",
      "         0.1128,  0.9318], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8764,  0.6463,  0.2531, -0.9054, -0.0165, -0.5348, -0.1819,  0.3144,\n",
      "         0.1123,  0.9336], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8774,  0.6479,  0.2511, -0.9088, -0.0159, -0.5348, -0.1826,  0.3148,\n",
      "         0.1129,  0.9337], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8787,  0.6475,  0.2525, -0.9076, -0.0172, -0.5356, -0.1824,  0.3148,\n",
      "         0.1134,  0.9343], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8798,  0.6485,  0.2516, -0.9107, -0.0147, -0.5338, -0.1824,  0.3154,\n",
      "         0.1131,  0.9350], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8812,  0.6474,  0.2522, -0.9088, -0.0170, -0.5369, -0.1818,  0.3155,\n",
      "         0.1133,  0.9356], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8819,  0.6499,  0.2527, -0.9122, -0.0150, -0.5356, -0.1820,  0.3156,\n",
      "         0.1130,  0.9356], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8835,  0.6485,  0.2525, -0.9107, -0.0169, -0.5364, -0.1825,  0.3155,\n",
      "         0.1136,  0.9367], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8842,  0.6517,  0.2533, -0.9125, -0.0140, -0.5371, -0.1840,  0.3161,\n",
      "         0.1125,  0.9375], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8860,  0.6497,  0.2525, -0.9122, -0.0173, -0.5384, -0.1821,  0.3165,\n",
      "         0.1138,  0.9377], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8862,  0.6519,  0.2535, -0.9129, -0.0139, -0.5383, -0.1851,  0.3174,\n",
      "         0.1122,  0.9385], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8881,  0.6503,  0.2527, -0.9133, -0.0166, -0.5394, -0.1822,  0.3166,\n",
      "         0.1135,  0.9380], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8890,  0.6530,  0.2534, -0.9137, -0.0157, -0.5374, -0.1844,  0.3170,\n",
      "         0.1131,  0.9392], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8903,  0.6514,  0.2534, -0.9131, -0.0169, -0.5397, -0.1828,  0.3163,\n",
      "         0.1132,  0.9396], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8912,  0.6529,  0.2544, -0.9139, -0.0147, -0.5384, -0.1844,  0.3166,\n",
      "         0.1143,  0.9401], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8926,  0.6529,  0.2530, -0.9149, -0.0173, -0.5405, -0.1828,  0.3167,\n",
      "         0.1130,  0.9405], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8936,  0.6518,  0.2540, -0.9154, -0.0142, -0.5381, -0.1842,  0.3177,\n",
      "         0.1142,  0.9417], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8947,  0.6534,  0.2545, -0.9154, -0.0163, -0.5415, -0.1831,  0.3172,\n",
      "         0.1130,  0.9417], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8960,  0.6529,  0.2545, -0.9163, -0.0145, -0.5396, -0.1845,  0.3178,\n",
      "         0.1148,  0.9424], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8968,  0.6543,  0.2553, -0.9171, -0.0158, -0.5405, -0.1837,  0.3175,\n",
      "         0.1132,  0.9428], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8987,  0.6551,  0.2557, -0.9168, -0.0148, -0.5425, -0.1850,  0.3173,\n",
      "         0.1138,  0.9438], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.8992,  0.6556,  0.2560, -0.9195, -0.0151, -0.5405, -0.1839,  0.3176,\n",
      "         0.1135,  0.9432], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9009,  0.6557,  0.2551, -0.9173, -0.0150, -0.5424, -0.1855,  0.3188,\n",
      "         0.1140,  0.9448], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9018,  0.6569,  0.2563, -0.9187, -0.0161, -0.5428, -0.1841,  0.3184,\n",
      "         0.1136,  0.9445], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9030,  0.6570,  0.2553, -0.9197, -0.0150, -0.5432, -0.1850,  0.3194,\n",
      "         0.1140,  0.9458], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9043,  0.6569,  0.2560, -0.9199, -0.0145, -0.5442, -0.1854,  0.3192,\n",
      "         0.1132,  0.9457], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9055,  0.6584,  0.2567, -0.9223, -0.0170, -0.5427, -0.1852,  0.3194,\n",
      "         0.1135,  0.9471], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9069,  0.6568,  0.2565, -0.9205, -0.0150, -0.5441, -0.1844,  0.3195,\n",
      "         0.1139,  0.9465], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9079,  0.6587,  0.2566, -0.9221, -0.0162, -0.5436, -0.1853,  0.3197,\n",
      "         0.1136,  0.9487], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9092,  0.6579,  0.2562, -0.9216, -0.0164, -0.5453, -0.1840,  0.3208,\n",
      "         0.1139,  0.9475], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9098,  0.6606,  0.2555, -0.9243, -0.0155, -0.5442, -0.1857,  0.3207,\n",
      "         0.1140,  0.9506], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9117,  0.6581,  0.2562, -0.9238, -0.0158, -0.5463, -0.1849,  0.3197,\n",
      "         0.1139,  0.9492], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9121,  0.6607,  0.2564, -0.9250, -0.0142, -0.5441, -0.1859,  0.3202,\n",
      "         0.1149,  0.9504], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9137,  0.6593,  0.2560, -0.9247, -0.0174, -0.5477, -0.1848,  0.3200,\n",
      "         0.1139,  0.9499], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9145,  0.6609,  0.2570, -0.9256, -0.0133, -0.5447, -0.1877,  0.3209,\n",
      "         0.1143,  0.9514], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9161,  0.6605,  0.2561, -0.9257, -0.0173, -0.5473, -0.1844,  0.3203,\n",
      "         0.1148,  0.9523], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9171,  0.6627,  0.2570, -0.9266, -0.0138, -0.5469, -0.1873,  0.3214,\n",
      "         0.1152,  0.9523], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9183,  0.6621,  0.2570, -0.9267, -0.0175, -0.5488, -0.1857,  0.3210,\n",
      "         0.1136,  0.9532], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9195,  0.6635,  0.2576, -0.9275, -0.0137, -0.5472, -0.1872,  0.3218,\n",
      "         0.1145,  0.9540], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9203,  0.6625,  0.2563, -0.9276, -0.0169, -0.5495, -0.1857,  0.3213,\n",
      "         0.1143,  0.9529], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9219,  0.6646,  0.2576, -0.9292, -0.0142, -0.5486, -0.1877,  0.3230,\n",
      "         0.1151,  0.9554], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9228,  0.6640,  0.2579, -0.9292, -0.0172, -0.5499, -0.1861,  0.3213,\n",
      "         0.1155,  0.9553], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9240,  0.6656,  0.2572, -0.9306, -0.0140, -0.5485, -0.1875,  0.3214,\n",
      "         0.1146,  0.9557], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9252,  0.6641,  0.2584, -0.9311, -0.0167, -0.5499, -0.1870,  0.3223,\n",
      "         0.1153,  0.9559], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9263,  0.6668,  0.2580, -0.9312, -0.0140, -0.5507, -0.1882,  0.3224,\n",
      "         0.1141,  0.9578], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9276,  0.6647,  0.2585, -0.9312, -0.0164, -0.5497, -0.1866,  0.3224,\n",
      "         0.1158,  0.9574], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9289,  0.6675,  0.2583, -0.9329, -0.0153, -0.5521, -0.1888,  0.3229,\n",
      "         0.1139,  0.9579], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9300,  0.6667,  0.2590, -0.9322, -0.0172, -0.5503, -0.1869,  0.3230,\n",
      "         0.1154,  0.9581], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9312,  0.6668,  0.2583, -0.9337, -0.0145, -0.5521, -0.1888,  0.3237,\n",
      "         0.1134,  0.9587], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9321,  0.6674,  0.2588, -0.9343, -0.0158, -0.5503, -0.1875,  0.3226,\n",
      "         0.1156,  0.9605], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9336,  0.6679,  0.2592, -0.9349, -0.0156, -0.5529, -0.1887,  0.3235,\n",
      "         0.1145,  0.9595], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9345,  0.6673,  0.2595, -0.9349, -0.0154, -0.5523, -0.1881,  0.3236,\n",
      "         0.1163,  0.9611], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9358,  0.6686,  0.2597, -0.9357, -0.0154, -0.5531, -0.1892,  0.3245,\n",
      "         0.1140,  0.9611], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9371,  0.6689,  0.2596, -0.9361, -0.0148, -0.5526, -0.1895,  0.3232,\n",
      "         0.1150,  0.9623], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9382,  0.6691,  0.2603, -0.9374, -0.0156, -0.5536, -0.1885,  0.3251,\n",
      "         0.1152,  0.9614], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9394,  0.6700,  0.2599, -0.9359, -0.0162, -0.5548, -0.1895,  0.3247,\n",
      "         0.1154,  0.9636], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9407,  0.6702,  0.2604, -0.9384, -0.0151, -0.5539, -0.1887,  0.3256,\n",
      "         0.1157,  0.9638], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9416,  0.6698,  0.2600, -0.9370, -0.0168, -0.5554, -0.1885,  0.3252,\n",
      "         0.1162,  0.9646], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9429,  0.6712,  0.2608, -0.9391, -0.0146, -0.5542, -0.1899,  0.3250,\n",
      "         0.1145,  0.9655], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9438,  0.6705,  0.2607, -0.9385, -0.0167, -0.5560, -0.1889,  0.3250,\n",
      "         0.1159,  0.9652], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9449,  0.6727,  0.2607, -0.9416, -0.0151, -0.5543, -0.1899,  0.3248,\n",
      "         0.1138,  0.9664], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9461,  0.6716,  0.2613, -0.9394, -0.0165, -0.5579, -0.1893,  0.3270,\n",
      "         0.1170,  0.9663], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9473,  0.6742,  0.2606, -0.9409, -0.0152, -0.5542, -0.1889,  0.3246,\n",
      "         0.1149,  0.9670], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9487,  0.6718,  0.2618, -0.9408, -0.0164, -0.5584, -0.1895,  0.3262,\n",
      "         0.1178,  0.9675], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9495,  0.6740,  0.2609, -0.9417, -0.0162, -0.5553, -0.1888,  0.3246,\n",
      "         0.1148,  0.9679], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9510,  0.6728,  0.2620, -0.9416, -0.0145, -0.5583, -0.1903,  0.3272,\n",
      "         0.1182,  0.9696], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9521,  0.6754,  0.2617, -0.9434, -0.0170, -0.5574, -0.1907,  0.3265,\n",
      "         0.1137,  0.9691], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9534,  0.6735,  0.2619, -0.9424, -0.0152, -0.5592, -0.1895,  0.3273,\n",
      "         0.1167,  0.9697], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9546,  0.6770,  0.2624, -0.9451, -0.0162, -0.5578, -0.1907,  0.3266,\n",
      "         0.1140,  0.9708], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9554,  0.6756,  0.2623, -0.9440, -0.0145, -0.5593, -0.1904,  0.3267,\n",
      "         0.1168,  0.9720], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9571,  0.6766,  0.2616, -0.9456, -0.0165, -0.5578, -0.1899,  0.3275,\n",
      "         0.1138,  0.9713], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9578,  0.6750,  0.2632, -0.9449, -0.0153, -0.5602, -0.1904,  0.3290,\n",
      "         0.1178,  0.9725], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9591,  0.6774,  0.2630, -0.9458, -0.0165, -0.5603, -0.1902,  0.3266,\n",
      "         0.1148,  0.9724], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9603,  0.6765,  0.2638, -0.9457, -0.0142, -0.5605, -0.1909,  0.3285,\n",
      "         0.1177,  0.9737], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9614,  0.6779,  0.2623, -0.9467, -0.0165, -0.5605, -0.1906,  0.3274,\n",
      "         0.1149,  0.9741], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9627,  0.6779,  0.2634, -0.9472, -0.0138, -0.5604, -0.1921,  0.3294,\n",
      "         0.1164,  0.9749], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9638,  0.6781,  0.2633, -0.9470, -0.0156, -0.5606, -0.1908,  0.3272,\n",
      "         0.1150,  0.9747], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9648,  0.6805,  0.2634, -0.9481, -0.0141, -0.5610, -0.1929,  0.3290,\n",
      "         0.1164,  0.9767], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9663,  0.6783,  0.2634, -0.9485, -0.0161, -0.5627, -0.1911,  0.3285,\n",
      "         0.1161,  0.9756], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9672,  0.6819,  0.2645, -0.9501, -0.0157, -0.5609, -0.1928,  0.3291,\n",
      "         0.1155,  0.9778], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9684,  0.6790,  0.2633, -0.9491, -0.0167, -0.5641, -0.1907,  0.3287,\n",
      "         0.1165,  0.9764], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9694,  0.6826,  0.2643, -0.9521, -0.0136, -0.5623, -0.1927,  0.3283,\n",
      "         0.1156,  0.9786], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9710,  0.6807,  0.2638, -0.9508, -0.0173, -0.5637, -0.1911,  0.3294,\n",
      "         0.1168,  0.9788], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9719,  0.6832,  0.2659, -0.9535, -0.0149, -0.5638, -0.1926,  0.3307,\n",
      "         0.1151,  0.9790], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9732,  0.6811,  0.2632, -0.9527, -0.0164, -0.5644, -0.1911,  0.3303,\n",
      "         0.1174,  0.9784], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9742,  0.6822,  0.2646, -0.9525, -0.0139, -0.5645, -0.1938,  0.3299,\n",
      "         0.1155,  0.9809], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9756,  0.6829,  0.2640, -0.9546, -0.0156, -0.5653, -0.1913,  0.3299,\n",
      "         0.1172,  0.9798], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9767,  0.6831,  0.2645, -0.9529, -0.0131, -0.5649, -0.1941,  0.3301,\n",
      "         0.1155,  0.9823], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9778,  0.6829,  0.2652, -0.9553, -0.0167, -0.5654, -0.1913,  0.3297,\n",
      "         0.1171,  0.9810], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9794,  0.6851,  0.2655, -0.9548, -0.0141, -0.5665, -0.1940,  0.3307,\n",
      "         0.1164,  0.9825], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9800,  0.6843,  0.2651, -0.9559, -0.0149, -0.5652, -0.1923,  0.3303,\n",
      "         0.1164,  0.9826], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9819,  0.6850,  0.2659, -0.9556, -0.0147, -0.5675, -0.1939,  0.3327,\n",
      "         0.1179,  0.9840], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9825,  0.6863,  0.2661, -0.9571, -0.0164, -0.5657, -0.1917,  0.3306,\n",
      "         0.1166,  0.9835], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9839,  0.6855,  0.2670, -0.9569, -0.0132, -0.5672, -0.1949,  0.3326,\n",
      "         0.1174,  0.9868], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9852,  0.6861,  0.2662, -0.9581, -0.0159, -0.5684, -0.1932,  0.3320,\n",
      "         0.1171,  0.9846], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9862,  0.6876,  0.2674, -0.9578, -0.0147, -0.5684, -0.1947,  0.3325,\n",
      "         0.1170,  0.9862], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9872,  0.6860,  0.2661, -0.9601, -0.0157, -0.5685, -0.1921,  0.3317,\n",
      "         0.1174,  0.9854], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9888,  0.6878,  0.2672, -0.9591, -0.0144, -0.5690, -0.1955,  0.3329,\n",
      "         0.1171,  0.9882], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9895,  0.6877,  0.2660, -0.9604, -0.0164, -0.5702, -0.1928,  0.3322,\n",
      "         0.1179,  0.9865], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9909,  0.6897,  0.2670, -0.9609, -0.0140, -0.5681, -0.1945,  0.3324,\n",
      "         0.1170,  0.9886], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9920,  0.6887,  0.2673, -0.9623, -0.0163, -0.5719, -0.1942,  0.3335,\n",
      "         0.1177,  0.9876], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9932,  0.6912,  0.2670, -0.9621, -0.0137, -0.5686, -0.1956,  0.3321,\n",
      "         0.1167,  0.9900], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9945,  0.6882,  0.2675, -0.9624, -0.0159, -0.5707, -0.1934,  0.3328,\n",
      "         0.1183,  0.9899], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9959,  0.6914,  0.2674, -0.9631, -0.0151, -0.5705, -0.1956,  0.3337,\n",
      "         0.1174,  0.9906], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9966,  0.6899,  0.2682, -0.9630, -0.0165, -0.5717, -0.1937,  0.3328,\n",
      "         0.1186,  0.9916], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9981,  0.6921,  0.2666, -0.9653, -0.0137, -0.5701, -0.1950,  0.3334,\n",
      "         0.1170,  0.9917], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 1.9991,  0.6907,  0.2682, -0.9631, -0.0158, -0.5726, -0.1951,  0.3337,\n",
      "         0.1183,  0.9921], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0003,  0.6919,  0.2676, -0.9674, -0.0140, -0.5718, -0.1942,  0.3345,\n",
      "         0.1186,  0.9926], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0019,  0.6915,  0.2676, -0.9652, -0.0164, -0.5721, -0.1952,  0.3348,\n",
      "         0.1179,  0.9935], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0027,  0.6928,  0.2687, -0.9673, -0.0149, -0.5737, -0.1948,  0.3355,\n",
      "         0.1186,  0.9935], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0041,  0.6928,  0.2688, -0.9661, -0.0157, -0.5725, -0.1956,  0.3346,\n",
      "         0.1190,  0.9948], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0051,  0.6938,  0.2675, -0.9675, -0.0158, -0.5740, -0.1954,  0.3349,\n",
      "         0.1170,  0.9947], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0068,  0.6936,  0.2696, -0.9674, -0.0153, -0.5740, -0.1959,  0.3353,\n",
      "         0.1193,  0.9963], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0072,  0.6971,  0.2690, -0.9702, -0.0151, -0.5741, -0.1965,  0.3345,\n",
      "         0.1165,  0.9968], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0088,  0.6939,  0.2694, -0.9681, -0.0161, -0.5753, -0.1954,  0.3359,\n",
      "         0.1198,  0.9967], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0095,  0.6973,  0.2690, -0.9714, -0.0157, -0.5756, -0.1956,  0.3356,\n",
      "         0.1180,  0.9968], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0111,  0.6941,  0.2696, -0.9693, -0.0163, -0.5761, -0.1956,  0.3361,\n",
      "         0.1199,  0.9977], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0118,  0.6979,  0.2691, -0.9721, -0.0164, -0.5752, -0.1964,  0.3357,\n",
      "         0.1186,  0.9987], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0136,  0.6964,  0.2702, -0.9703, -0.0165, -0.5767, -0.1958,  0.3354,\n",
      "         0.1193,  0.9988], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0141,  0.6977,  0.2698, -0.9723, -0.0147, -0.5758, -0.1971,  0.3364,\n",
      "         0.1168,  0.9991], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0158,  0.6980,  0.2700, -0.9724, -0.0153, -0.5766, -0.1969,  0.3363,\n",
      "         0.1186,  1.0005], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0166,  0.6981,  0.2695, -0.9731, -0.0157, -0.5775, -0.1961,  0.3375,\n",
      "         0.1189,  1.0000], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0181,  0.6983,  0.2710, -0.9725, -0.0162, -0.5769, -0.1965,  0.3365,\n",
      "         0.1191,  1.0013], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0187,  0.6994,  0.2711, -0.9737, -0.0146, -0.5776, -0.1977,  0.3364,\n",
      "         0.1181,  1.0016], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0207,  0.6990,  0.2711, -0.9751, -0.0171, -0.5778, -0.1970,  0.3374,\n",
      "         0.1187,  1.0024], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0212,  0.7007,  0.2715, -0.9757, -0.0150, -0.5791, -0.1975,  0.3370,\n",
      "         0.1185,  1.0027], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0228,  0.7012,  0.2718, -0.9758, -0.0160, -0.5785, -0.1975,  0.3376,\n",
      "         0.1191,  1.0039], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0240,  0.6999,  0.2715, -0.9764, -0.0166, -0.5798, -0.1965,  0.3384,\n",
      "         0.1191,  1.0036], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0250,  0.7021,  0.2715, -0.9761, -0.0155, -0.5808, -0.1990,  0.3375,\n",
      "         0.1189,  1.0043], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0263,  0.7006,  0.2721, -0.9771, -0.0158, -0.5799, -0.1973,  0.3387,\n",
      "         0.1188,  1.0046], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0276,  0.7020,  0.2711, -0.9775, -0.0156, -0.5802, -0.1992,  0.3385,\n",
      "         0.1183,  1.0058], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0287,  0.7005,  0.2719, -0.9782, -0.0149, -0.5805, -0.1967,  0.3383,\n",
      "         0.1195,  1.0058], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0300,  0.7024,  0.2715, -0.9788, -0.0164, -0.5813, -0.1978,  0.3388,\n",
      "         0.1200,  1.0064], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0310,  0.7029,  0.2720, -0.9796, -0.0155, -0.5825, -0.1984,  0.3392,\n",
      "         0.1188,  1.0076], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0322,  0.7035,  0.2726, -0.9807, -0.0156, -0.5816, -0.1985,  0.3391,\n",
      "         0.1201,  1.0080], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0335,  0.7045,  0.2711, -0.9809, -0.0140, -0.5814, -0.1997,  0.3393,\n",
      "         0.1186,  1.0090], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0349,  0.7047,  0.2735, -0.9820, -0.0170, -0.5833, -0.1984,  0.3396,\n",
      "         0.1206,  1.0091], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0356,  0.7055,  0.2724, -0.9823, -0.0137, -0.5816, -0.2006,  0.3399,\n",
      "         0.1180,  1.0101], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0372,  0.7049,  0.2728, -0.9826, -0.0158, -0.5834, -0.1987,  0.3398,\n",
      "         0.1203,  1.0100], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0378,  0.7060,  0.2727, -0.9832, -0.0150, -0.5833, -0.1991,  0.3395,\n",
      "         0.1189,  1.0103], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0393,  0.7051,  0.2731, -0.9828, -0.0145, -0.5844, -0.1987,  0.3408,\n",
      "         0.1201,  1.0114], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0406,  0.7075,  0.2735, -0.9854, -0.0155, -0.5841, -0.1993,  0.3401,\n",
      "         0.1189,  1.0116], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0415,  0.7050,  0.2732, -0.9837, -0.0138, -0.5838, -0.1995,  0.3409,\n",
      "         0.1206,  1.0126], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0429,  0.7075,  0.2742, -0.9862, -0.0158, -0.5848, -0.1991,  0.3406,\n",
      "         0.1184,  1.0131], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0440,  0.7065,  0.2731, -0.9849, -0.0151, -0.5854, -0.1992,  0.3416,\n",
      "         0.1203,  1.0123], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0450,  0.7087,  0.2741, -0.9870, -0.0165, -0.5841, -0.1989,  0.3410,\n",
      "         0.1184,  1.0148], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0461,  0.7081,  0.2735, -0.9866, -0.0140, -0.5866, -0.2001,  0.3420,\n",
      "         0.1208,  1.0140], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0476,  0.7093,  0.2748, -0.9859, -0.0158, -0.5852, -0.1999,  0.3405,\n",
      "         0.1193,  1.0166], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0486,  0.7095,  0.2745, -0.9882, -0.0162, -0.5872, -0.1997,  0.3427,\n",
      "         0.1206,  1.0149], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0499,  0.7094,  0.2751, -0.9864, -0.0158, -0.5862, -0.2010,  0.3408,\n",
      "         0.1193,  1.0170], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0507,  0.7107,  0.2740, -0.9898, -0.0156, -0.5884, -0.1997,  0.3416,\n",
      "         0.1202,  1.0160], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0523,  0.7100,  0.2755, -0.9877, -0.0160, -0.5880, -0.2007,  0.3423,\n",
      "         0.1200,  1.0176], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0527,  0.7113,  0.2745, -0.9919, -0.0157, -0.5887, -0.1999,  0.3418,\n",
      "         0.1193,  1.0178], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0547,  0.7117,  0.2755, -0.9898, -0.0160, -0.5885, -0.2009,  0.3422,\n",
      "         0.1205,  1.0187], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0549,  0.7131,  0.2750, -0.9915, -0.0166, -0.5891, -0.2010,  0.3420,\n",
      "         0.1191,  1.0188], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0570,  0.7123,  0.2760, -0.9905, -0.0154, -0.5910, -0.2017,  0.3432,\n",
      "         0.1212,  1.0194], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0575,  0.7141,  0.2752, -0.9933, -0.0164, -0.5899, -0.2010,  0.3432,\n",
      "         0.1198,  1.0199], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0590,  0.7128,  0.2765, -0.9915, -0.0137, -0.5903, -0.2011,  0.3435,\n",
      "         0.1213,  1.0205], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0601,  0.7152,  0.2756, -0.9934, -0.0169, -0.5914, -0.2009,  0.3438,\n",
      "         0.1197,  1.0209], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0613,  0.7140,  0.2762, -0.9937, -0.0131, -0.5904, -0.2025,  0.3441,\n",
      "         0.1204,  1.0225], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0625,  0.7155,  0.2762, -0.9955, -0.0158, -0.5923, -0.2015,  0.3440,\n",
      "         0.1194,  1.0217], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0636,  0.7157,  0.2760, -0.9950, -0.0133, -0.5909, -0.2037,  0.3442,\n",
      "         0.1204,  1.0235], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0648,  0.7147,  0.2770, -0.9957, -0.0161, -0.5928, -0.2017,  0.3446,\n",
      "         0.1205,  1.0230], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0657,  0.7174,  0.2770, -0.9957, -0.0142, -0.5909, -0.2029,  0.3442,\n",
      "         0.1220,  1.0245], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0672,  0.7156,  0.2769, -0.9960, -0.0165, -0.5932, -0.2012,  0.3445,\n",
      "         0.1199,  1.0247], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0681,  0.7189,  0.2770, -0.9982, -0.0142, -0.5916, -0.2033,  0.3441,\n",
      "         0.1202,  1.0255], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0695,  0.7169,  0.2768, -0.9980, -0.0164, -0.5943, -0.2015,  0.3447,\n",
      "         0.1206,  1.0257], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0704,  0.7191,  0.2775, -0.9995, -0.0143, -0.5928, -0.2037,  0.3452,\n",
      "         0.1197,  1.0276], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0720,  0.7169,  0.2779, -0.9981, -0.0161, -0.5954, -0.2016,  0.3459,\n",
      "         0.1214,  1.0269], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0725,  0.7190,  0.2769, -1.0004, -0.0143, -0.5923, -0.2029,  0.3462,\n",
      "         0.1203,  1.0290], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0742,  0.7192,  0.2785, -1.0001, -0.0165, -0.5957, -0.2025,  0.3457,\n",
      "         0.1206,  1.0280], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0754,  0.7196,  0.2774, -1.0023, -0.0147, -0.5942, -0.2027,  0.3459,\n",
      "         0.1205,  1.0288], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0764,  0.7185,  0.2790, -1.0002, -0.0167, -0.5967, -0.2026,  0.3465,\n",
      "         0.1223,  1.0291], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0774,  0.7216,  0.2779, -1.0030, -0.0146, -0.5952, -0.2042,  0.3465,\n",
      "         0.1194,  1.0309], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0792,  0.7197,  0.2787, -1.0027, -0.0169, -0.5966, -0.2029,  0.3471,\n",
      "         0.1216,  1.0302], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0796,  0.7228,  0.2784, -1.0033, -0.0142, -0.5966, -0.2045,  0.3475,\n",
      "         0.1200,  1.0313], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0814,  0.7203,  0.2789, -1.0030, -0.0175, -0.5976, -0.2036,  0.3468,\n",
      "         0.1220,  1.0309], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0820,  0.7225,  0.2794, -1.0049, -0.0151, -0.5963, -0.2052,  0.3472,\n",
      "         0.1197,  1.0325], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0833,  0.7210,  0.2791, -1.0045, -0.0153, -0.5984, -0.2033,  0.3476,\n",
      "         0.1227,  1.0318], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0849,  0.7241,  0.2801, -1.0061, -0.0157, -0.5963, -0.2044,  0.3468,\n",
      "         0.1200,  1.0330], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0855,  0.7221,  0.2792, -1.0051, -0.0159, -0.5986, -0.2045,  0.3479,\n",
      "         0.1225,  1.0332], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0870,  0.7238,  0.2797, -1.0064, -0.0147, -0.5977, -0.2046,  0.3475,\n",
      "         0.1206,  1.0342], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0885,  0.7236,  0.2796, -1.0066, -0.0164, -0.5998, -0.2049,  0.3486,\n",
      "         0.1223,  1.0348], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0892,  0.7246,  0.2803, -1.0079, -0.0158, -0.5987, -0.2044,  0.3481,\n",
      "         0.1204,  1.0358], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0906,  0.7245,  0.2796, -1.0066, -0.0150, -0.6007, -0.2048,  0.3479,\n",
      "         0.1220,  1.0353], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0921,  0.7251,  0.2799, -1.0094, -0.0156, -0.5995, -0.2049,  0.3496,\n",
      "         0.1216,  1.0359], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0930,  0.7252,  0.2798, -1.0074, -0.0148, -0.6001, -0.2060,  0.3488,\n",
      "         0.1218,  1.0376], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0942,  0.7261,  0.2808, -1.0103, -0.0155, -0.6005, -0.2045,  0.3496,\n",
      "         0.1210,  1.0376], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0956,  0.7272,  0.2805, -1.0098, -0.0154, -0.6017, -0.2062,  0.3488,\n",
      "         0.1217,  1.0388], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0965,  0.7269,  0.2808, -1.0112, -0.0157, -0.6002, -0.2038,  0.3490,\n",
      "         0.1226,  1.0383], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0979,  0.7276,  0.2814, -1.0098, -0.0156, -0.6012, -0.2059,  0.3482,\n",
      "         0.1218,  1.0394], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.0988,  0.7284,  0.2811, -1.0129, -0.0151, -0.6023, -0.2060,  0.3503,\n",
      "         0.1218,  1.0397], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1001,  0.7279,  0.2810, -1.0123, -0.0168, -0.6023, -0.2054,  0.3495,\n",
      "         0.1220,  1.0404], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1011,  0.7286,  0.2818, -1.0123, -0.0144, -0.6013, -0.2057,  0.3498,\n",
      "         0.1224,  1.0411], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1027,  0.7300,  0.2813, -1.0141, -0.0170, -0.6021, -0.2057,  0.3503,\n",
      "         0.1220,  1.0417], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1032,  0.7301,  0.2820, -1.0136, -0.0148, -0.6036, -0.2061,  0.3511,\n",
      "         0.1227,  1.0421], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1050,  0.7312,  0.2812, -1.0140, -0.0160, -0.6019, -0.2062,  0.3498,\n",
      "         0.1214,  1.0429], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1058,  0.7300,  0.2820, -1.0153, -0.0129, -0.6037, -0.2067,  0.3519,\n",
      "         0.1219,  1.0433], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1073,  0.7305,  0.2813, -1.0151, -0.0174, -0.6034, -0.2060,  0.3506,\n",
      "         0.1215,  1.0437], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1082,  0.7311,  0.2835, -1.0164, -0.0139, -0.6047, -0.2074,  0.3518,\n",
      "         0.1223,  1.0445], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1097,  0.7313,  0.2822, -1.0168, -0.0173, -0.6040, -0.2060,  0.3514,\n",
      "         0.1221,  1.0450], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1111,  0.7326,  0.2847, -1.0173, -0.0145, -0.6062, -0.2077,  0.3526,\n",
      "         0.1212,  1.0456], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1118,  0.7329,  0.2820, -1.0188, -0.0172, -0.6045, -0.2063,  0.3517,\n",
      "         0.1218,  1.0467], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1135,  0.7331,  0.2837, -1.0175, -0.0141, -0.6061, -0.2077,  0.3527,\n",
      "         0.1228,  1.0476], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1142,  0.7329,  0.2821, -1.0202, -0.0168, -0.6056, -0.2058,  0.3515,\n",
      "         0.1227,  1.0472], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1159,  0.7346,  0.2843, -1.0186, -0.0143, -0.6076, -0.2079,  0.3533,\n",
      "         0.1227,  1.0479], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1168,  0.7337,  0.2826, -1.0202, -0.0172, -0.6075, -0.2060,  0.3528,\n",
      "         0.1235,  1.0476], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1177,  0.7346,  0.2840, -1.0193, -0.0130, -0.6066, -0.2087,  0.3531,\n",
      "         0.1228,  1.0497], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1188,  0.7353,  0.2826, -1.0222, -0.0166, -0.6070, -0.2067,  0.3523,\n",
      "         0.1219,  1.0494], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1204,  0.7352,  0.2838, -1.0204, -0.0138, -0.6090, -0.2079,  0.3538,\n",
      "         0.1239,  1.0497], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1211,  0.7377,  0.2836, -1.0236, -0.0168, -0.6087, -0.2079,  0.3528,\n",
      "         0.1220,  1.0510], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1226,  0.7353,  0.2847, -1.0215, -0.0145, -0.6090, -0.2076,  0.3538,\n",
      "         0.1245,  1.0508], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1235,  0.7376,  0.2840, -1.0230, -0.0153, -0.6101, -0.2088,  0.3532,\n",
      "         0.1207,  1.0510], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1248,  0.7358,  0.2844, -1.0233, -0.0146, -0.6104, -0.2085,  0.3546,\n",
      "         0.1241,  1.0521], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1257,  0.7388,  0.2835, -1.0241, -0.0143, -0.6099, -0.2092,  0.3533,\n",
      "         0.1218,  1.0526], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1270,  0.7371,  0.2840, -1.0240, -0.0160, -0.6123, -0.2092,  0.3550,\n",
      "         0.1241,  1.0536], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1280,  0.7394,  0.2848, -1.0254, -0.0141, -0.6092, -0.2092,  0.3531,\n",
      "         0.1213,  1.0541], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1297,  0.7384,  0.2848, -1.0251, -0.0158, -0.6130, -0.2089,  0.3541,\n",
      "         0.1241,  1.0544], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1302,  0.7395,  0.2851, -1.0278, -0.0142, -0.6093, -0.2091,  0.3547,\n",
      "         0.1229,  1.0553], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1320,  0.7391,  0.2852, -1.0270, -0.0170, -0.6126, -0.2081,  0.3548,\n",
      "         0.1247,  1.0557], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1325,  0.7406,  0.2846, -1.0269, -0.0134, -0.6101, -0.2096,  0.3536,\n",
      "         0.1219,  1.0569], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1344,  0.7389,  0.2856, -1.0287, -0.0160, -0.6139, -0.2091,  0.3559,\n",
      "         0.1246,  1.0572], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1352,  0.7414,  0.2849, -1.0279, -0.0147, -0.6130, -0.2109,  0.3542,\n",
      "         0.1218,  1.0573], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1367,  0.7398,  0.2858, -1.0288, -0.0159, -0.6141, -0.2093,  0.3574,\n",
      "         0.1249,  1.0578], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1374,  0.7428,  0.2858, -1.0304, -0.0162, -0.6123, -0.2098,  0.3542,\n",
      "         0.1219,  1.0585], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1389,  0.7413,  0.2858, -1.0299, -0.0145, -0.6146, -0.2093,  0.3572,\n",
      "         0.1262,  1.0591], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1401,  0.7431,  0.2869, -1.0308, -0.0161, -0.6131, -0.2099,  0.3560,\n",
      "         0.1212,  1.0593], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1415,  0.7429,  0.2864, -1.0313, -0.0143, -0.6155, -0.2108,  0.3572,\n",
      "         0.1235,  1.0609], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1425,  0.7441,  0.2870, -1.0314, -0.0163, -0.6140, -0.2097,  0.3566,\n",
      "         0.1227,  1.0614], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1439,  0.7452,  0.2869, -1.0341, -0.0148, -0.6159, -0.2107,  0.3577,\n",
      "         0.1234,  1.0627], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1449,  0.7445,  0.2877, -1.0320, -0.0164, -0.6157, -0.2100,  0.3564,\n",
      "         0.1237,  1.0616], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1459,  0.7439,  0.2863, -1.0338, -0.0144, -0.6169, -0.2108,  0.3570,\n",
      "         0.1241,  1.0623], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1474,  0.7464,  0.2876, -1.0340, -0.0155, -0.6163, -0.2124,  0.3571,\n",
      "         0.1241,  1.0639], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1484,  0.7454,  0.2868, -1.0359, -0.0153, -0.6171, -0.2100,  0.3581,\n",
      "         0.1238,  1.0629], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1500,  0.7471,  0.2881, -1.0346, -0.0166, -0.6173, -0.2116,  0.3577,\n",
      "         0.1227,  1.0652], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1506,  0.7454,  0.2854, -1.0375, -0.0152, -0.6166, -0.2103,  0.3584,\n",
      "         0.1241,  1.0638], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1524,  0.7473,  0.2890, -1.0346, -0.0155, -0.6171, -0.2112,  0.3576,\n",
      "         0.1236,  1.0657], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1528,  0.7474,  0.2869, -1.0374, -0.0168, -0.6197, -0.2115,  0.3596,\n",
      "         0.1237,  1.0659], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1547,  0.7476,  0.2887, -1.0362, -0.0151, -0.6171, -0.2110,  0.3579,\n",
      "         0.1238,  1.0657], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1554,  0.7489,  0.2874, -1.0386, -0.0144, -0.6203, -0.2117,  0.3586,\n",
      "         0.1237,  1.0674], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1568,  0.7482,  0.2891, -1.0388, -0.0150, -0.6179, -0.2115,  0.3594,\n",
      "         0.1236,  1.0680], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1577,  0.7484,  0.2882, -1.0392, -0.0154, -0.6205, -0.2111,  0.3590,\n",
      "         0.1240,  1.0680], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1589,  0.7499,  0.2881, -1.0406, -0.0142, -0.6185, -0.2123,  0.3593,\n",
      "         0.1238,  1.0689], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1604,  0.7486,  0.2892, -1.0396, -0.0158, -0.6213, -0.2123,  0.3596,\n",
      "         0.1231,  1.0697], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1609,  0.7522,  0.2887, -1.0426, -0.0135, -0.6196, -0.2123,  0.3596,\n",
      "         0.1234,  1.0702], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1628,  0.7492,  0.2888, -1.0411, -0.0164, -0.6221, -0.2120,  0.3601,\n",
      "         0.1238,  1.0709], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1635,  0.7542,  0.2892, -1.0436, -0.0152, -0.6212, -0.2135,  0.3601,\n",
      "         0.1226,  1.0711], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1653,  0.7502,  0.2891, -1.0426, -0.0156, -0.6224, -0.2124,  0.3601,\n",
      "         0.1255,  1.0709], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1659,  0.7543,  0.2893, -1.0447, -0.0142, -0.6208, -0.2124,  0.3599,\n",
      "         0.1240,  1.0725], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1675,  0.7511,  0.2894, -1.0425, -0.0153, -0.6229, -0.2133,  0.3607,\n",
      "         0.1250,  1.0734], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1684,  0.7546,  0.2902, -1.0464, -0.0151, -0.6229, -0.2130,  0.3612,\n",
      "         0.1237,  1.0726], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1698,  0.7530,  0.2908, -1.0439, -0.0138, -0.6242, -0.2136,  0.3609,\n",
      "         0.1256,  1.0741], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1707,  0.7550,  0.2895, -1.0465, -0.0155, -0.6230, -0.2134,  0.3611,\n",
      "         0.1234,  1.0736], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1723,  0.7532,  0.2905, -1.0455, -0.0158, -0.6247, -0.2133,  0.3618,\n",
      "         0.1255,  1.0743], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1732,  0.7554,  0.2906, -1.0458, -0.0155, -0.6235, -0.2147,  0.3611,\n",
      "         0.1235,  1.0755], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1744,  0.7532,  0.2910, -1.0467, -0.0142, -0.6239, -0.2130,  0.3624,\n",
      "         0.1247,  1.0759], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1757,  0.7566,  0.2910, -1.0470, -0.0171, -0.6242, -0.2141,  0.3623,\n",
      "         0.1253,  1.0760], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1767,  0.7561,  0.2920, -1.0482, -0.0147, -0.6258, -0.2135,  0.3623,\n",
      "         0.1253,  1.0778], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1781,  0.7570,  0.2919, -1.0478, -0.0170, -0.6253, -0.2134,  0.3621,\n",
      "         0.1252,  1.0773], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1788,  0.7573,  0.2919, -1.0496, -0.0142, -0.6266, -0.2151,  0.3623,\n",
      "         0.1231,  1.0785], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1804,  0.7575,  0.2916, -1.0491, -0.0156, -0.6263, -0.2142,  0.3624,\n",
      "         0.1251,  1.0787], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1812,  0.7589,  0.2921, -1.0515, -0.0149, -0.6281, -0.2151,  0.3633,\n",
      "         0.1242,  1.0790], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1829,  0.7582,  0.2924, -1.0500, -0.0168, -0.6268, -0.2151,  0.3632,\n",
      "         0.1251,  1.0805], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1835,  0.7590,  0.2913, -1.0513, -0.0143, -0.6272, -0.2154,  0.3635,\n",
      "         0.1241,  1.0807], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1852,  0.7590,  0.2919, -1.0514, -0.0161, -0.6291, -0.2144,  0.3636,\n",
      "         0.1268,  1.0801], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1855,  0.7611,  0.2915, -1.0535, -0.0140, -0.6276, -0.2158,  0.3631,\n",
      "         0.1236,  1.0822], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1874,  0.7599,  0.2915, -1.0523, -0.0167, -0.6295, -0.2145,  0.3642,\n",
      "         0.1268,  1.0815], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1884,  0.7607,  0.2930, -1.0537, -0.0144, -0.6284, -0.2161,  0.3647,\n",
      "         0.1243,  1.0823], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1895,  0.7601,  0.2918, -1.0543, -0.0161, -0.6311, -0.2154,  0.3658,\n",
      "         0.1256,  1.0827], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1910,  0.7615,  0.2931, -1.0537, -0.0145, -0.6291, -0.2170,  0.3641,\n",
      "         0.1252,  1.0843], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1918,  0.7610,  0.2921, -1.0555, -0.0167, -0.6301, -0.2149,  0.3653,\n",
      "         0.1259,  1.0829], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1935,  0.7627,  0.2930, -1.0556, -0.0141, -0.6298, -0.2173,  0.3648,\n",
      "         0.1235,  1.0859], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1943,  0.7613,  0.2922, -1.0573, -0.0153, -0.6301, -0.2150,  0.3661,\n",
      "         0.1266,  1.0846], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1958,  0.7641,  0.2936, -1.0576, -0.0157, -0.6316, -0.2174,  0.3656,\n",
      "         0.1241,  1.0871], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1963,  0.7617,  0.2923, -1.0574, -0.0150, -0.6310, -0.2148,  0.3666,\n",
      "         0.1266,  1.0856], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1981,  0.7648,  0.2941, -1.0571, -0.0157, -0.6314, -0.2163,  0.3649,\n",
      "         0.1247,  1.0877], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.1986,  0.7638,  0.2938, -1.0577, -0.0144, -0.6311, -0.2164,  0.3657,\n",
      "         0.1255,  1.0879], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2004,  0.7651,  0.2942, -1.0583, -0.0158, -0.6328, -0.2167,  0.3661,\n",
      "         0.1252,  1.0882], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2012,  0.7653,  0.2945, -1.0589, -0.0156, -0.6331, -0.2164,  0.3661,\n",
      "         0.1257,  1.0890], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2026,  0.7659,  0.2946, -1.0595, -0.0163, -0.6331, -0.2171,  0.3660,\n",
      "         0.1251,  1.0890], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2037,  0.7666,  0.2955, -1.0607, -0.0156, -0.6336, -0.2168,  0.3677,\n",
      "         0.1257,  1.0899], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2045,  0.7670,  0.2939, -1.0624, -0.0151, -0.6331, -0.2170,  0.3671,\n",
      "         0.1255,  1.0912], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2056,  0.7662,  0.2946, -1.0617, -0.0162, -0.6347, -0.2165,  0.3671,\n",
      "         0.1257,  1.0909], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2071,  0.7692,  0.2946, -1.0634, -0.0147, -0.6338, -0.2186,  0.3674,\n",
      "         0.1253,  1.0923], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2081,  0.7667,  0.2950, -1.0622, -0.0173, -0.6358, -0.2163,  0.3668,\n",
      "         0.1258,  1.0922], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2092,  0.7692,  0.2945, -1.0653, -0.0145, -0.6348, -0.2185,  0.3683,\n",
      "         0.1263,  1.0927], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2106,  0.7677,  0.2955, -1.0637, -0.0162, -0.6365, -0.2166,  0.3675,\n",
      "         0.1262,  1.0931], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2116,  0.7692,  0.2947, -1.0655, -0.0138, -0.6352, -0.2194,  0.3690,\n",
      "         0.1263,  1.0946], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2130,  0.7690,  0.2951, -1.0648, -0.0165, -0.6370, -0.2168,  0.3675,\n",
      "         0.1251,  1.0941], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2137,  0.7701,  0.2954, -1.0664, -0.0141, -0.6357, -0.2190,  0.3691,\n",
      "         0.1260,  1.0954], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2154,  0.7695,  0.2953, -1.0667, -0.0168, -0.6381, -0.2172,  0.3685,\n",
      "         0.1262,  1.0952], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2162,  0.7699,  0.2954, -1.0665, -0.0134, -0.6359, -0.2196,  0.3686,\n",
      "         0.1269,  1.0960], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2177,  0.7712,  0.2965, -1.0671, -0.0173, -0.6386, -0.2181,  0.3684,\n",
      "         0.1249,  1.0970], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2190,  0.7712,  0.2963, -1.0668, -0.0140, -0.6384, -0.2191,  0.3694,\n",
      "         0.1279,  1.0965], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2199,  0.7722,  0.2959, -1.0685, -0.0165, -0.6381, -0.2184,  0.3691,\n",
      "         0.1251,  1.0975], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2215,  0.7710,  0.2960, -1.0682, -0.0132, -0.6395, -0.2200,  0.3706,\n",
      "         0.1279,  1.0984], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2222,  0.7736,  0.2964, -1.0702, -0.0161, -0.6387, -0.2181,  0.3695,\n",
      "         0.1249,  1.0988], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2235,  0.7727,  0.2968, -1.0697, -0.0140, -0.6408, -0.2190,  0.3698,\n",
      "         0.1290,  1.0995], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2249,  0.7739,  0.2972, -1.0699, -0.0155, -0.6394, -0.2191,  0.3691,\n",
      "         0.1263,  1.0993], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2260,  0.7745,  0.2968, -1.0709, -0.0157, -0.6421, -0.2197,  0.3711,\n",
      "         0.1274,  1.1008], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2269,  0.7748,  0.2975, -1.0727, -0.0142, -0.6401, -0.2192,  0.3699,\n",
      "         0.1248,  1.1015], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2283,  0.7739,  0.2962, -1.0719, -0.0160, -0.6423, -0.2187,  0.3712,\n",
      "         0.1278,  1.1009], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2290,  0.7771,  0.2976, -1.0746, -0.0141, -0.6397, -0.2202,  0.3703,\n",
      "         0.1254,  1.1030], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2308,  0.7752,  0.2977, -1.0734, -0.0166, -0.6429, -0.2193,  0.3717,\n",
      "         0.1284,  1.1019], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2316,  0.7780,  0.2969, -1.0753, -0.0155, -0.6406, -0.2193,  0.3703,\n",
      "         0.1266,  1.1031], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2331,  0.7757,  0.2986, -1.0735, -0.0157, -0.6433, -0.2201,  0.3711,\n",
      "         0.1280,  1.1038], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2338,  0.7784,  0.2973, -1.0772, -0.0145, -0.6431, -0.2198,  0.3718,\n",
      "         0.1263,  1.1039], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2354,  0.7765,  0.2992, -1.0754, -0.0164, -0.6446, -0.2198,  0.3711,\n",
      "         0.1280,  1.1050], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2363,  0.7787,  0.2978, -1.0773, -0.0147, -0.6429, -0.2205,  0.3715,\n",
      "         0.1269,  1.1062], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2375,  0.7764,  0.2990, -1.0765, -0.0158, -0.6447, -0.2196,  0.3715,\n",
      "         0.1278,  1.1061], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2385,  0.7799,  0.2984, -1.0788, -0.0160, -0.6443, -0.2201,  0.3725,\n",
      "         0.1270,  1.1063], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2403,  0.7778,  0.2993, -1.0766, -0.0155, -0.6455, -0.2205,  0.3725,\n",
      "         0.1274,  1.1073], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2409,  0.7806,  0.2984, -1.0784, -0.0151, -0.6454, -0.2215,  0.3725,\n",
      "         0.1271,  1.1078], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2425,  0.7788,  0.2989, -1.0782, -0.0150, -0.6455, -0.2200,  0.3724,\n",
      "         0.1274,  1.1084], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2431,  0.7810,  0.2996, -1.0793, -0.0146, -0.6448, -0.2231,  0.3729,\n",
      "         0.1268,  1.1095], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2452,  0.7807,  0.2997, -1.0804, -0.0163, -0.6464, -0.2206,  0.3727,\n",
      "         0.1273,  1.1098], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2456,  0.7822,  0.3004, -1.0804, -0.0142, -0.6458, -0.2217,  0.3738,\n",
      "         0.1282,  1.1097], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2471,  0.7797,  0.2996, -1.0814, -0.0165, -0.6475, -0.2203,  0.3733,\n",
      "         0.1281,  1.1103], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2481,  0.7840,  0.2995, -1.0813, -0.0141, -0.6460, -0.2230,  0.3731,\n",
      "         0.1266,  1.1123], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2496,  0.7820,  0.3004, -1.0819, -0.0168, -0.6486, -0.2210,  0.3727,\n",
      "         0.1276,  1.1117], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2503,  0.7856,  0.3008, -1.0836, -0.0143, -0.6461, -0.2225,  0.3738,\n",
      "         0.1274,  1.1127], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2519,  0.7824,  0.3000, -1.0830, -0.0169, -0.6490, -0.2208,  0.3743,\n",
      "         0.1284,  1.1122], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2529,  0.7845,  0.3003, -1.0853, -0.0143, -0.6471, -0.2228,  0.3743,\n",
      "         0.1269,  1.1141], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2543,  0.7842,  0.3001, -1.0837, -0.0154, -0.6492, -0.2210,  0.3747,\n",
      "         0.1269,  1.1138], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2552,  0.7852,  0.3007, -1.0861, -0.0154, -0.6493, -0.2222,  0.3750,\n",
      "         0.1285,  1.1141], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2566,  0.7848,  0.3001, -1.0853, -0.0157, -0.6493, -0.2211,  0.3748,\n",
      "         0.1279,  1.1146], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2576,  0.7853,  0.3006, -1.0863, -0.0138, -0.6495, -0.2241,  0.3763,\n",
      "         0.1283,  1.1162], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2590,  0.7860,  0.3007, -1.0869, -0.0162, -0.6514, -0.2217,  0.3752,\n",
      "         0.1270,  1.1159], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2598,  0.7853,  0.3013, -1.0871, -0.0138, -0.6503, -0.2242,  0.3760,\n",
      "         0.1285,  1.1166], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2614,  0.7874,  0.3023, -1.0883, -0.0169, -0.6518, -0.2224,  0.3756,\n",
      "         0.1277,  1.1170], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2624,  0.7875,  0.3020, -1.0876, -0.0140, -0.6518, -0.2240,  0.3760,\n",
      "         0.1289,  1.1183], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2635,  0.7877,  0.3021, -1.0898, -0.0159, -0.6531, -0.2227,  0.3761,\n",
      "         0.1274,  1.1183], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2647,  0.7873,  0.3023, -1.0893, -0.0140, -0.6520, -0.2235,  0.3761,\n",
      "         0.1286,  1.1191], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2660,  0.7881,  0.3026, -1.0904, -0.0159, -0.6534, -0.2232,  0.3767,\n",
      "         0.1281,  1.1195], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2670,  0.7878,  0.3022, -1.0901, -0.0131, -0.6512, -0.2239,  0.3764,\n",
      "         0.1300,  1.1205], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2687,  0.7897,  0.3027, -1.0914, -0.0164, -0.6543, -0.2232,  0.3768,\n",
      "         0.1279,  1.1201], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2692,  0.7901,  0.3026, -1.0918, -0.0132, -0.6519, -0.2250,  0.3775,\n",
      "         0.1282,  1.1230], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2707,  0.7889,  0.3023, -1.0925, -0.0161, -0.6542, -0.2235,  0.3773,\n",
      "         0.1287,  1.1208], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2715,  0.7922,  0.3031, -1.0941, -0.0141, -0.6520, -0.2237,  0.3768,\n",
      "         0.1290,  1.1234], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2729,  0.7898,  0.3028, -1.0935, -0.0169, -0.6559, -0.2231,  0.3778,\n",
      "         0.1295,  1.1222], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2740,  0.7936,  0.3032, -1.0948, -0.0139, -0.6541, -0.2251,  0.3778,\n",
      "         0.1278,  1.1248], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2753,  0.7898,  0.3035, -1.0941, -0.0170, -0.6567, -0.2233,  0.3776,\n",
      "         0.1301,  1.1238], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2761,  0.7939,  0.3024, -1.0961, -0.0136, -0.6543, -0.2258,  0.3776,\n",
      "         0.1275,  1.1256], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2775,  0.7914,  0.3028, -1.0956, -0.0168, -0.6570, -0.2248,  0.3781,\n",
      "         0.1298,  1.1252], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2786,  0.7950,  0.3040, -1.0967, -0.0152, -0.6563, -0.2254,  0.3787,\n",
      "         0.1275,  1.1260], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2801,  0.7929,  0.3033, -1.0963, -0.0157, -0.6573, -0.2253,  0.3786,\n",
      "         0.1296,  1.1264], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2808,  0.7944,  0.3037, -1.0987, -0.0157, -0.6568, -0.2248,  0.3786,\n",
      "         0.1282,  1.1262], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2825,  0.7943,  0.3037, -1.0978, -0.0157, -0.6585, -0.2250,  0.3791,\n",
      "         0.1301,  1.1272], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2835,  0.7952,  0.3039, -1.0992, -0.0154, -0.6570, -0.2265,  0.3787,\n",
      "         0.1277,  1.1280], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2846,  0.7955,  0.3036, -1.0989, -0.0155, -0.6590, -0.2254,  0.3799,\n",
      "         0.1300,  1.1290], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2863,  0.7958,  0.3049, -1.0991, -0.0156, -0.6585, -0.2252,  0.3795,\n",
      "         0.1282,  1.1290], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2870,  0.7971,  0.3049, -1.1005, -0.0140, -0.6590, -0.2258,  0.3795,\n",
      "         0.1296,  1.1307], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2883,  0.7951,  0.3050, -1.0997, -0.0145, -0.6588, -0.2255,  0.3804,\n",
      "         0.1292,  1.1300], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2895,  0.7980,  0.3046, -1.1011, -0.0151, -0.6599, -0.2266,  0.3793,\n",
      "         0.1290,  1.1318], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2909,  0.7966,  0.3063, -1.1020, -0.0146, -0.6610, -0.2257,  0.3814,\n",
      "         0.1294,  1.1305], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2919,  0.7981,  0.3047, -1.1030, -0.0148, -0.6591, -0.2259,  0.3793,\n",
      "         0.1292,  1.1323], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2934,  0.7981,  0.3062, -1.1018, -0.0144, -0.6615, -0.2270,  0.3818,\n",
      "         0.1296,  1.1329], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2942,  0.7992,  0.3051, -1.1040, -0.0158, -0.6599, -0.2260,  0.3802,\n",
      "         0.1298,  1.1343], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2958,  0.7992,  0.3066, -1.1042, -0.0145, -0.6617, -0.2266,  0.3821,\n",
      "         0.1303,  1.1332], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2967,  0.8012,  0.3059, -1.1043, -0.0170, -0.6614, -0.2277,  0.3811,\n",
      "         0.1288,  1.1343], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2978,  0.8005,  0.3068, -1.1053, -0.0131, -0.6619, -0.2273,  0.3821,\n",
      "         0.1284,  1.1351], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.2989,  0.7998,  0.3063, -1.1045, -0.0160, -0.6628, -0.2277,  0.3825,\n",
      "         0.1292,  1.1348], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3002,  0.8020,  0.3069, -1.1073, -0.0131, -0.6627, -0.2271,  0.3823,\n",
      "         0.1285,  1.1358], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3014,  0.8004,  0.3055, -1.1058, -0.0165, -0.6644, -0.2276,  0.3823,\n",
      "         0.1309,  1.1362], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3021,  0.8038,  0.3074, -1.1091, -0.0133, -0.6626, -0.2283,  0.3816,\n",
      "         0.1288,  1.1377], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3039,  0.8020,  0.3062, -1.1075, -0.0165, -0.6640, -0.2276,  0.3828,\n",
      "         0.1306,  1.1373], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3048,  0.8041,  0.3071, -1.1086, -0.0140, -0.6645, -0.2286,  0.3832,\n",
      "         0.1290,  1.1387], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3063,  0.8040,  0.3069, -1.1085, -0.0170, -0.6648, -0.2275,  0.3833,\n",
      "         0.1314,  1.1388], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3069,  0.8029,  0.3071, -1.1090, -0.0131, -0.6651, -0.2283,  0.3823,\n",
      "         0.1296,  1.1396], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3089,  0.8049,  0.3075, -1.1090, -0.0162, -0.6652, -0.2284,  0.3831,\n",
      "         0.1310,  1.1402], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3095,  0.8048,  0.3076, -1.1112, -0.0156, -0.6646, -0.2273,  0.3843,\n",
      "         0.1304,  1.1405], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3112,  0.8059,  0.3077, -1.1092, -0.0155, -0.6655, -0.2297,  0.3832,\n",
      "         0.1297,  1.1416], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3116,  0.8050,  0.3075, -1.1133, -0.0151, -0.6660, -0.2269,  0.3848,\n",
      "         0.1309,  1.1408], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3136,  0.8057,  0.3085, -1.1109, -0.0145, -0.6665, -0.2287,  0.3835,\n",
      "         0.1301,  1.1426], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3142,  0.8065,  0.3080, -1.1136, -0.0161, -0.6671, -0.2282,  0.3852,\n",
      "         0.1297,  1.1419], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3158,  0.8065,  0.3093, -1.1120, -0.0153, -0.6675, -0.2280,  0.3841,\n",
      "         0.1307,  1.1435], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3165,  0.8070,  0.3085, -1.1138, -0.0140, -0.6689, -0.2293,  0.3851,\n",
      "         0.1287,  1.1433], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3179,  0.8068,  0.3093, -1.1152, -0.0156, -0.6680, -0.2284,  0.3863,\n",
      "         0.1317,  1.1451], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3192,  0.8089,  0.3087, -1.1155, -0.0155, -0.6688, -0.2287,  0.3852,\n",
      "         0.1296,  1.1445], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3203,  0.8088,  0.3102, -1.1162, -0.0141, -0.6690, -0.2289,  0.3853,\n",
      "         0.1318,  1.1460], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3215,  0.8098,  0.3092, -1.1172, -0.0165, -0.6696, -0.2288,  0.3854,\n",
      "         0.1301,  1.1450], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3226,  0.8089,  0.3093, -1.1156, -0.0128, -0.6692, -0.2308,  0.3863,\n",
      "         0.1312,  1.1475], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3237,  0.8096,  0.3093, -1.1178, -0.0158, -0.6706, -0.2291,  0.3852,\n",
      "         0.1292,  1.1468], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3252,  0.8106,  0.3093, -1.1166, -0.0136, -0.6706, -0.2308,  0.3875,\n",
      "         0.1320,  1.1480], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3258,  0.8098,  0.3099, -1.1184, -0.0173, -0.6718, -0.2282,  0.3865,\n",
      "         0.1308,  1.1482], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3271,  0.8127,  0.3106, -1.1197, -0.0129, -0.6686, -0.2310,  0.3859,\n",
      "         0.1308,  1.1495], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3285,  0.8110,  0.3101, -1.1196, -0.0165, -0.6732, -0.2297,  0.3862,\n",
      "         0.1310,  1.1493], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3297,  0.8132,  0.3101, -1.1216, -0.0137, -0.6694, -0.2310,  0.3866,\n",
      "         0.1319,  1.1512], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3310,  0.8126,  0.3109, -1.1211, -0.0169, -0.6738, -0.2300,  0.3873,\n",
      "         0.1313,  1.1507], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3319,  0.8138,  0.3104, -1.1223, -0.0133, -0.6710, -0.2320,  0.3869,\n",
      "         0.1303,  1.1535], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3334,  0.8125,  0.3114, -1.1215, -0.0171, -0.6739, -0.2288,  0.3877,\n",
      "         0.1317,  1.1522], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3343,  0.8158,  0.3102, -1.1234, -0.0145, -0.6730, -0.2320,  0.3868,\n",
      "         0.1306,  1.1537], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3357,  0.8137,  0.3103, -1.1235, -0.0166, -0.6754, -0.2295,  0.3879,\n",
      "         0.1324,  1.1535], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3367,  0.8164,  0.3110, -1.1242, -0.0153, -0.6720, -0.2319,  0.3870,\n",
      "         0.1305,  1.1540], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3376,  0.8136,  0.3105, -1.1242, -0.0164, -0.6757, -0.2301,  0.3889,\n",
      "         0.1326,  1.1543], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3393,  0.8167,  0.3117, -1.1245, -0.0141, -0.6738, -0.2328,  0.3875,\n",
      "         0.1299,  1.1552], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3400,  0.8145,  0.3102, -1.1250, -0.0164, -0.6769, -0.2306,  0.3884,\n",
      "         0.1322,  1.1540], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3416,  0.8185,  0.3122, -1.1263, -0.0153, -0.6741, -0.2319,  0.3883,\n",
      "         0.1302,  1.1565], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3427,  0.8156,  0.3107, -1.1256, -0.0164, -0.6770, -0.2311,  0.3878,\n",
      "         0.1314,  1.1554], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3437,  0.8184,  0.3121, -1.1277, -0.0135, -0.6759, -0.2330,  0.3896,\n",
      "         0.1298,  1.1576], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3450,  0.8166,  0.3119, -1.1274, -0.0157, -0.6774, -0.2322,  0.3892,\n",
      "         0.1316,  1.1569], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3460,  0.8184,  0.3122, -1.1289, -0.0139, -0.6768, -0.2322,  0.3897,\n",
      "         0.1305,  1.1575], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3473,  0.8179,  0.3127, -1.1280, -0.0164, -0.6777, -0.2322,  0.3888,\n",
      "         0.1322,  1.1583], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3484,  0.8205,  0.3125, -1.1296, -0.0149, -0.6790, -0.2333,  0.3909,\n",
      "         0.1299,  1.1592], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3497,  0.8191,  0.3134, -1.1284, -0.0163, -0.6781, -0.2326,  0.3900,\n",
      "         0.1317,  1.1595], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3509,  0.8201,  0.3128, -1.1298, -0.0147, -0.6792, -0.2339,  0.3905,\n",
      "         0.1312,  1.1600], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3521,  0.8209,  0.3135, -1.1302, -0.0156, -0.6773, -0.2328,  0.3896,\n",
      "         0.1299,  1.1608], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3531,  0.8208,  0.3133, -1.1309, -0.0161, -0.6802, -0.2317,  0.3912,\n",
      "         0.1320,  1.1596], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3548,  0.8227,  0.3134, -1.1308, -0.0151, -0.6782, -0.2344,  0.3906,\n",
      "         0.1303,  1.1626], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3554,  0.8207,  0.3135, -1.1316, -0.0170, -0.6809, -0.2311,  0.3920,\n",
      "         0.1330,  1.1613], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3571,  0.8234,  0.3144, -1.1322, -0.0155, -0.6790, -0.2341,  0.3909,\n",
      "         0.1311,  1.1636], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3577,  0.8217,  0.3143, -1.1328, -0.0141, -0.6804, -0.2332,  0.3918,\n",
      "         0.1310,  1.1639], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3593,  0.8228,  0.3141, -1.1325, -0.0154, -0.6806, -0.2332,  0.3909,\n",
      "         0.1322,  1.1639], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3605,  0.8245,  0.3154, -1.1352, -0.0151, -0.6813, -0.2329,  0.3916,\n",
      "         0.1310,  1.1645], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3619,  0.8254,  0.3140, -1.1345, -0.0151, -0.6811, -0.2345,  0.3914,\n",
      "         0.1315,  1.1651], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3627,  0.8241,  0.3150, -1.1354, -0.0155, -0.6824, -0.2329,  0.3928,\n",
      "         0.1331,  1.1646], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3643,  0.8260,  0.3143, -1.1359, -0.0138, -0.6813, -0.2350,  0.3914,\n",
      "         0.1309,  1.1675], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3649,  0.8237,  0.3149, -1.1360, -0.0169, -0.6837, -0.2331,  0.3935,\n",
      "         0.1331,  1.1658], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3663,  0.8272,  0.3147, -1.1382, -0.0137, -0.6822, -0.2347,  0.3930,\n",
      "         0.1312,  1.1679], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3677,  0.8253,  0.3152, -1.1373, -0.0167, -0.6832, -0.2332,  0.3926,\n",
      "         0.1329,  1.1672], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3684,  0.8278,  0.3149, -1.1394, -0.0139, -0.6828, -0.2345,  0.3932,\n",
      "         0.1322,  1.1692], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3700,  0.8254,  0.3159, -1.1380, -0.0168, -0.6850, -0.2347,  0.3936,\n",
      "         0.1328,  1.1688], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3707,  0.8284,  0.3152, -1.1405, -0.0136, -0.6824, -0.2346,  0.3927,\n",
      "         0.1315,  1.1701], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3728,  0.8274,  0.3151, -1.1402, -0.0172, -0.6856, -0.2343,  0.3939,\n",
      "         0.1326,  1.1702], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3728,  0.8291,  0.3157, -1.1408, -0.0134, -0.6840, -0.2357,  0.3937,\n",
      "         0.1315,  1.1714], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3749,  0.8288,  0.3155, -1.1409, -0.0158, -0.6847, -0.2356,  0.3930,\n",
      "         0.1330,  1.1711], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3756,  0.8288,  0.3165, -1.1418, -0.0142, -0.6854, -0.2357,  0.3950,\n",
      "         0.1323,  1.1722], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3770,  0.8295,  0.3162, -1.1415, -0.0156, -0.6866, -0.2359,  0.3957,\n",
      "         0.1342,  1.1724], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3781,  0.8299,  0.3165, -1.1428, -0.0138, -0.6867, -0.2356,  0.3936,\n",
      "         0.1322,  1.1728], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3793,  0.8298,  0.3167, -1.1428, -0.0158, -0.6875, -0.2356,  0.3949,\n",
      "         0.1341,  1.1738], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3805,  0.8315,  0.3173, -1.1451, -0.0144, -0.6874, -0.2370,  0.3943,\n",
      "         0.1320,  1.1747], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3816,  0.8309,  0.3167, -1.1450, -0.0148, -0.6867, -0.2360,  0.3946,\n",
      "         0.1334,  1.1754], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3830,  0.8318,  0.3182, -1.1449, -0.0146, -0.6881, -0.2364,  0.3957,\n",
      "         0.1323,  1.1749], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3840,  0.8313,  0.3174, -1.1460, -0.0141, -0.6883, -0.2359,  0.3953,\n",
      "         0.1333,  1.1765], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3855,  0.8330,  0.3178, -1.1450, -0.0140, -0.6879, -0.2374,  0.3956,\n",
      "         0.1319,  1.1759], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3864,  0.8320,  0.3174, -1.1463, -0.0160, -0.6888, -0.2361,  0.3950,\n",
      "         0.1338,  1.1774], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3878,  0.8347,  0.3176, -1.1476, -0.0136, -0.6896, -0.2383,  0.3969,\n",
      "         0.1322,  1.1782], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3889,  0.8332,  0.3183, -1.1476, -0.0170, -0.6902, -0.2358,  0.3959,\n",
      "         0.1336,  1.1786], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3899,  0.8356,  0.3179, -1.1500, -0.0146, -0.6889, -0.2364,  0.3965,\n",
      "         0.1327,  1.1789], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3914,  0.8338,  0.3189, -1.1489, -0.0162, -0.6921, -0.2364,  0.3965,\n",
      "         0.1335,  1.1794], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3925,  0.8371,  0.3182, -1.1518, -0.0151, -0.6896, -0.2372,  0.3969,\n",
      "         0.1332,  1.1800], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3939,  0.8345,  0.3194, -1.1494, -0.0154, -0.6931, -0.2379,  0.3976,\n",
      "         0.1333,  1.1808], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3948,  0.8363,  0.3178, -1.1512, -0.0152, -0.6907, -0.2379,  0.3970,\n",
      "         0.1322,  1.1809], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3968,  0.8361,  0.3192, -1.1511, -0.0150, -0.6933, -0.2373,  0.3984,\n",
      "         0.1344,  1.1817], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3970,  0.8383,  0.3183, -1.1537, -0.0139, -0.6919, -0.2381,  0.3962,\n",
      "         0.1331,  1.1821], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3990,  0.8365,  0.3197, -1.1513, -0.0157, -0.6938, -0.2379,  0.3981,\n",
      "         0.1344,  1.1830], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.3994,  0.8382,  0.3184, -1.1543, -0.0146, -0.6923, -0.2377,  0.3973,\n",
      "         0.1317,  1.1829], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4012,  0.8375,  0.3195, -1.1527, -0.0143, -0.6938, -0.2383,  0.3984,\n",
      "         0.1343,  1.1853], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4018,  0.8387,  0.3190, -1.1536, -0.0158, -0.6946, -0.2376,  0.3979,\n",
      "         0.1326,  1.1834], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4034,  0.8387,  0.3202, -1.1531, -0.0146, -0.6953, -0.2379,  0.3987,\n",
      "         0.1342,  1.1852], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4044,  0.8393,  0.3190, -1.1546, -0.0160, -0.6949, -0.2378,  0.3982,\n",
      "         0.1328,  1.1848], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4056,  0.8397,  0.3203, -1.1554, -0.0140, -0.6953, -0.2388,  0.3998,\n",
      "         0.1348,  1.1868], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4068,  0.8404,  0.3186, -1.1560, -0.0172, -0.6957, -0.2380,  0.3993,\n",
      "         0.1333,  1.1862], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4078,  0.8417,  0.3203, -1.1561, -0.0132, -0.6955, -0.2396,  0.3998,\n",
      "         0.1334,  1.1882], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4094,  0.8406,  0.3203, -1.1584, -0.0168, -0.6966, -0.2387,  0.3990,\n",
      "         0.1322,  1.1882], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4102,  0.8430,  0.3210, -1.1572, -0.0139, -0.6957, -0.2402,  0.3995,\n",
      "         0.1337,  1.1891], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4117,  0.8416,  0.3203, -1.1591, -0.0158, -0.6988, -0.2381,  0.3994,\n",
      "         0.1333,  1.1891], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4127,  0.8439,  0.3209, -1.1582, -0.0147, -0.6966, -0.2402,  0.4000,\n",
      "         0.1337,  1.1896], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4138,  0.8421,  0.3210, -1.1590, -0.0163, -0.6977, -0.2377,  0.3997,\n",
      "         0.1349,  1.1896], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4150,  0.8445,  0.3214, -1.1599, -0.0141, -0.6965, -0.2399,  0.3992,\n",
      "         0.1341,  1.1906], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4166,  0.8436,  0.3216, -1.1610, -0.0162, -0.6993, -0.2393,  0.4004,\n",
      "         0.1345,  1.1909], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4174,  0.8458,  0.3212, -1.1609, -0.0149, -0.6972, -0.2396,  0.4001,\n",
      "         0.1335,  1.1921], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4191,  0.8442,  0.3218, -1.1621, -0.0149, -0.6992, -0.2411,  0.4009,\n",
      "         0.1336,  1.1931], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4197,  0.8460,  0.3220, -1.1632, -0.0151, -0.6983, -0.2400,  0.4008,\n",
      "         0.1335,  1.1932], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4215,  0.8457,  0.3226, -1.1632, -0.0149, -0.7005, -0.2400,  0.4012,\n",
      "         0.1346,  1.1932], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4223,  0.8453,  0.3228, -1.1632, -0.0148, -0.6997, -0.2418,  0.4018,\n",
      "         0.1343,  1.1948], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4235,  0.8464,  0.3227, -1.1646, -0.0141, -0.7015, -0.2400,  0.4025,\n",
      "         0.1337,  1.1953], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4249,  0.8456,  0.3233, -1.1634, -0.0150, -0.7004, -0.2405,  0.4020,\n",
      "         0.1360,  1.1945], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4261,  0.8480,  0.3237, -1.1652, -0.0140, -0.7021, -0.2418,  0.4026,\n",
      "         0.1333,  1.1963], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4271,  0.8476,  0.3235, -1.1640, -0.0167, -0.7019, -0.2405,  0.4020,\n",
      "         0.1350,  1.1961], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4281,  0.8478,  0.3227, -1.1662, -0.0126, -0.7019, -0.2415,  0.4019,\n",
      "         0.1330,  1.1979], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4297,  0.8486,  0.3233, -1.1664, -0.0166, -0.7035, -0.2410,  0.4027,\n",
      "         0.1349,  1.1973], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4303,  0.8501,  0.3232, -1.1678, -0.0127, -0.7015, -0.2415,  0.4018,\n",
      "         0.1340,  1.1988], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4323,  0.8493,  0.3233, -1.1664, -0.0171, -0.7042, -0.2413,  0.4023,\n",
      "         0.1352,  1.1975], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4325,  0.8519,  0.3241, -1.1701, -0.0123, -0.7020, -0.2427,  0.4028,\n",
      "         0.1341,  1.2005], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4347,  0.8502,  0.3232, -1.1687, -0.0168, -0.7040, -0.2413,  0.4028,\n",
      "         0.1352,  1.2002], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4350,  0.8523,  0.3239, -1.1700, -0.0124, -0.7032, -0.2422,  0.4037,\n",
      "         0.1345,  1.1999], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4366,  0.8503,  0.3232, -1.1703, -0.0170, -0.7064, -0.2421,  0.4037,\n",
      "         0.1358,  1.2004], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4377,  0.8526,  0.3242, -1.1719, -0.0137, -0.7024, -0.2426,  0.4044,\n",
      "         0.1338,  1.2028], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4392,  0.8509,  0.3234, -1.1713, -0.0164, -0.7066, -0.2413,  0.4038,\n",
      "         0.1364,  1.2016], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4398,  0.8543,  0.3251, -1.1724, -0.0148, -0.7041, -0.2426,  0.4038,\n",
      "         0.1342,  1.2034], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4419,  0.8523,  0.3238, -1.1720, -0.0147, -0.7082, -0.2422,  0.4043,\n",
      "         0.1360,  1.2030], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4425,  0.8543,  0.3247, -1.1718, -0.0149, -0.7052, -0.2430,  0.4044,\n",
      "         0.1342,  1.2052], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4438,  0.8533,  0.3244, -1.1734, -0.0144, -0.7082, -0.2419,  0.4052,\n",
      "         0.1367,  1.2041], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4451,  0.8549,  0.3241, -1.1732, -0.0146, -0.7057, -0.2439,  0.4043,\n",
      "         0.1333,  1.2056], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4460,  0.8536,  0.3243, -1.1738, -0.0151, -0.7088, -0.2420,  0.4053,\n",
      "         0.1359,  1.2056], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4476,  0.8560,  0.3254, -1.1755, -0.0152, -0.7061, -0.2432,  0.4052,\n",
      "         0.1348,  1.2067], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4486,  0.8550,  0.3266, -1.1756, -0.0152, -0.7096, -0.2423,  0.4060,\n",
      "         0.1358,  1.2062], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4498,  0.8571,  0.3254, -1.1766, -0.0140, -0.7068, -0.2445,  0.4053,\n",
      "         0.1341,  1.2079], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4509,  0.8551,  0.3262, -1.1768, -0.0157, -0.7103, -0.2426,  0.4052,\n",
      "         0.1354,  1.2074], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4519,  0.8590,  0.3264, -1.1783, -0.0131, -0.7084, -0.2447,  0.4063,\n",
      "         0.1355,  1.2095], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4532,  0.8563,  0.3257, -1.1771, -0.0160, -0.7106, -0.2423,  0.4051,\n",
      "         0.1363,  1.2087], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4542,  0.8589,  0.3266, -1.1793, -0.0132, -0.7089, -0.2447,  0.4071,\n",
      "         0.1360,  1.2108], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4556,  0.8575,  0.3270, -1.1797, -0.0164, -0.7113, -0.2432,  0.4068,\n",
      "         0.1350,  1.2105], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4565,  0.8595,  0.3272, -1.1787, -0.0135, -0.7106, -0.2447,  0.4073,\n",
      "         0.1359,  1.2109], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4580,  0.8588,  0.3261, -1.1813, -0.0162, -0.7125, -0.2437,  0.4073,\n",
      "         0.1352,  1.2112], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4592,  0.8597,  0.3274, -1.1800, -0.0134, -0.7109, -0.2449,  0.4079,\n",
      "         0.1348,  1.2122], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4604,  0.8597,  0.3265, -1.1823, -0.0148, -0.7129, -0.2439,  0.4078,\n",
      "         0.1362,  1.2121], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4614,  0.8592,  0.3281, -1.1798, -0.0143, -0.7129, -0.2446,  0.4074,\n",
      "         0.1361,  1.2124], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4626,  0.8618,  0.3269, -1.1842, -0.0163, -0.7135, -0.2445,  0.4085,\n",
      "         0.1343,  1.2129], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4639,  0.8591,  0.3278, -1.1808, -0.0136, -0.7127, -0.2448,  0.4085,\n",
      "         0.1354,  1.2142], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4652,  0.8631,  0.3284, -1.1852, -0.0155, -0.7143, -0.2450,  0.4089,\n",
      "         0.1353,  1.2146], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4662,  0.8595,  0.3286, -1.1821, -0.0138, -0.7149, -0.2453,  0.4089,\n",
      "         0.1358,  1.2158], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4672,  0.8636,  0.3277, -1.1846, -0.0150, -0.7133, -0.2445,  0.4077,\n",
      "         0.1351,  1.2149], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4686,  0.8613,  0.3291, -1.1841, -0.0137, -0.7152, -0.2460,  0.4103,\n",
      "         0.1367,  1.2170], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4698,  0.8632,  0.3280, -1.1849, -0.0154, -0.7148, -0.2447,  0.4080,\n",
      "         0.1356,  1.2156], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4712,  0.8624,  0.3293, -1.1849, -0.0130, -0.7160, -0.2463,  0.4103,\n",
      "         0.1367,  1.2180], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4722,  0.8655,  0.3288, -1.1871, -0.0155, -0.7144, -0.2455,  0.4083,\n",
      "         0.1337,  1.2173], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4738,  0.8631,  0.3292, -1.1858, -0.0148, -0.7178, -0.2461,  0.4107,\n",
      "         0.1370,  1.2191], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4742,  0.8662,  0.3286, -1.1896, -0.0146, -0.7159, -0.2455,  0.4097,\n",
      "         0.1346,  1.2187], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4760,  0.8650,  0.3292, -1.1878, -0.0150, -0.7178, -0.2456,  0.4099,\n",
      "         0.1374,  1.2197], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4766,  0.8665,  0.3289, -1.1892, -0.0132, -0.7163, -0.2467,  0.4095,\n",
      "         0.1361,  1.2213], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4784,  0.8661,  0.3294, -1.1892, -0.0155, -0.7187, -0.2461,  0.4113,\n",
      "         0.1371,  1.2212], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4794,  0.8670,  0.3295, -1.1903, -0.0141, -0.7161, -0.2464,  0.4098,\n",
      "         0.1360,  1.2222], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4807,  0.8664,  0.3295, -1.1895, -0.0162, -0.7188, -0.2468,  0.4113,\n",
      "         0.1372,  1.2216], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4814,  0.8683,  0.3300, -1.1918, -0.0127, -0.7182, -0.2477,  0.4108,\n",
      "         0.1356,  1.2228], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4832,  0.8673,  0.3303, -1.1912, -0.0161, -0.7207, -0.2466,  0.4106,\n",
      "         0.1380,  1.2232], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4840,  0.8697,  0.3303, -1.1933, -0.0135, -0.7176, -0.2476,  0.4102,\n",
      "         0.1347,  1.2240], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4855,  0.8683,  0.3297, -1.1925, -0.0175, -0.7217, -0.2457,  0.4117,\n",
      "         0.1383,  1.2236], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4867,  0.8711,  0.3302, -1.1940, -0.0127, -0.7191, -0.2487,  0.4116,\n",
      "         0.1354,  1.2261], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4875,  0.8690,  0.3303, -1.1946, -0.0163, -0.7217, -0.2461,  0.4119,\n",
      "         0.1385,  1.2251], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4890,  0.8728,  0.3308, -1.1951, -0.0148, -0.7195, -0.2475,  0.4129,\n",
      "         0.1365,  1.2269], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4902,  0.8693,  0.3311, -1.1949, -0.0157, -0.7225, -0.2462,  0.4129,\n",
      "         0.1372,  1.2257], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4909,  0.8730,  0.3316, -1.1965, -0.0134, -0.7199, -0.2484,  0.4123,\n",
      "         0.1372,  1.2279], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4925,  0.8718,  0.3308, -1.1961, -0.0171, -0.7237, -0.2467,  0.4121,\n",
      "         0.1376,  1.2272], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4937,  0.8730,  0.3313, -1.1965, -0.0142, -0.7205, -0.2480,  0.4127,\n",
      "         0.1364,  1.2287], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4948,  0.8733,  0.3317, -1.1974, -0.0153, -0.7243, -0.2487,  0.4131,\n",
      "         0.1362,  1.2305], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4962,  0.8738,  0.3317, -1.1994, -0.0146, -0.7219, -0.2478,  0.4141,\n",
      "         0.1373,  1.2291], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4972,  0.8741,  0.3318, -1.1985, -0.0136, -0.7240, -0.2486,  0.4127,\n",
      "         0.1358,  1.2304], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4985,  0.8743,  0.3325, -1.2003, -0.0153, -0.7231, -0.2477,  0.4144,\n",
      "         0.1381,  1.2306], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.4997,  0.8739,  0.3323, -1.2000, -0.0145, -0.7249, -0.2479,  0.4141,\n",
      "         0.1366,  1.2308], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5009,  0.8736,  0.3327, -1.2003, -0.0151, -0.7247, -0.2483,  0.4151,\n",
      "         0.1385,  1.2312], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5024,  0.8761,  0.3330, -1.2001, -0.0154, -0.7250, -0.2485,  0.4138,\n",
      "         0.1363,  1.2319], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5034,  0.8752,  0.3323, -1.2001, -0.0146, -0.7260, -0.2496,  0.4144,\n",
      "         0.1382,  1.2326], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5047,  0.8766,  0.3324, -1.2020, -0.0138, -0.7254, -0.2505,  0.4144,\n",
      "         0.1356,  1.2332], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5060,  0.8768,  0.3328, -1.2019, -0.0156, -0.7268, -0.2494,  0.4143,\n",
      "         0.1373,  1.2340], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5067,  0.8778,  0.3324, -1.2046, -0.0138, -0.7252, -0.2494,  0.4152,\n",
      "         0.1369,  1.2350], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5085,  0.8772,  0.3337, -1.2034, -0.0166, -0.7277, -0.2489,  0.4155,\n",
      "         0.1386,  1.2347], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5090,  0.8793,  0.3328, -1.2055, -0.0131, -0.7254, -0.2500,  0.4155,\n",
      "         0.1367,  1.2363], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5110,  0.8785,  0.3340, -1.2045, -0.0164, -0.7290, -0.2495,  0.4154,\n",
      "         0.1380,  1.2370], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5115,  0.8800,  0.3339, -1.2063, -0.0130, -0.7265, -0.2499,  0.4155,\n",
      "         0.1375,  1.2361], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5133,  0.8791,  0.3336, -1.2059, -0.0164, -0.7294, -0.2491,  0.4156,\n",
      "         0.1387,  1.2374], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5140,  0.8802,  0.3337, -1.2068, -0.0131, -0.7275, -0.2508,  0.4173,\n",
      "         0.1375,  1.2386], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5157,  0.8799,  0.3343, -1.2073, -0.0151, -0.7284, -0.2498,  0.4157,\n",
      "         0.1385,  1.2395], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5169,  0.8817,  0.3350, -1.2072, -0.0150, -0.7295, -0.2500,  0.4170,\n",
      "         0.1380,  1.2386], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5179,  0.8798,  0.3347, -1.2071, -0.0152, -0.7295, -0.2500,  0.4164,\n",
      "         0.1389,  1.2399], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5193,  0.8826,  0.3350, -1.2091, -0.0138, -0.7300, -0.2516,  0.4179,\n",
      "         0.1378,  1.2400], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5203,  0.8812,  0.3356, -1.2085, -0.0156, -0.7300, -0.2511,  0.4169,\n",
      "         0.1383,  1.2421], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5215,  0.8829,  0.3359, -1.2106, -0.0135, -0.7307, -0.2507,  0.4179,\n",
      "         0.1384,  1.2413], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5230,  0.8825,  0.3352, -1.2101, -0.0156, -0.7310, -0.2516,  0.4166,\n",
      "         0.1390,  1.2425], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5238,  0.8845,  0.3358, -1.2125, -0.0140, -0.7318, -0.2511,  0.4186,\n",
      "         0.1375,  1.2424], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5251,  0.8820,  0.3355, -1.2109, -0.0162, -0.7317, -0.2510,  0.4182,\n",
      "         0.1396,  1.2432], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5263,  0.8853,  0.3359, -1.2135, -0.0137, -0.7323, -0.2519,  0.4180,\n",
      "         0.1375,  1.2436], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5277,  0.8832,  0.3359, -1.2121, -0.0158, -0.7324, -0.2510,  0.4180,\n",
      "         0.1402,  1.2438], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5284,  0.8874,  0.3360, -1.2145, -0.0132, -0.7328, -0.2533,  0.4192,\n",
      "         0.1371,  1.2457], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5301,  0.8851,  0.3360, -1.2144, -0.0156, -0.7329, -0.2525,  0.4194,\n",
      "         0.1392,  1.2458], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5310,  0.8870,  0.3376, -1.2148, -0.0141, -0.7340, -0.2523,  0.4195,\n",
      "         0.1381,  1.2461], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5326,  0.8866,  0.3369, -1.2150, -0.0150, -0.7332, -0.2523,  0.4194,\n",
      "         0.1387,  1.2469], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5337,  0.8875,  0.3373, -1.2152, -0.0143, -0.7357, -0.2532,  0.4201,\n",
      "         0.1389,  1.2471], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5347,  0.8870,  0.3366, -1.2165, -0.0154, -0.7336, -0.2518,  0.4193,\n",
      "         0.1392,  1.2477], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5363,  0.8882,  0.3377, -1.2168, -0.0126, -0.7353, -0.2533,  0.4191,\n",
      "         0.1376,  1.2486], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5372,  0.8870,  0.3372, -1.2167, -0.0148, -0.7359, -0.2526,  0.4203,\n",
      "         0.1398,  1.2494], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5386,  0.8898,  0.3385, -1.2181, -0.0140, -0.7363, -0.2525,  0.4211,\n",
      "         0.1382,  1.2488], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5398,  0.8883,  0.3373, -1.2175, -0.0153, -0.7367, -0.2528,  0.4200,\n",
      "         0.1394,  1.2507], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5409,  0.8901,  0.3377, -1.2192, -0.0125, -0.7360, -0.2535,  0.4210,\n",
      "         0.1388,  1.2509], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5423,  0.8891,  0.3381, -1.2187, -0.0164, -0.7384, -0.2535,  0.4205,\n",
      "         0.1392,  1.2513], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5434,  0.8910,  0.3375, -1.2211, -0.0134, -0.7357, -0.2536,  0.4202,\n",
      "         0.1386,  1.2518], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5448,  0.8904,  0.3376, -1.2202, -0.0153, -0.7390, -0.2530,  0.4212,\n",
      "         0.1404,  1.2526], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5458,  0.8923,  0.3383, -1.2228, -0.0147, -0.7380, -0.2543,  0.4213,\n",
      "         0.1384,  1.2531], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5470,  0.8904,  0.3381, -1.2215, -0.0155, -0.7399, -0.2530,  0.4220,\n",
      "         0.1407,  1.2530], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5481,  0.8924,  0.3386, -1.2230, -0.0139, -0.7385, -0.2543,  0.4214,\n",
      "         0.1389,  1.2546], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5495,  0.8916,  0.3390, -1.2221, -0.0160, -0.7401, -0.2541,  0.4223,\n",
      "         0.1394,  1.2545], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5508,  0.8945,  0.3389, -1.2250, -0.0154, -0.7401, -0.2547,  0.4225,\n",
      "         0.1378,  1.2556], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5520,  0.8920,  0.3397, -1.2230, -0.0151, -0.7400, -0.2541,  0.4236,\n",
      "         0.1394,  1.2559], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5528,  0.8954,  0.3391, -1.2262, -0.0146, -0.7395, -0.2552,  0.4228,\n",
      "         0.1383,  1.2569], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5544,  0.8933,  0.3396, -1.2240, -0.0142, -0.7406, -0.2545,  0.4225,\n",
      "         0.1395,  1.2579], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5552,  0.8954,  0.3390, -1.2276, -0.0138, -0.7408, -0.2547,  0.4227,\n",
      "         0.1385,  1.2580], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5568,  0.8942,  0.3403, -1.2250, -0.0149, -0.7428, -0.2544,  0.4241,\n",
      "         0.1401,  1.2583], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5576,  0.8964,  0.3400, -1.2278, -0.0134, -0.7414, -0.2554,  0.4235,\n",
      "         0.1385,  1.2592], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5592,  0.8946,  0.3407, -1.2273, -0.0153, -0.7425, -0.2543,  0.4232,\n",
      "         0.1397,  1.2592], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5603,  0.8988,  0.3405, -1.2300, -0.0148, -0.7423, -0.2550,  0.4238,\n",
      "         0.1392,  1.2606], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5616,  0.8943,  0.3407, -1.2281, -0.0153, -0.7444, -0.2545,  0.4243,\n",
      "         0.1399,  1.2604], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5627,  0.8992,  0.3401, -1.2297, -0.0152, -0.7420, -0.2558,  0.4238,\n",
      "         0.1399,  1.2613], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5639,  0.8957,  0.3407, -1.2287, -0.0156, -0.7443, -0.2538,  0.4240,\n",
      "         0.1405,  1.2612], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5648,  0.9000,  0.3410, -1.2308, -0.0138, -0.7438, -0.2574,  0.4242,\n",
      "         0.1395,  1.2631], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5662,  0.8971,  0.3401, -1.2312, -0.0154, -0.7445, -0.2550,  0.4241,\n",
      "         0.1400,  1.2628], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5671,  0.8997,  0.3412, -1.2305, -0.0133, -0.7452, -0.2571,  0.4247,\n",
      "         0.1406,  1.2632], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5686,  0.8987,  0.3408, -1.2315, -0.0160, -0.7460, -0.2549,  0.4249,\n",
      "         0.1406,  1.2642], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5697,  0.8995,  0.3411, -1.2315, -0.0138, -0.7458, -0.2570,  0.4249,\n",
      "         0.1413,  1.2640], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5708,  0.9008,  0.3409, -1.2330, -0.0145, -0.7468, -0.2567,  0.4250,\n",
      "         0.1389,  1.2649], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5724,  0.9011,  0.3420, -1.2343, -0.0144, -0.7457, -0.2567,  0.4260,\n",
      "         0.1416,  1.2661], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5732,  0.9013,  0.3419, -1.2335, -0.0141, -0.7467, -0.2561,  0.4252,\n",
      "         0.1396,  1.2653], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5748,  0.9014,  0.3421, -1.2336, -0.0151, -0.7480, -0.2575,  0.4266,\n",
      "         0.1419,  1.2666], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5760,  0.9023,  0.3411, -1.2353, -0.0146, -0.7462, -0.2564,  0.4256,\n",
      "         0.1397,  1.2680], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5771,  0.9025,  0.3424, -1.2359, -0.0156, -0.7494, -0.2572,  0.4276,\n",
      "         0.1410,  1.2676], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5785,  0.9027,  0.3421, -1.2365, -0.0146, -0.7488, -0.2565,  0.4274,\n",
      "         0.1408,  1.2675], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5796,  0.9033,  0.3430, -1.2356, -0.0139, -0.7494, -0.2576,  0.4266,\n",
      "         0.1413,  1.2695], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5810,  0.9041,  0.3431, -1.2383, -0.0151, -0.7491, -0.2573,  0.4266,\n",
      "         0.1402,  1.2693], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5821,  0.9048,  0.3443, -1.2375, -0.0148, -0.7490, -0.2575,  0.4275,\n",
      "         0.1412,  1.2709], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5833,  0.9053,  0.3426, -1.2381, -0.0137, -0.7508, -0.2578,  0.4274,\n",
      "         0.1405,  1.2708], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5844,  0.9046,  0.3438, -1.2385, -0.0153, -0.7506, -0.2573,  0.4274,\n",
      "         0.1417,  1.2715], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5853,  0.9073,  0.3424, -1.2401, -0.0134, -0.7488, -0.2586,  0.4275,\n",
      "         0.1401,  1.2721], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5868,  0.9052,  0.3440, -1.2405, -0.0151, -0.7519, -0.2581,  0.4283,\n",
      "         0.1418,  1.2736], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5877,  0.9085,  0.3437, -1.2426, -0.0130, -0.7503, -0.2587,  0.4277,\n",
      "         0.1404,  1.2730], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5894,  0.9067,  0.3440, -1.2425, -0.0160, -0.7527, -0.2585,  0.4286,\n",
      "         0.1421,  1.2743], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5901,  0.9085,  0.3438, -1.2432, -0.0129, -0.7496, -0.2589,  0.4277,\n",
      "         0.1397,  1.2745], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5917,  0.9074,  0.3437, -1.2428, -0.0156, -0.7534, -0.2591,  0.4291,\n",
      "         0.1421,  1.2746], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5926,  0.9108,  0.3434, -1.2453, -0.0135, -0.7506, -0.2591,  0.4288,\n",
      "         0.1406,  1.2754], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5942,  0.9080,  0.3443, -1.2443, -0.0158, -0.7528, -0.2587,  0.4292,\n",
      "         0.1421,  1.2760], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5951,  0.9107,  0.3433, -1.2452, -0.0133, -0.7527, -0.2603,  0.4295,\n",
      "         0.1396,  1.2776], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5965,  0.9094,  0.3444, -1.2463, -0.0154, -0.7539, -0.2582,  0.4302,\n",
      "         0.1429,  1.2773], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5973,  0.9116,  0.3451, -1.2467, -0.0145, -0.7537, -0.2603,  0.4284,\n",
      "         0.1394,  1.2774], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5988,  0.9107,  0.3452, -1.2458, -0.0151, -0.7552, -0.2596,  0.4304,\n",
      "         0.1427,  1.2784], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.5999,  0.9114,  0.3441, -1.2474, -0.0151, -0.7536, -0.2592,  0.4284,\n",
      "         0.1407,  1.2781], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6014,  0.9106,  0.3458, -1.2469, -0.0141, -0.7557, -0.2601,  0.4311,\n",
      "         0.1419,  1.2801], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6026,  0.9133,  0.3455, -1.2486, -0.0154, -0.7560, -0.2598,  0.4305,\n",
      "         0.1405,  1.2797], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6037,  0.9124,  0.3466, -1.2486, -0.0138, -0.7560, -0.2596,  0.4311,\n",
      "         0.1422,  1.2807], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6049,  0.9144,  0.3450, -1.2500, -0.0158, -0.7554, -0.2604,  0.4301,\n",
      "         0.1407,  1.2812], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6065,  0.9128,  0.3467, -1.2482, -0.0145, -0.7573, -0.2595,  0.4313,\n",
      "         0.1417,  1.2817], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6071,  0.9141,  0.3455, -1.2519, -0.0149, -0.7560, -0.2604,  0.4320,\n",
      "         0.1416,  1.2824], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6091,  0.9139,  0.3471, -1.2501, -0.0133, -0.7576, -0.2615,  0.4312,\n",
      "         0.1416,  1.2841], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6095,  0.9143,  0.3455, -1.2532, -0.0140, -0.7560, -0.2598,  0.4322,\n",
      "         0.1419,  1.2837], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6116,  0.9152,  0.3472, -1.2513, -0.0138, -0.7587, -0.2612,  0.4326,\n",
      "         0.1427,  1.2843], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6121,  0.9162,  0.3467, -1.2541, -0.0149, -0.7565, -0.2598,  0.4313,\n",
      "         0.1414,  1.2850], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6140,  0.9167,  0.3479, -1.2532, -0.0139, -0.7598, -0.2616,  0.4326,\n",
      "         0.1428,  1.2855], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6146,  0.9169,  0.3472, -1.2551, -0.0140, -0.7579, -0.2607,  0.4317,\n",
      "         0.1428,  1.2860], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6162,  0.9170,  0.3481, -1.2540, -0.0161, -0.7603, -0.2599,  0.4322,\n",
      "         0.1427,  1.2865], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6169,  0.9172,  0.3464, -1.2565, -0.0126, -0.7581, -0.2621,  0.4330,\n",
      "         0.1417,  1.2876], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6185,  0.9173,  0.3478, -1.2556, -0.0147, -0.7621, -0.2608,  0.4325,\n",
      "         0.1413,  1.2881], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6195,  0.9185,  0.3479, -1.2567, -0.0125, -0.7591, -0.2627,  0.4335,\n",
      "         0.1426,  1.2888], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6212,  0.9183,  0.3485, -1.2574, -0.0149, -0.7617, -0.2612,  0.4325,\n",
      "         0.1412,  1.2892], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6216,  0.9216,  0.3488, -1.2585, -0.0143, -0.7603, -0.2632,  0.4343,\n",
      "         0.1408,  1.2897], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6234,  0.9180,  0.3479, -1.2575, -0.0152, -0.7628, -0.2608,  0.4326,\n",
      "         0.1428,  1.2900], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6244,  0.9216,  0.3480, -1.2585, -0.0140, -0.7617, -0.2647,  0.4347,\n",
      "         0.1398,  1.2909], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6256,  0.9193,  0.3494, -1.2588, -0.0153, -0.7632, -0.2616,  0.4328,\n",
      "         0.1427,  1.2899], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6268,  0.9230,  0.3481, -1.2607, -0.0142, -0.7637, -0.2631,  0.4349,\n",
      "         0.1409,  1.2920], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6280,  0.9206,  0.3490, -1.2591, -0.0164, -0.7641, -0.2617,  0.4348,\n",
      "         0.1426,  1.2918], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6289,  0.9222,  0.3493, -1.2618, -0.0133, -0.7633, -0.2626,  0.4347,\n",
      "         0.1410,  1.2923], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6306,  0.9224,  0.3488, -1.2599, -0.0165, -0.7635, -0.2625,  0.4345,\n",
      "         0.1441,  1.2932], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6310,  0.9240,  0.3495, -1.2625, -0.0132, -0.7625, -0.2639,  0.4342,\n",
      "         0.1407,  1.2941], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6331,  0.9225,  0.3498, -1.2622, -0.0157, -0.7661, -0.2632,  0.4352,\n",
      "         0.1431,  1.2944], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6337,  0.9251,  0.3501, -1.2634, -0.0129, -0.7645, -0.2641,  0.4353,\n",
      "         0.1417,  1.2953], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6356,  0.9242,  0.3499, -1.2629, -0.0154, -0.7653, -0.2633,  0.4355,\n",
      "         0.1433,  1.2954], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6363,  0.9253,  0.3504, -1.2631, -0.0128, -0.7652, -0.2644,  0.4360,\n",
      "         0.1414,  1.2970], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6378,  0.9247,  0.3505, -1.2640, -0.0158, -0.7672, -0.2635,  0.4358,\n",
      "         0.1423,  1.2971], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6387,  0.9264,  0.3511, -1.2658, -0.0136, -0.7665, -0.2644,  0.4366,\n",
      "         0.1419,  1.2974], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6401,  0.9258,  0.3518, -1.2651, -0.0143, -0.7679, -0.2640,  0.4367,\n",
      "         0.1437,  1.2987], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6415,  0.9260,  0.3515, -1.2659, -0.0146, -0.7682, -0.2641,  0.4362,\n",
      "         0.1427,  1.2975], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6423,  0.9262,  0.3516, -1.2660, -0.0132, -0.7658, -0.2634,  0.4365,\n",
      "         0.1443,  1.2996], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6440,  0.9269,  0.3513, -1.2679, -0.0139, -0.7694, -0.2655,  0.4374,\n",
      "         0.1420,  1.2991], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6449,  0.9267,  0.3515, -1.2682, -0.0152, -0.7661, -0.2633,  0.4374,\n",
      "         0.1436,  1.2997], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6461,  0.9293,  0.3510, -1.2694, -0.0139, -0.7691, -0.2651,  0.4374,\n",
      "         0.1425,  1.3006], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6474,  0.9283,  0.3519, -1.2694, -0.0148, -0.7691, -0.2642,  0.4390,\n",
      "         0.1445,  1.3006], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6486,  0.9290,  0.3521, -1.2694, -0.0139, -0.7695, -0.2659,  0.4377,\n",
      "         0.1432,  1.3030], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6497,  0.9295,  0.3523, -1.2690, -0.0132, -0.7697, -0.2655,  0.4388,\n",
      "         0.1434,  1.3020], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6508,  0.9302,  0.3530, -1.2700, -0.0155, -0.7705, -0.2654,  0.4381,\n",
      "         0.1425,  1.3037], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6523,  0.9307,  0.3524, -1.2712, -0.0138, -0.7700, -0.2653,  0.4397,\n",
      "         0.1433,  1.3034], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6533,  0.9303,  0.3527, -1.2706, -0.0162, -0.7700, -0.2650,  0.4383,\n",
      "         0.1426,  1.3046], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6547,  0.9321,  0.3534, -1.2723, -0.0134, -0.7703, -0.2666,  0.4395,\n",
      "         0.1424,  1.3050], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6558,  0.9312,  0.3528, -1.2720, -0.0158, -0.7722, -0.2650,  0.4390,\n",
      "         0.1433,  1.3053], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6568,  0.9334,  0.3532, -1.2745, -0.0133, -0.7708, -0.2661,  0.4395,\n",
      "         0.1417,  1.3063], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6582,  0.9320,  0.3524, -1.2733, -0.0157, -0.7737, -0.2653,  0.4401,\n",
      "         0.1443,  1.3066], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6592,  0.9339,  0.3528, -1.2758, -0.0131, -0.7706, -0.2663,  0.4391,\n",
      "         0.1428,  1.3069], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6609,  0.9331,  0.3531, -1.2756, -0.0160, -0.7743, -0.2663,  0.4401,\n",
      "         0.1446,  1.3075], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6616,  0.9350,  0.3529, -1.2779, -0.0145, -0.7723, -0.2660,  0.4400,\n",
      "         0.1420,  1.3072], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6634,  0.9340,  0.3533, -1.2758, -0.0156, -0.7752, -0.2666,  0.4400,\n",
      "         0.1441,  1.3091], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6642,  0.9366,  0.3530, -1.2777, -0.0135, -0.7729, -0.2680,  0.4401,\n",
      "         0.1426,  1.3104], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6656,  0.9344,  0.3541, -1.2780, -0.0161, -0.7748, -0.2659,  0.4403,\n",
      "         0.1447,  1.3106], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6665,  0.9371,  0.3534, -1.2797, -0.0141, -0.7747, -0.2673,  0.4406,\n",
      "         0.1434,  1.3099], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6681,  0.9357,  0.3543, -1.2788, -0.0158, -0.7771, -0.2665,  0.4420,\n",
      "         0.1447,  1.3114], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6689,  0.9367,  0.3542, -1.2793, -0.0129, -0.7744, -0.2668,  0.4414,\n",
      "         0.1433,  1.3122], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6707,  0.9364,  0.3552, -1.2797, -0.0155, -0.7768, -0.2672,  0.4412,\n",
      "         0.1452,  1.3132], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6713,  0.9373,  0.3538, -1.2799, -0.0137, -0.7756, -0.2672,  0.4413,\n",
      "         0.1431,  1.3125], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6732,  0.9373,  0.3554, -1.2804, -0.0160, -0.7775, -0.2681,  0.4417,\n",
      "         0.1453,  1.3135], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6736,  0.9381,  0.3541, -1.2823, -0.0120, -0.7757, -0.2685,  0.4422,\n",
      "         0.1446,  1.3145], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6754,  0.9378,  0.3557, -1.2821, -0.0169, -0.7774, -0.2670,  0.4419,\n",
      "         0.1449,  1.3145], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6766,  0.9404,  0.3559, -1.2825, -0.0136, -0.7768, -0.2690,  0.4419,\n",
      "         0.1440,  1.3153], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6777,  0.9389,  0.3557, -1.2818, -0.0166, -0.7787, -0.2672,  0.4429,\n",
      "         0.1449,  1.3152], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6791,  0.9413,  0.3555, -1.2828, -0.0121, -0.7785, -0.2696,  0.4431,\n",
      "         0.1439,  1.3179], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6802,  0.9399,  0.3562, -1.2847, -0.0156, -0.7787, -0.2669,  0.4421,\n",
      "         0.1447,  1.3161], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6816,  0.9417,  0.3557, -1.2839, -0.0127, -0.7792, -0.2700,  0.4434,\n",
      "         0.1434,  1.3197], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6828,  0.9406,  0.3562, -1.2853, -0.0152, -0.7813, -0.2678,  0.4435,\n",
      "         0.1436,  1.3170], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6838,  0.9434,  0.3564, -1.2856, -0.0132, -0.7800, -0.2700,  0.4428,\n",
      "         0.1453,  1.3199], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6851,  0.9424,  0.3571, -1.2873, -0.0150, -0.7826, -0.2688,  0.4443,\n",
      "         0.1448,  1.3190], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6862,  0.9438,  0.3567, -1.2864, -0.0131, -0.7804, -0.2706,  0.4438,\n",
      "         0.1441,  1.3207], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6874,  0.9427,  0.3570, -1.2882, -0.0140, -0.7822, -0.2683,  0.4436,\n",
      "         0.1454,  1.3197], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6889,  0.9439,  0.3575, -1.2881, -0.0140, -0.7827, -0.2696,  0.4449,\n",
      "         0.1445,  1.3208], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6899,  0.9435,  0.3581, -1.2884, -0.0140, -0.7825, -0.2685,  0.4448,\n",
      "         0.1460,  1.3210], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6911,  0.9460,  0.3574, -1.2901, -0.0141, -0.7827, -0.2702,  0.4457,\n",
      "         0.1445,  1.3233], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6923,  0.9441,  0.3578, -1.2900, -0.0144, -0.7842, -0.2686,  0.4456,\n",
      "         0.1463,  1.3221], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6935,  0.9465,  0.3575, -1.2907, -0.0134, -0.7819, -0.2707,  0.4447,\n",
      "         0.1441,  1.3243], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6947,  0.9445,  0.3581, -1.2913, -0.0147, -0.7846, -0.2691,  0.4456,\n",
      "         0.1454,  1.3238], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6960,  0.9472,  0.3580, -1.2920, -0.0141, -0.7830, -0.2698,  0.4458,\n",
      "         0.1455,  1.3246], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6974,  0.9459,  0.3585, -1.2929, -0.0149, -0.7862, -0.2694,  0.4466,\n",
      "         0.1457,  1.3250], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6981,  0.9468,  0.3583, -1.2934, -0.0122, -0.7833, -0.2715,  0.4465,\n",
      "         0.1455,  1.3262], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.6995,  0.9474,  0.3584, -1.2943, -0.0150, -0.7867, -0.2700,  0.4461,\n",
      "         0.1449,  1.3259], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7011,  0.9470,  0.3592, -1.2934, -0.0132, -0.7863, -0.2719,  0.4469,\n",
      "         0.1460,  1.3266], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7019,  0.9490,  0.3584, -1.2940, -0.0161, -0.7866, -0.2695,  0.4470,\n",
      "         0.1451,  1.3272], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7032,  0.9484,  0.3592, -1.2948, -0.0119, -0.7859, -0.2715,  0.4472,\n",
      "         0.1465,  1.3279], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7045,  0.9498,  0.3580, -1.2960, -0.0162, -0.7879, -0.2700,  0.4474,\n",
      "         0.1448,  1.3274], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7055,  0.9495,  0.3594, -1.2956, -0.0127, -0.7863, -0.2720,  0.4472,\n",
      "         0.1459,  1.3294], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7069,  0.9503,  0.3582, -1.2969, -0.0155, -0.7883, -0.2706,  0.4475,\n",
      "         0.1450,  1.3291], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7081,  0.9509,  0.3602, -1.2974, -0.0140, -0.7888, -0.2715,  0.4486,\n",
      "         0.1469,  1.3299], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7093,  0.9520,  0.3576, -1.2983, -0.0161, -0.7868, -0.2705,  0.4471,\n",
      "         0.1451,  1.3306], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7104,  0.9517,  0.3601, -1.2984, -0.0130, -0.7896, -0.2723,  0.4482,\n",
      "         0.1452,  1.3314], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7119,  0.9528,  0.3603, -1.3000, -0.0156, -0.7883, -0.2718,  0.4478,\n",
      "         0.1449,  1.3324], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7130,  0.9535,  0.3605, -1.3002, -0.0137, -0.7911, -0.2726,  0.4490,\n",
      "         0.1454,  1.3322], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7142,  0.9523,  0.3606, -1.3012, -0.0145, -0.7885, -0.2716,  0.4477,\n",
      "         0.1462,  1.3337], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7153,  0.9542,  0.3611, -1.3013, -0.0122, -0.7909, -0.2733,  0.4492,\n",
      "         0.1453,  1.3344], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7167,  0.9535,  0.3608, -1.3014, -0.0149, -0.7892, -0.2725,  0.4487,\n",
      "         0.1460,  1.3344], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7177,  0.9555,  0.3611, -1.3035, -0.0129, -0.7918, -0.2725,  0.4502,\n",
      "         0.1449,  1.3346], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7192,  0.9543,  0.3606, -1.3023, -0.0155, -0.7916, -0.2731,  0.4493,\n",
      "         0.1470,  1.3352], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7199,  0.9562,  0.3613, -1.3040, -0.0109, -0.7921, -0.2742,  0.4497,\n",
      "         0.1452,  1.3373], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7214,  0.9548,  0.3607, -1.3039, -0.0162, -0.7932, -0.2728,  0.4494,\n",
      "         0.1471,  1.3353], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7226,  0.9577,  0.3620, -1.3062, -0.0131, -0.7915, -0.2736,  0.4495,\n",
      "         0.1456,  1.3374], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7241,  0.9555,  0.3616, -1.3042, -0.0156, -0.7945, -0.2725,  0.4504,\n",
      "         0.1475,  1.3373], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7248,  0.9580,  0.3611, -1.3063, -0.0132, -0.7912, -0.2726,  0.4494,\n",
      "         0.1455,  1.3382], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7266,  0.9565,  0.3617, -1.3056, -0.0138, -0.7943, -0.2742,  0.4508,\n",
      "         0.1476,  1.3394], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7273,  0.9585,  0.3617, -1.3080, -0.0135, -0.7932, -0.2729,  0.4508,\n",
      "         0.1459,  1.3385], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7288,  0.9571,  0.3620, -1.3064, -0.0143, -0.7955, -0.2745,  0.4509,\n",
      "         0.1477,  1.3399], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7296,  0.9601,  0.3623, -1.3099, -0.0146, -0.7947, -0.2734,  0.4503,\n",
      "         0.1454,  1.3392], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7314,  0.9578,  0.3633, -1.3072, -0.0130, -0.7959, -0.2745,  0.4517,\n",
      "         0.1471,  1.3415], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7318,  0.9601,  0.3615, -1.3092, -0.0143, -0.7947, -0.2728,  0.4498,\n",
      "         0.1457,  1.3412], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7336,  0.9586,  0.3631, -1.3096, -0.0128, -0.7970, -0.2743,  0.4530,\n",
      "         0.1486,  1.3417], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7346,  0.9617,  0.3629, -1.3094, -0.0153, -0.7957, -0.2741,  0.4508,\n",
      "         0.1448,  1.3422], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7358,  0.9610,  0.3635, -1.3103, -0.0136, -0.7974, -0.2753,  0.4532,\n",
      "         0.1485,  1.3436], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7372,  0.9608,  0.3627, -1.3100, -0.0137, -0.7969, -0.2750,  0.4518,\n",
      "         0.1453,  1.3443], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7383,  0.9608,  0.3636, -1.3118, -0.0139, -0.7982, -0.2741,  0.4538,\n",
      "         0.1497,  1.3446], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7394,  0.9636,  0.3629, -1.3136, -0.0140, -0.7958, -0.2753,  0.4522,\n",
      "         0.1456,  1.3455], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7408,  0.9620,  0.3643, -1.3120, -0.0140, -0.7993, -0.2747,  0.4538,\n",
      "         0.1481,  1.3456], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7420,  0.9632,  0.3636, -1.3132, -0.0132, -0.7982, -0.2764,  0.4529,\n",
      "         0.1454,  1.3465], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7431,  0.9631,  0.3650, -1.3136, -0.0153, -0.7999, -0.2750,  0.4537,\n",
      "         0.1483,  1.3468], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7444,  0.9648,  0.3642, -1.3154, -0.0134, -0.7980, -0.2751,  0.4533,\n",
      "         0.1460,  1.3470], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7453,  0.9640,  0.3645, -1.3144, -0.0149, -0.8008, -0.2757,  0.4533,\n",
      "         0.1488,  1.3473], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7471,  0.9660,  0.3637, -1.3157, -0.0140, -0.7992, -0.2759,  0.4540,\n",
      "         0.1468,  1.3486], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7478,  0.9649,  0.3642, -1.3157, -0.0140, -0.8017, -0.2766,  0.4541,\n",
      "         0.1486,  1.3490], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7492,  0.9657,  0.3644, -1.3163, -0.0137, -0.7986, -0.2762,  0.4534,\n",
      "         0.1467,  1.3497], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7506,  0.9653,  0.3649, -1.3165, -0.0145, -0.8027, -0.2763,  0.4540,\n",
      "         0.1472,  1.3502], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7517,  0.9679,  0.3645, -1.3201, -0.0130, -0.8002, -0.2765,  0.4548,\n",
      "         0.1467,  1.3504], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7529,  0.9654,  0.3654, -1.3175, -0.0148, -0.8038, -0.2760,  0.4550,\n",
      "         0.1480,  1.3517], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7541,  0.9677,  0.3647, -1.3205, -0.0125, -0.8000, -0.2763,  0.4553,\n",
      "         0.1474,  1.3520], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7554,  0.9663,  0.3652, -1.3199, -0.0158, -0.8042, -0.2758,  0.4549,\n",
      "         0.1485,  1.3522], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7566,  0.9692,  0.3651, -1.3200, -0.0124, -0.8021, -0.2782,  0.4550,\n",
      "         0.1463,  1.3537], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7579,  0.9678,  0.3658, -1.3209, -0.0150, -0.8045, -0.2768,  0.4558,\n",
      "         0.1484,  1.3537], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7590,  0.9691,  0.3662, -1.3220, -0.0139, -0.8038, -0.2777,  0.4555,\n",
      "         0.1468,  1.3539], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7605,  0.9692,  0.3663, -1.3227, -0.0143, -0.8067, -0.2776,  0.4569,\n",
      "         0.1499,  1.3543], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7615,  0.9705,  0.3668, -1.3224, -0.0134, -0.8041, -0.2785,  0.4558,\n",
      "         0.1458,  1.3559], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7631,  0.9693,  0.3667, -1.3233, -0.0142, -0.8054, -0.2769,  0.4573,\n",
      "         0.1488,  1.3562], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7638,  0.9735,  0.3668, -1.3246, -0.0136, -0.8055, -0.2785,  0.4565,\n",
      "         0.1467,  1.3564], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7651,  0.9714,  0.3672, -1.3238, -0.0133, -0.8065, -0.2785,  0.4565,\n",
      "         0.1488,  1.3575], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7666,  0.9726,  0.3673, -1.3241, -0.0148, -0.8062, -0.2771,  0.4569,\n",
      "         0.1478,  1.3577], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7672,  0.9726,  0.3665, -1.3256, -0.0132, -0.8050, -0.2789,  0.4576,\n",
      "         0.1486,  1.3591], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7688,  0.9718,  0.3672, -1.3257, -0.0131, -0.8084, -0.2779,  0.4568,\n",
      "         0.1474,  1.3583], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7699,  0.9750,  0.3679, -1.3273, -0.0144, -0.8063, -0.2792,  0.4575,\n",
      "         0.1481,  1.3591], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7712,  0.9731,  0.3677, -1.3273, -0.0154, -0.8084, -0.2777,  0.4569,\n",
      "         0.1483,  1.3592], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7721,  0.9762,  0.3677, -1.3270, -0.0127, -0.8084, -0.2808,  0.4583,\n",
      "         0.1484,  1.3617], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7735,  0.9734,  0.3674, -1.3277, -0.0159, -0.8091, -0.2767,  0.4580,\n",
      "         0.1485,  1.3602], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7749,  0.9767,  0.3686, -1.3276, -0.0122, -0.8075, -0.2802,  0.4577,\n",
      "         0.1476,  1.3626], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7757,  0.9748,  0.3683, -1.3295, -0.0155, -0.8106, -0.2784,  0.4587,\n",
      "         0.1486,  1.3619], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7772,  0.9767,  0.3692, -1.3294, -0.0125, -0.8075, -0.2793,  0.4584,\n",
      "         0.1487,  1.3634], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7784,  0.9776,  0.3687, -1.3312, -0.0152, -0.8117, -0.2794,  0.4591,\n",
      "         0.1484,  1.3633], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7793,  0.9766,  0.3687, -1.3317, -0.0125, -0.8091, -0.2792,  0.4601,\n",
      "         0.1484,  1.3643], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7810,  0.9773,  0.3691, -1.3323, -0.0149, -0.8111, -0.2790,  0.4596,\n",
      "         0.1488,  1.3642], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7817,  0.9781,  0.3685, -1.3322, -0.0111, -0.8095, -0.2804,  0.4605,\n",
      "         0.1493,  1.3656], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7836,  0.9791,  0.3705, -1.3325, -0.0150, -0.8115, -0.2791,  0.4598,\n",
      "         0.1488,  1.3661], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7841,  0.9797,  0.3688, -1.3347, -0.0123, -0.8105, -0.2798,  0.4596,\n",
      "         0.1485,  1.3674], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7858,  0.9795,  0.3698, -1.3333, -0.0157, -0.8113, -0.2789,  0.4593,\n",
      "         0.1491,  1.3673], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7868,  0.9803,  0.3693, -1.3354, -0.0128, -0.8118, -0.2806,  0.4602,\n",
      "         0.1492,  1.3683], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7881,  0.9795,  0.3706, -1.3348, -0.0152, -0.8124, -0.2798,  0.4599,\n",
      "         0.1495,  1.3682], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7893,  0.9808,  0.3692, -1.3371, -0.0129, -0.8116, -0.2805,  0.4610,\n",
      "         0.1486,  1.3697], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7909,  0.9804,  0.3703, -1.3354, -0.0162, -0.8140, -0.2799,  0.4611,\n",
      "         0.1505,  1.3688], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7918,  0.9816,  0.3697, -1.3377, -0.0130, -0.8128, -0.2805,  0.4609,\n",
      "         0.1485,  1.3697], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7931,  0.9805,  0.3705, -1.3369, -0.0152, -0.8144, -0.2805,  0.4609,\n",
      "         0.1490,  1.3699], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7944,  0.9835,  0.3706, -1.3383, -0.0137, -0.8147, -0.2823,  0.4633,\n",
      "         0.1491,  1.3713], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7954,  0.9813,  0.3711, -1.3387, -0.0150, -0.8151, -0.2799,  0.4610,\n",
      "         0.1492,  1.3722], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7967,  0.9844,  0.3718, -1.3390, -0.0133, -0.8152, -0.2824,  0.4630,\n",
      "         0.1486,  1.3727], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7979,  0.9820,  0.3706, -1.3399, -0.0146, -0.8154, -0.2799,  0.4617,\n",
      "         0.1498,  1.3716], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.7992,  0.9855,  0.3715, -1.3397, -0.0130, -0.8154, -0.2830,  0.4625,\n",
      "         0.1485,  1.3743], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8005,  0.9836,  0.3727, -1.3411, -0.0150, -0.8170, -0.2807,  0.4621,\n",
      "         0.1492,  1.3734], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8013,  0.9860,  0.3713, -1.3415, -0.0131, -0.8158, -0.2831,  0.4626,\n",
      "         0.1484,  1.3758], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8030,  0.9835,  0.3731, -1.3415, -0.0145, -0.8174, -0.2805,  0.4626,\n",
      "         0.1502,  1.3746], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8035,  0.9869,  0.3714, -1.3427, -0.0139, -0.8165, -0.2814,  0.4628,\n",
      "         0.1492,  1.3760], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8055,  0.9866,  0.3730, -1.3431, -0.0153, -0.8185, -0.2815,  0.4637,\n",
      "         0.1496,  1.3767], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8060,  0.9875,  0.3717, -1.3459, -0.0131, -0.8167, -0.2818,  0.4633,\n",
      "         0.1501,  1.3770], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8078,  0.9875,  0.3734, -1.3441, -0.0151, -0.8189, -0.2818,  0.4642,\n",
      "         0.1500,  1.3778], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8085,  0.9882,  0.3722, -1.3458, -0.0129, -0.8198, -0.2839,  0.4645,\n",
      "         0.1496,  1.3784], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8102,  0.9879,  0.3737, -1.3448, -0.0149, -0.8202, -0.2817,  0.4632,\n",
      "         0.1489,  1.3782], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8111,  0.9879,  0.3733, -1.3462, -0.0136, -0.8208, -0.2837,  0.4652,\n",
      "         0.1506,  1.3789], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8128,  0.9895,  0.3734, -1.3466, -0.0148, -0.8202, -0.2818,  0.4634,\n",
      "         0.1486,  1.3795], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8135,  0.9887,  0.3736, -1.3473, -0.0126, -0.8218, -0.2839,  0.4653,\n",
      "         0.1520,  1.3805], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8147,  0.9916,  0.3736, -1.3483, -0.0141, -0.8196, -0.2832,  0.4636,\n",
      "         0.1483,  1.3812], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8160,  0.9887,  0.3742, -1.3482, -0.0138, -0.8227, -0.2829,  0.4650,\n",
      "         0.1512,  1.3815], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8169,  0.9928,  0.3732, -1.3510, -0.0145, -0.8211, -0.2833,  0.4649,\n",
      "         0.1488,  1.3821], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8187,  0.9901,  0.3745, -1.3487, -0.0137, -0.8224, -0.2835,  0.4661,\n",
      "         0.1509,  1.3825], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8196,  0.9924,  0.3733, -1.3502, -0.0139, -0.8221, -0.2837,  0.4650,\n",
      "         0.1498,  1.3832], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8209,  0.9912,  0.3757, -1.3503, -0.0133, -0.8239, -0.2834,  0.4660,\n",
      "         0.1515,  1.3835], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8218,  0.9933,  0.3734, -1.3518, -0.0139, -0.8218, -0.2839,  0.4655,\n",
      "         0.1485,  1.3841], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8238,  0.9919,  0.3749, -1.3512, -0.0149, -0.8241, -0.2833,  0.4667,\n",
      "         0.1509,  1.3853], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8243,  0.9952,  0.3748, -1.3546, -0.0130, -0.8227, -0.2841,  0.4655,\n",
      "         0.1494,  1.3856], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8262,  0.9940,  0.3749, -1.3531, -0.0138, -0.8254, -0.2845,  0.4673,\n",
      "         0.1514,  1.3874], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8267,  0.9953,  0.3751, -1.3549, -0.0131, -0.8221, -0.2838,  0.4652,\n",
      "         0.1498,  1.3863], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8287,  0.9936,  0.3758, -1.3540, -0.0144, -0.8264, -0.2846,  0.4664,\n",
      "         0.1500,  1.3877], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8289,  0.9959,  0.3747, -1.3571, -0.0120, -0.8247, -0.2854,  0.4668,\n",
      "         0.1495,  1.3878], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8308,  0.9963,  0.3758, -1.3559, -0.0147, -0.8253, -0.2849,  0.4665,\n",
      "         0.1509,  1.3898], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8316,  0.9963,  0.3762, -1.3562, -0.0142, -0.8251, -0.2849,  0.4678,\n",
      "         0.1508,  1.3878], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8331,  0.9957,  0.3762, -1.3556, -0.0151, -0.8256, -0.2839,  0.4668,\n",
      "         0.1507,  1.3898], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8341,  0.9975,  0.3760, -1.3573, -0.0128, -0.8260, -0.2849,  0.4680,\n",
      "         0.1504,  1.3900], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8356,  0.9960,  0.3772, -1.3577, -0.0145, -0.8275, -0.2850,  0.4675,\n",
      "         0.1514,  1.3913], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8367,  0.9979,  0.3767, -1.3573, -0.0140, -0.8270, -0.2847,  0.4681,\n",
      "         0.1504,  1.3914], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8380,  0.9982,  0.3777, -1.3584, -0.0146, -0.8283, -0.2857,  0.4679,\n",
      "         0.1515,  1.3923], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8391,  0.9987,  0.3768, -1.3601, -0.0129, -0.8270, -0.2854,  0.4675,\n",
      "         0.1506,  1.3924], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8405,  0.9984,  0.3773, -1.3580, -0.0144, -0.8293, -0.2860,  0.4684,\n",
      "         0.1515,  1.3932], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8411,  0.9992,  0.3764, -1.3612, -0.0125, -0.8268, -0.2854,  0.4676,\n",
      "         0.1503,  1.3934], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8430,  0.9993,  0.3771, -1.3609, -0.0138, -0.8301, -0.2865,  0.4699,\n",
      "         0.1513,  1.3949], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8438,  1.0014,  0.3769, -1.3617, -0.0144, -0.8289, -0.2855,  0.4687,\n",
      "         0.1504,  1.3943], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([10])\n",
      "tensor([ 2.8453,  0.9995,  0.3784, -1.3612, -0.0138, -0.8308, -0.2858,  0.4704,\n",
      "         0.1527,  1.3959], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model.eval() # fixed model\n",
    "\n",
    "# total_acc, total_top5 = AverageMeter(), AverageMeter()\n",
    "total_loss = AverageMeter()\n",
    "\n",
    "for step in range(1000):\n",
    "    # for c in range(1):\n",
    "    c=1\n",
    "    xx = clsmax.x_c[c]#.flatten()#.cuda()\n",
    "    #print(xx.size())\n",
    "    preds = model(xx.unsqueeze(0)) # cnn 1 x 3 x 32 x 32, expected dim\n",
    "    preds = preds.squeeze(0)\n",
    "\n",
    "    print(preds.size())\n",
    "    targs = torch.tensor(c)#.cuda()\n",
    "\n",
    "    loss = (preds[c] - lamb*(torch.norm(clsmax.x_c[c])))\n",
    "    (loss).backward()\n",
    "    # loss = loss_fn(preds, targs)\n",
    "    \n",
    "    # loss = loss / args.accum_steps\n",
    "    # loss.backward()\n",
    "\n",
    "    print(preds)\n",
    "    \n",
    "    grad = clsmax.x_c.grad / (torch.norm(clsmax.x_c.grad)+ 1e-5) # l2 norm, grads\n",
    "    clsmax.x_c = nn.Parameter(clsmax.x_c + grad*lr) # update step, gradient ascent\n",
    "    # opt.step()\n",
    "    # opt.zero_grad()\n",
    "\n",
    "    #total_loss.update(loss.item() * args.accum_steps, 1)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "# scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "ccba4f39",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'layout'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/alpayozkan/eth/dl_proj/class_maxim.ipynb Cell 49\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/alpayozkan/eth/dl_proj/class_maxim.ipynb#Y126sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m grad \u001b[39m=\u001b[39m clsmax\u001b[39m.\u001b[39mx_c\u001b[39m.\u001b[39mgrad \u001b[39m/\u001b[39m (torch\u001b[39m.\u001b[39;49mnorm(clsmax\u001b[39m.\u001b[39;49mx_c\u001b[39m.\u001b[39;49mgrad)\u001b[39m+\u001b[39m \u001b[39m1e-5\u001b[39m) \u001b[39m# l2 norm, grads\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alpayozkan/eth/dl_proj/class_maxim.ipynb#Y126sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m grad\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ex4/lib/python3.10/site-packages/torch/functional.py:1582\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m   1575\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   1576\u001b[0m         norm, (\u001b[39minput\u001b[39m,), \u001b[39minput\u001b[39m, p\u001b[39m=\u001b[39mp, dim\u001b[39m=\u001b[39mdim, keepdim\u001b[39m=\u001b[39mkeepdim, out\u001b[39m=\u001b[39mout, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m   1578\u001b[0m \u001b[39m# NB. All the repeated code and weird python is to please TorchScript.\u001b[39;00m\n\u001b[1;32m   1579\u001b[0m \u001b[39m#     For a more compact implementation see the relevant function in `_refs/__init__.py`\u001b[39;00m\n\u001b[1;32m   1580\u001b[0m \n\u001b[1;32m   1581\u001b[0m \u001b[39m# We don't do this for MPS or sparse tensors\u001b[39;00m\n\u001b[0;32m-> 1582\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49mlayout \u001b[39m==\u001b[39m torch\u001b[39m.\u001b[39mstrided \u001b[39mand\u001b[39;00m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdevice\u001b[39m.\u001b[39mtype \u001b[39min\u001b[39;00m \\\n\u001b[1;32m   1583\u001b[0m         (\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmeta\u001b[39m\u001b[39m\"\u001b[39m, torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mbackend_registration\u001b[39m.\u001b[39m_privateuse1_backend_name):\n\u001b[1;32m   1584\u001b[0m     \u001b[39mif\u001b[39;00m dim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1585\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dim, \u001b[39mint\u001b[39m):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'layout'"
     ]
    }
   ],
   "source": [
    "grad = clsmax.x_c.grad / (torch.norm(clsmax.x_c.grad)+ 1e-5) # l2 norm, grads\n",
    "grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256384b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6628d212",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "clsmax.x_c = clsmax.x_c + grad*lr # update step, gradient ascent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "11aeedde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "preds = model(xx.unsqueeze(0)) # cnn 1 x 3 x 32 x 32, expected dim\n",
    "preds = preds.squeeze(0)\n",
    "\n",
    "print(preds.size())\n",
    "targs = torch.tensor(c)#.cuda()\n",
    "\n",
    "loss = -preds[c] + lamb*(torch.norm(clsmax.x_c[c]))\n",
    "(loss).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "61932103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 32, 32])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clsmax.x_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "0c499bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2559)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(clsmax.x_c.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "6765d50c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2559)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(clsmax.x_c.grad[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "f94f6945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 3.6772e-04, -5.1931e-03,  2.2714e-03,  ..., -2.0196e-03,\n",
       "           -8.5167e-04,  1.8453e-03],\n",
       "          [ 6.6818e-04,  5.9691e-03, -1.3274e-03,  ...,  4.8924e-03,\n",
       "            1.9272e-03, -2.0007e-03],\n",
       "          [ 1.3825e-03, -4.3285e-04, -3.6058e-03,  ..., -4.0789e-03,\n",
       "            1.3792e-03,  2.2885e-04],\n",
       "          ...,\n",
       "          [-5.9478e-03,  4.2290e-03,  2.2372e-03,  ...,  9.0848e-04,\n",
       "           -7.7713e-04,  3.9812e-03],\n",
       "          [ 1.5608e-03,  9.8118e-04,  6.1146e-04,  ...,  2.2378e-03,\n",
       "           -1.4844e-03, -2.9392e-03],\n",
       "          [ 1.4714e-03, -2.3886e-03, -2.0476e-03,  ...,  2.4383e-03,\n",
       "           -3.5500e-03, -7.6746e-04]],\n",
       "\n",
       "         [[ 6.0295e-03, -5.4358e-03,  3.3974e-03,  ...,  2.9846e-03,\n",
       "           -2.1898e-03, -2.6742e-03],\n",
       "          [-5.9061e-03,  3.6545e-03, -1.3115e-04,  ...,  5.6619e-04,\n",
       "            5.0864e-03,  2.2871e-03],\n",
       "          [ 2.5569e-04,  7.3502e-03, -6.9699e-03,  ..., -1.4000e-03,\n",
       "           -1.6652e-03, -3.5039e-03],\n",
       "          ...,\n",
       "          [-2.6247e-03,  8.5443e-04, -6.7210e-04,  ...,  2.7496e-03,\n",
       "            2.3906e-03, -1.0110e-03],\n",
       "          [ 1.0332e-03, -9.1558e-04,  2.7326e-03,  ...,  3.8790e-03,\n",
       "            1.8155e-03, -2.5020e-04],\n",
       "          [ 1.7118e-03,  3.0810e-03,  6.2466e-04,  ...,  2.4983e-03,\n",
       "           -1.9011e-04, -9.2728e-04]],\n",
       "\n",
       "         [[ 3.2427e-03, -7.5404e-03,  4.1511e-04,  ...,  2.2272e-03,\n",
       "           -8.2055e-05,  1.2929e-03],\n",
       "          [ 2.5556e-03, -1.1161e-02,  9.2746e-03,  ...,  1.1353e-03,\n",
       "            2.7886e-04, -5.2608e-04],\n",
       "          [-3.7862e-05,  4.0790e-03,  3.6579e-03,  ..., -1.3226e-03,\n",
       "           -1.0329e-03, -5.1968e-04],\n",
       "          ...,\n",
       "          [ 2.6809e-03, -2.3708e-03,  1.3859e-03,  ...,  3.3017e-03,\n",
       "            1.4647e-03,  1.6129e-03],\n",
       "          [-2.7760e-03,  3.3379e-04,  1.1953e-03,  ..., -2.7442e-03,\n",
       "            3.0382e-03,  1.7424e-03],\n",
       "          [-2.6840e-03,  2.8708e-05,  1.1883e-03,  ..., -6.0863e-04,\n",
       "            2.1866e-03,  8.0513e-05]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]]]])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clsmax.x_c.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "a43cfe71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3.6772e-04, -5.1931e-03,  2.2714e-03,  ..., -2.0196e-03,\n",
       "          -8.5167e-04,  1.8453e-03],\n",
       "         [ 6.6818e-04,  5.9691e-03, -1.3274e-03,  ...,  4.8924e-03,\n",
       "           1.9272e-03, -2.0007e-03],\n",
       "         [ 1.3825e-03, -4.3285e-04, -3.6058e-03,  ..., -4.0789e-03,\n",
       "           1.3792e-03,  2.2885e-04],\n",
       "         ...,\n",
       "         [-5.9478e-03,  4.2290e-03,  2.2372e-03,  ...,  9.0848e-04,\n",
       "          -7.7713e-04,  3.9812e-03],\n",
       "         [ 1.5608e-03,  9.8118e-04,  6.1146e-04,  ...,  2.2378e-03,\n",
       "          -1.4844e-03, -2.9392e-03],\n",
       "         [ 1.4714e-03, -2.3886e-03, -2.0476e-03,  ...,  2.4383e-03,\n",
       "          -3.5500e-03, -7.6746e-04]],\n",
       "\n",
       "        [[ 6.0295e-03, -5.4358e-03,  3.3974e-03,  ...,  2.9846e-03,\n",
       "          -2.1898e-03, -2.6742e-03],\n",
       "         [-5.9061e-03,  3.6545e-03, -1.3115e-04,  ...,  5.6619e-04,\n",
       "           5.0864e-03,  2.2871e-03],\n",
       "         [ 2.5569e-04,  7.3502e-03, -6.9699e-03,  ..., -1.4000e-03,\n",
       "          -1.6652e-03, -3.5039e-03],\n",
       "         ...,\n",
       "         [-2.6247e-03,  8.5443e-04, -6.7210e-04,  ...,  2.7496e-03,\n",
       "           2.3906e-03, -1.0110e-03],\n",
       "         [ 1.0332e-03, -9.1558e-04,  2.7326e-03,  ...,  3.8790e-03,\n",
       "           1.8155e-03, -2.5020e-04],\n",
       "         [ 1.7118e-03,  3.0810e-03,  6.2466e-04,  ...,  2.4983e-03,\n",
       "          -1.9011e-04, -9.2728e-04]],\n",
       "\n",
       "        [[ 3.2427e-03, -7.5404e-03,  4.1511e-04,  ...,  2.2272e-03,\n",
       "          -8.2055e-05,  1.2929e-03],\n",
       "         [ 2.5556e-03, -1.1161e-02,  9.2746e-03,  ...,  1.1353e-03,\n",
       "           2.7886e-04, -5.2608e-04],\n",
       "         [-3.7862e-05,  4.0790e-03,  3.6579e-03,  ..., -1.3226e-03,\n",
       "          -1.0329e-03, -5.1968e-04],\n",
       "         ...,\n",
       "         [ 2.6809e-03, -2.3708e-03,  1.3859e-03,  ...,  3.3017e-03,\n",
       "           1.4647e-03,  1.6129e-03],\n",
       "         [-2.7760e-03,  3.3379e-04,  1.1953e-03,  ..., -2.7442e-03,\n",
       "           3.0382e-03,  1.7424e-03],\n",
       "         [-2.6840e-03,  2.8708e-05,  1.1883e-03,  ..., -6.0863e-04,\n",
       "           2.1866e-03,  8.0513e-05]]])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clsmax.x_c.grad[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "2cb48fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0149, -0.0115, -0.0360,  ..., -0.0096, -0.0024, -0.0012],\n",
       "         [-0.0234,  0.0226, -0.0139,  ..., -0.0054,  0.0100,  0.0133],\n",
       "         [ 0.0055,  0.0152,  0.0389,  ...,  0.0435, -0.0021, -0.0061],\n",
       "         ...,\n",
       "         [-0.0080, -0.0079, -0.0125,  ..., -0.0119,  0.0080,  0.0033],\n",
       "         [ 0.0309,  0.0095, -0.0230,  ...,  0.0040, -0.0048,  0.0055],\n",
       "         [-0.0004, -0.0187, -0.0008,  ...,  0.0018, -0.0012, -0.0080]],\n",
       "\n",
       "        [[-0.0082, -0.0018, -0.0164,  ..., -0.0088, -0.0026,  0.0003],\n",
       "         [-0.0035, -0.0118,  0.0027,  ..., -0.0107, -0.0020, -0.0023],\n",
       "         [ 0.0047, -0.0211,  0.0237,  ...,  0.0319, -0.0016, -0.0142],\n",
       "         ...,\n",
       "         [-0.0019, -0.0022, -0.0053,  ..., -0.0101, -0.0036,  0.0006],\n",
       "         [ 0.0115, -0.0148, -0.0025,  ...,  0.0056, -0.0052, -0.0054],\n",
       "         [ 0.0211, -0.0002, -0.0188,  ..., -0.0027,  0.0101,  0.0064]],\n",
       "\n",
       "        [[ 0.0262,  0.0010, -0.0148,  ..., -0.0043,  0.0006, -0.0084],\n",
       "         [-0.0135,  0.0038, -0.0006,  ...,  0.0013,  0.0025,  0.0149],\n",
       "         [-0.0380,  0.0004, -0.0294,  ..., -0.0014, -0.0018,  0.0032],\n",
       "         ...,\n",
       "         [-0.0143, -0.0089, -0.0025,  ...,  0.0012,  0.0035,  0.0068],\n",
       "         [-0.0023,  0.0024, -0.0005,  ..., -0.0042,  0.0019, -0.0036],\n",
       "         [ 0.0006, -0.0013,  0.0157,  ...,  0.0162, -0.0128, -0.0319]]])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clsmax.x_c.grad[c]/(torch.norm(clsmax.x_c.grad[c]) + 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "2e581e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "ca4aebad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dp/4fr32ggj4tb41_86_5pj1l8h0000gn/T/ipykernel_90916/1679040594.py:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/core/TensorBody.h:494.)\n",
      "  clsmax.x_c[0].grad\n"
     ]
    }
   ],
   "source": [
    "clsmax.x_c[0].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d47425b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67df0c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.norm(clsmax.x_c[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "35a2b838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "9a942db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1230ff310>"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "std_tens = torch.tensor(std).reshape(-1,1,1)\n",
    "mean_tens = torch.tensor(mean).reshape(-1,1,1)\n",
    "plt.imshow((clsmax.x_c[0]*std_tens + mean_tens).detach().numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "cb027593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2471]],\n",
       "\n",
       "        [[0.2435]],\n",
       "\n",
       "        [[0.2616]]])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "aaba415e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4914]],\n",
       "\n",
       "        [[0.4822]],\n",
       "\n",
       "        [[0.4465]]])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "5099ee21",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model((clsmax.x_c[0]).unsqueeze(0))\n",
    "cls_lbl = out.argmax() # model((clsmax.x_c[0]*std_tens + mean_tens).unsqueeze(0)).argmax()\n",
    "# cls_lbl = model((centers[0]).unsqueeze(0)).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "91fb5894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6624,  0.5677,  0.2245, -0.8091, -0.0145, -0.4719, -0.1604,  0.2799,\n",
       "          0.1038,  0.8313]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "a0f3b28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_classes = [\n",
    "    'airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "    'dog', 'frog', 'horse', 'ship', 'truck'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "5a92a3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airplane\n"
     ]
    }
   ],
   "source": [
    "print(cifar10_classes[cls_lbl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027d3d04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0896a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
